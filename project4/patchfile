diff --git mysys/my_pthread.c mysys/my_pthread.c
index ac6d3f87de3..6d245e3fa18 100644
--- mysys/my_pthread.c
+++ mysys/my_pthread.c
@@ -59,8 +59,8 @@ struct tm *localtime_r(const time_t *clock, struct tm *res)
 #endif
 
 #if !defined(HAVE_GMTIME_R)
-/* 
-  Reentrant version of standard gmtime() function. 
+/*
+  Reentrant version of standard gmtime() function.
   Needed on some systems which don't implement it.
 */
 
@@ -383,7 +383,7 @@ void my_pthread_attr_getstacksize(pthread_attr_t *connection_attrib,
   0		If we are able successfully lock the mutex.
   EBUSY		Mutex was locked by another thread
   #		Other error number returned by pthread_mutex_trylock()
-		(Not likely)  
+		(Not likely)
 */
 
 int my_pthread_mutex_trylock(pthread_mutex_t *mutex)
diff --git storage/innobase/buf/buf0buf.cc storage/innobase/buf/buf0buf.cc
index 41d242a9360..5d53f6a8d45 100644
--- storage/innobase/buf/buf0buf.cc
+++ storage/innobase/buf/buf0buf.cc
@@ -80,37 +80,37 @@ Created 11/5/1995 Heikki Tuuri
 #include <numaif.h>
 struct set_numa_interleave_t
 {
-	set_numa_interleave_t()
-	{
-		if (srv_numa_interleave) {
-
-			struct bitmask *numa_mems_allowed = numa_get_mems_allowed();
-			ib::info() << "Setting NUMA memory policy to"
-				" MPOL_INTERLEAVE";
-			if (set_mempolicy(MPOL_INTERLEAVE,
-					  numa_mems_allowed->maskp,
-					  numa_mems_allowed->size) != 0) {
-
-				ib::warn() << "Failed to set NUMA memory"
-					" policy to MPOL_INTERLEAVE: "
-					<< strerror(errno);
-			}
-		}
-	}
-
-	~set_numa_interleave_t()
-	{
-		if (srv_numa_interleave) {
-
-			ib::info() << "Setting NUMA memory policy to"
-				" MPOL_DEFAULT";
-			if (set_mempolicy(MPOL_DEFAULT, NULL, 0) != 0) {
-				ib::warn() << "Failed to set NUMA memory"
-					" policy to MPOL_DEFAULT: "
-					<< strerror(errno);
-			}
-		}
-	}
+  set_numa_interleave_t()
+  {
+    if (srv_numa_interleave) {
+
+      struct bitmask *numa_mems_allowed = numa_get_mems_allowed();
+      ib::info() << "Setting NUMA memory policy to"
+        " MPOL_INTERLEAVE";
+      if (set_mempolicy(MPOL_INTERLEAVE,
+            numa_mems_allowed->maskp,
+            numa_mems_allowed->size) != 0) {
+
+        ib::warn() << "Failed to set NUMA memory"
+          " policy to MPOL_INTERLEAVE: "
+          << strerror(errno);
+      }
+    }
+  }
+
+  ~set_numa_interleave_t()
+  {
+    if (srv_numa_interleave) {
+
+      ib::info() << "Setting NUMA memory policy to"
+        " MPOL_DEFAULT";
+      if (set_mempolicy(MPOL_DEFAULT, NULL, 0) != 0) {
+        ib::warn() << "Failed to set NUMA memory"
+          " policy to MPOL_DEFAULT: "
+          << strerror(errno);
+      }
+    }
+  }
 };
 
 #define NUMA_MEMPOLICY_INTERLEAVE_IN_SCOPE set_numa_interleave_t scoped_numa
@@ -129,7 +129,7 @@ inline void* aligned_malloc(size_t size, size_t align) {
     result = _aligned_malloc(size, align);
 #elif defined (HAVE_POSIX_MEMALIGN)
     if(posix_memalign(&result, align, size)) {
-	    result = 0;
+      result = 0;
     }
 #else
     /* Use unaligned malloc as fallback */
@@ -148,17 +148,17 @@ inline void aligned_free(void *ptr) {
 
 buf_pool_t::io_buf_t::~io_buf_t()
 {
-	for (buf_tmp_buffer_t* s = slots, *e = slots + n_slots; s != e; s++) {
-		aligned_free(s->crypt_buf);
-		aligned_free(s->comp_buf);
-	}
-	ut_free(slots);
+  for (buf_tmp_buffer_t* s = slots, *e = slots + n_slots; s != e; s++) {
+    aligned_free(s->crypt_buf);
+    aligned_free(s->comp_buf);
+  }
+  ut_free(slots);
 }
 #endif /* !UNIV_INNOCHECKSUM */
 
 /*
-		IMPLEMENTATION OF THE BUFFER POOL
-		=================================
+    IMPLEMENTATION OF THE BUFFER POOL
+    =================================
 
 Performance improvement:
 ------------------------
@@ -175,16 +175,16 @@ and NT. User space thread libraries might be very fast.
 SQL Server 7.0 can be configured to use 'fibers' which are lightweight
 threads in NT. These should be studied.
 
-		Buffer frames and blocks
-		------------------------
+    Buffer frames and blocks
+    ------------------------
 Following the terminology of Gray and Reuter, we call the memory
 blocks where file pages are loaded buffer frames. For each buffer
 frame there is a control block, or shortly, a block, in the buffer
 control array. The control info which does not need to be stored
 in the file along with the file page, resides in the control block.
 
-		Buffer pool struct
-		------------------
+    Buffer pool struct
+    ------------------
 The buffer buf_pool contains a single mutex which protects all the
 control data structures of the buf_pool. The content of a buffer frame is
 protected by a separate read-write lock in its control block, though.
@@ -204,8 +204,8 @@ create a separate mutex for the page hash table. On Pentium,
 accessing the hash table takes 2 microseconds, about half
 of the total buf_pool->mutex hold time.
 
-		Control blocks
-		--------------
+    Control blocks
+    --------------
 
 The control block contains, for instance, the bufferfix count
 which is incremented when a thread wants a file page to be fixed
@@ -241,8 +241,8 @@ possibly, extra space required on non-leaf pages for memory pointers.
 A simpler solution is just to speed up the hash table mechanism
 in the database, using tables whose size is a power of 2.
 
-		Lists of blocks
-		---------------
+    Lists of blocks
+    ---------------
 
 There are several lists of control blocks.
 
@@ -293,8 +293,8 @@ BUF_BLOCK_MEMORY that the buddy allocator requests from the buffer
 pool.  The buddy allocator is solely used for allocating control
 blocks for compressed pages (buf_page_t) and compressed page frames.
 
-		Loading a file page
-		-------------------
+    Loading a file page
+    -------------------
 
 First, a victim block for replacement has to be found in the
 buf_pool. It is taken from the free list or searched for from the
@@ -308,8 +308,8 @@ A thread may request the above operation using the function
 buf_page_get(). It may then continue to request a lock on the frame.
 The lock is granted when the io-handler releases the x-lock.
 
-		Read-ahead
-		----------
+    Read-ahead
+    ----------
 
 The read-ahead mechanism is intended to be intelligent and
 isolated from the semantically higher levels of the database
@@ -374,11 +374,11 @@ volatile ulint	buf_withdraw_clock;
 This is newly made by initialization of buffer pool and buf_resize_thread.
 Currently, no need mutex protection for update. */
 typedef std::map<
-	const byte*,
-	buf_chunk_t*,
-	std::less<const byte*>,
-	ut_allocator<std::pair<const byte* const, buf_chunk_t*> > >
-	buf_pool_chunk_map_t;
+  const byte*,
+  buf_chunk_t*,
+  std::less<const byte*>,
+  ut_allocator<std::pair<const byte* const, buf_chunk_t*> > >
+  buf_pool_chunk_map_t;
 
 static buf_pool_chunk_map_t*			buf_chunk_map_reg;
 
@@ -418,9 +418,9 @@ be effective only if PFS_GROUP_BUFFER_SYNC is defined. */
 /** Macro to determine whether the read of write counter is used depending
 on the io_type */
 #define MONITOR_RW_COUNTER(io_type, counter)		\
-	((io_type == BUF_IO_READ)			\
-	 ? (counter##_READ)				\
-	 : (counter##_WRITTEN))
+  ((io_type == BUF_IO_READ)			\
+   ? (counter##_READ)				\
+   : (counter##_WRITTEN))
 
 
 /** Reserve a buffer slot for encryption, decryption or page compression.
@@ -428,38 +428,38 @@ on the io_type */
 @return reserved buffer slot */
 static buf_tmp_buffer_t* buf_pool_reserve_tmp_slot(buf_pool_t* buf_pool)
 {
-	buf_tmp_buffer_t* slot = buf_pool->io_buf.reserve();
-	ut_a(slot);
-	return slot;
+  buf_tmp_buffer_t* slot = buf_pool->io_buf.reserve();
+  ut_a(slot);
+  return slot;
 }
 
 /** Reserve a buffer for encryption, decryption or decompression.
 @param[in,out]	slot	reserved slot */
 static void buf_tmp_reserve_crypt_buf(buf_tmp_buffer_t* slot)
 {
-	if (!slot->crypt_buf) {
-		slot->crypt_buf = static_cast<byte*>(
-			aligned_malloc(srv_page_size, srv_page_size));
-	}
+  if (!slot->crypt_buf) {
+    slot->crypt_buf = static_cast<byte*>(
+      aligned_malloc(srv_page_size, srv_page_size));
+  }
 }
 
 /** Reserve a buffer for compression.
 @param[in,out]	slot	reserved slot */
 static void buf_tmp_reserve_compression_buf(buf_tmp_buffer_t* slot)
 {
-	if (!slot->comp_buf) {
-		/* Both snappy and lzo compression methods require that
-		output buffer used for compression is bigger than input
-		buffer. Increase the allocated buffer size accordingly. */
-		ulint size = srv_page_size;
+  if (!slot->comp_buf) {
+    /* Both snappy and lzo compression methods require that
+    output buffer used for compression is bigger than input
+    buffer. Increase the allocated buffer size accordingly. */
+    ulint size = srv_page_size;
 #ifdef HAVE_LZO
-		size += LZO1X_1_15_MEM_COMPRESS;
+    size += LZO1X_1_15_MEM_COMPRESS;
 #elif defined HAVE_SNAPPY
-		size = snappy_max_compressed_length(size);
+    size = snappy_max_compressed_length(size);
 #endif
-		slot->comp_buf = static_cast<byte*>(
-			aligned_malloc(size, srv_page_size));
-	}
+    slot->comp_buf = static_cast<byte*>(
+      aligned_malloc(size, srv_page_size));
+  }
 }
 
 /** Registers a chunk to buf_pool_chunk_map
@@ -467,10 +467,10 @@ static void buf_tmp_reserve_compression_buf(buf_tmp_buffer_t* slot)
 static
 void
 buf_pool_register_chunk(
-	buf_chunk_t*	chunk)
+  buf_chunk_t*	chunk)
 {
-	buf_chunk_map_reg->insert(buf_pool_chunk_map_t::value_type(
-		chunk->blocks->frame, chunk));
+  buf_chunk_map_reg->insert(buf_pool_chunk_map_t::value_type(
+    chunk->blocks->frame, chunk));
 }
 
 /** Decrypt a page for temporary tablespace.
@@ -479,37 +479,37 @@ buf_pool_register_chunk(
 @return true if temporary tablespace decrypted, false if not */
 static bool buf_tmp_page_decrypt(byte* tmp_frame, byte* src_frame)
 {
-	if (buf_page_is_zeroes(src_frame, srv_page_size)) {
-		return true;
-	}
+  if (buf_page_is_zeroes(src_frame, srv_page_size)) {
+    return true;
+  }
 
-	/* read space & lsn */
-	uint header_len = FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION;
+  /* read space & lsn */
+  uint header_len = FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION;
 
-	/* Copy FIL page header, it is not encrypted */
-	memcpy(tmp_frame, src_frame, header_len);
+  /* Copy FIL page header, it is not encrypted */
+  memcpy(tmp_frame, src_frame, header_len);
 
-	/* Calculate the offset where decryption starts */
-	const byte* src = src_frame + header_len;
-	byte* dst = tmp_frame + header_len;
-	uint srclen = uint(srv_page_size)
-		- (header_len + FIL_PAGE_FCRC32_CHECKSUM);
-	ulint offset = mach_read_from_4(src_frame + FIL_PAGE_OFFSET);
+  /* Calculate the offset where decryption starts */
+  const byte* src = src_frame + header_len;
+  byte* dst = tmp_frame + header_len;
+  uint srclen = uint(srv_page_size)
+    - (header_len + FIL_PAGE_FCRC32_CHECKSUM);
+  ulint offset = mach_read_from_4(src_frame + FIL_PAGE_OFFSET);
 
-	if (!log_tmp_block_decrypt(src, srclen, dst,
-				   (offset * srv_page_size))) {
-		return false;
-	}
+  if (!log_tmp_block_decrypt(src, srclen, dst,
+           (offset * srv_page_size))) {
+    return false;
+  }
 
-	memcpy(tmp_frame + srv_page_size - FIL_PAGE_FCRC32_CHECKSUM,
-	       src_frame + srv_page_size - FIL_PAGE_FCRC32_CHECKSUM,
-	       FIL_PAGE_FCRC32_CHECKSUM);
+  memcpy(tmp_frame + srv_page_size - FIL_PAGE_FCRC32_CHECKSUM,
+         src_frame + srv_page_size - FIL_PAGE_FCRC32_CHECKSUM,
+         FIL_PAGE_FCRC32_CHECKSUM);
 
-	memcpy(src_frame, tmp_frame, srv_page_size);
-	srv_stats.pages_decrypted.inc();
-	srv_stats.n_temp_blocks_decrypted.inc();
+  memcpy(src_frame, tmp_frame, srv_page_size);
+  srv_stats.pages_decrypted.inc();
+  srv_stats.n_temp_blocks_decrypted.inc();
 
-	return true; /* page was decrypted */
+  return true; /* page was decrypted */
 }
 
 /** Decrypt a page.
@@ -518,109 +518,109 @@ static bool buf_tmp_page_decrypt(byte* tmp_frame, byte* src_frame)
 @return whether the operation was successful */
 static bool buf_page_decrypt_after_read(buf_page_t* bpage, fil_space_t* space)
 {
-	ut_ad(space->pending_io());
-	ut_ad(space->id == bpage->id.space());
-
-	byte* dst_frame = bpage->zip.data ? bpage->zip.data :
-		((buf_block_t*) bpage)->frame;
-	bool page_compressed = space->is_compressed()
-		&& buf_page_is_compressed(dst_frame, space->flags);
-	buf_pool_t* buf_pool = buf_pool_from_bpage(bpage);
-
-	if (bpage->id.page_no() == 0) {
-		/* File header pages are not encrypted/compressed */
-		return (true);
-	}
-
-	if (space->purpose == FIL_TYPE_TEMPORARY
-	    && innodb_encrypt_temporary_tables) {
-		buf_tmp_buffer_t* slot = buf_pool_reserve_tmp_slot(buf_pool);
-		buf_tmp_reserve_crypt_buf(slot);
-
-		if (!buf_tmp_page_decrypt(slot->crypt_buf, dst_frame)) {
-			slot->release();
-			ib::error() << "Encrypted page " << bpage->id
-				    << " in file " << space->chain.start->name;
-			return false;
-		}
-
-		slot->release();
-		return true;
-	}
-
-	/* Page is encrypted if encryption information is found from
-	tablespace and page contains used key_version. This is true
-	also for pages first compressed and then encrypted. */
-
-	buf_tmp_buffer_t* slot;
-	uint key_version = buf_page_get_key_version(dst_frame, space->flags);
-
-	if (page_compressed && !key_version) {
-		/* the page we read is unencrypted */
-		/* Find free slot from temporary memory array */
+  ut_ad(space->pending_io());
+  ut_ad(space->id == bpage->id.space());
+
+  byte* dst_frame = bpage->zip.data ? bpage->zip.data :
+    ((buf_block_t*) bpage)->frame;
+  bool page_compressed = space->is_compressed()
+    && buf_page_is_compressed(dst_frame, space->flags);
+  buf_pool_t* buf_pool = buf_pool_from_bpage(bpage);
+
+  if (bpage->id.page_no() == 0) {
+    /* File header pages are not encrypted/compressed */
+    return (true);
+  }
+
+  if (space->purpose == FIL_TYPE_TEMPORARY
+      && innodb_encrypt_temporary_tables) {
+    buf_tmp_buffer_t* slot = buf_pool_reserve_tmp_slot(buf_pool);
+    buf_tmp_reserve_crypt_buf(slot);
+
+    if (!buf_tmp_page_decrypt(slot->crypt_buf, dst_frame)) {
+      slot->release();
+      ib::error() << "Encrypted page " << bpage->id
+            << " in file " << space->chain.start->name;
+      return false;
+    }
+
+    slot->release();
+    return true;
+  }
+
+  /* Page is encrypted if encryption information is found from
+  tablespace and page contains used key_version. This is true
+  also for pages first compressed and then encrypted. */
+
+  buf_tmp_buffer_t* slot;
+  uint key_version = buf_page_get_key_version(dst_frame, space->flags);
+
+  if (page_compressed && !key_version) {
+    /* the page we read is unencrypted */
+    /* Find free slot from temporary memory array */
 decompress:
-		if (space->full_crc32()
-		    && buf_page_is_corrupted(true, dst_frame, space->flags)) {
-			return false;
-		}
+    if (space->full_crc32()
+        && buf_page_is_corrupted(true, dst_frame, space->flags)) {
+      return false;
+    }
 
-		slot = buf_pool_reserve_tmp_slot(buf_pool);
-		/* For decompression, use crypt_buf. */
-		buf_tmp_reserve_crypt_buf(slot);
+    slot = buf_pool_reserve_tmp_slot(buf_pool);
+    /* For decompression, use crypt_buf. */
+    buf_tmp_reserve_crypt_buf(slot);
 
 decompress_with_slot:
-		ut_d(fil_page_type_validate(space, dst_frame));
+    ut_d(fil_page_type_validate(space, dst_frame));
 
-		bpage->write_size = fil_page_decompress(
-			slot->crypt_buf, dst_frame, space->flags);
-		slot->release();
+    bpage->write_size = fil_page_decompress(
+      slot->crypt_buf, dst_frame, space->flags);
+    slot->release();
 
-		ut_ad(!bpage->write_size
-		      || fil_page_type_validate(space, dst_frame));
+    ut_ad(!bpage->write_size
+          || fil_page_type_validate(space, dst_frame));
 
-		ut_ad(space->pending_io());
+    ut_ad(space->pending_io());
 
-		return bpage->write_size != 0;
-	}
+    return bpage->write_size != 0;
+  }
 
-	if (key_version && space->crypt_data) {
-		/* Verify encryption checksum before we even try to
-		decrypt. */
-		if (!buf_page_verify_crypt_checksum(dst_frame, space->flags)) {
+  if (key_version && space->crypt_data) {
+    /* Verify encryption checksum before we even try to
+    decrypt. */
+    if (!buf_page_verify_crypt_checksum(dst_frame, space->flags)) {
 decrypt_failed:
-			ib::error() << "Encrypted page " << bpage->id
-				    << " in file " << space->chain.start->name
-				    << " looks corrupted; key_version="
-				    << key_version;
-			return false;
-		}
-
-		/* Find free slot from temporary memory array */
-		slot = buf_pool_reserve_tmp_slot(buf_pool);
-		buf_tmp_reserve_crypt_buf(slot);
-
-		ut_d(fil_page_type_validate(space, dst_frame));
-
-		/* decrypt using crypt_buf to dst_frame */
-		if (!fil_space_decrypt(space, slot->crypt_buf, dst_frame)) {
-			slot->release();
-			goto decrypt_failed;
-		}
-
-		ut_d(fil_page_type_validate(space, dst_frame));
-
-		if ((space->full_crc32() && page_compressed)
-		    || fil_page_is_compressed_encrypted(dst_frame)) {
-			goto decompress_with_slot;
-		}
-
-		slot->release();
-	} else if (fil_page_is_compressed_encrypted(dst_frame)) {
-		goto decompress;
-	}
-
-	ut_ad(space->pending_io());
-	return true;
+      ib::error() << "Encrypted page " << bpage->id
+            << " in file " << space->chain.start->name
+            << " looks corrupted; key_version="
+            << key_version;
+      return false;
+    }
+
+    /* Find free slot from temporary memory array */
+    slot = buf_pool_reserve_tmp_slot(buf_pool);
+    buf_tmp_reserve_crypt_buf(slot);
+
+    ut_d(fil_page_type_validate(space, dst_frame));
+
+    /* decrypt using crypt_buf to dst_frame */
+    if (!fil_space_decrypt(space, slot->crypt_buf, dst_frame)) {
+      slot->release();
+      goto decrypt_failed;
+    }
+
+    ut_d(fil_page_type_validate(space, dst_frame));
+
+    if ((space->full_crc32() && page_compressed)
+        || fil_page_is_compressed_encrypted(dst_frame)) {
+      goto decompress_with_slot;
+    }
+
+    slot->release();
+  } else if (fil_page_is_compressed_encrypted(dst_frame)) {
+    goto decompress;
+  }
+
+  ut_ad(space->pending_io());
+  return true;
 }
 
 /********************************************************************//**
@@ -631,50 +631,50 @@ lsn_t
 buf_pool_get_oldest_modification(void)
 /*==================================*/
 {
-	lsn_t		lsn = 0;
-	lsn_t		oldest_lsn = 0;
+  lsn_t		lsn = 0;
+  lsn_t		oldest_lsn = 0;
 
-	/* When we traverse all the flush lists we don't want another
-	thread to add a dirty page to any flush list. */
-	log_flush_order_mutex_enter();
+  /* When we traverse all the flush lists we don't want another
+  thread to add a dirty page to any flush list. */
+  log_flush_order_mutex_enter();
 
-	for (ulint i = 0; i < srv_buf_pool_instances; i++) {
-		buf_pool_t*	buf_pool;
+  for (ulint i = 0; i < srv_buf_pool_instances; i++) {
+    buf_pool_t*	buf_pool;
 
-		buf_pool = buf_pool_from_array(i);
+    buf_pool = buf_pool_from_array(i);
 
-		buf_flush_list_mutex_enter(buf_pool);
+    buf_flush_list_mutex_enter(buf_pool);
 
-		buf_page_t*	bpage;
+    buf_page_t*	bpage;
 
-		/* We don't let log-checkpoint halt because pages from system
-		temporary are not yet flushed to the disk. Anyway, object
-		residing in system temporary doesn't generate REDO logging. */
-		for (bpage = UT_LIST_GET_LAST(buf_pool->flush_list);
-		     bpage != NULL
-			&& fsp_is_system_temporary(bpage->id.space());
-		     bpage = UT_LIST_GET_PREV(list, bpage)) {
-			/* Do nothing. */
-		}
+    /* We don't let log-checkpoint halt because pages from system
+    temporary are not yet flushed to the disk. Anyway, object
+    residing in system temporary doesn't generate REDO logging. */
+    for (bpage = UT_LIST_GET_LAST(buf_pool->flush_list);
+         bpage != NULL
+      && fsp_is_system_temporary(bpage->id.space());
+         bpage = UT_LIST_GET_PREV(list, bpage)) {
+      /* Do nothing. */
+    }
 
-		if (bpage != NULL) {
-			ut_ad(bpage->in_flush_list);
-			lsn = bpage->oldest_modification;
-		}
+    if (bpage != NULL) {
+      ut_ad(bpage->in_flush_list);
+      lsn = bpage->oldest_modification;
+    }
 
-		buf_flush_list_mutex_exit(buf_pool);
+    buf_flush_list_mutex_exit(buf_pool);
 
-		if (!oldest_lsn || oldest_lsn > lsn) {
-			oldest_lsn = lsn;
-		}
-	}
+    if (!oldest_lsn || oldest_lsn > lsn) {
+      oldest_lsn = lsn;
+    }
+  }
 
-	log_flush_order_mutex_exit();
+  log_flush_order_mutex_exit();
 
-	/* The returned answer may be out of date: the flush_list can
-	change after the mutex has been released. */
+  /* The returned answer may be out of date: the flush_list can
+  change after the mutex has been released. */
 
-	return(oldest_lsn);
+  return(oldest_lsn);
 }
 
 /********************************************************************//**
@@ -682,25 +682,25 @@ Get total buffer pool statistics. */
 void
 buf_get_total_list_len(
 /*===================*/
-	ulint*		LRU_len,	/*!< out: length of all LRU lists */
-	ulint*		free_len,	/*!< out: length of all free lists */
-	ulint*		flush_list_len)	/*!< out: length of all flush lists */
+  ulint*		LRU_len,	/*!< out: length of all LRU lists */
+  ulint*		free_len,	/*!< out: length of all free lists */
+  ulint*		flush_list_len)	/*!< out: length of all flush lists */
 {
-	ulint		i;
+  ulint		i;
 
-	*LRU_len = 0;
-	*free_len = 0;
-	*flush_list_len = 0;
+  *LRU_len = 0;
+  *free_len = 0;
+  *flush_list_len = 0;
 
-	for (i = 0; i < srv_buf_pool_instances; i++) {
-		buf_pool_t*	buf_pool;
+  for (i = 0; i < srv_buf_pool_instances; i++) {
+    buf_pool_t*	buf_pool;
 
-		buf_pool = buf_pool_from_array(i);
+    buf_pool = buf_pool_from_array(i);
 
-		*LRU_len += UT_LIST_GET_LEN(buf_pool->LRU);
-		*free_len += UT_LIST_GET_LEN(buf_pool->free);
-		*flush_list_len += UT_LIST_GET_LEN(buf_pool->flush_list);
-	}
+    *LRU_len += UT_LIST_GET_LEN(buf_pool->LRU);
+    *free_len += UT_LIST_GET_LEN(buf_pool->free);
+    *flush_list_len += UT_LIST_GET_LEN(buf_pool->flush_list);
+  }
 }
 
 /********************************************************************//**
@@ -708,25 +708,25 @@ Get total list size in bytes from all buffer pools. */
 void
 buf_get_total_list_size_in_bytes(
 /*=============================*/
-	buf_pools_list_size_t*	buf_pools_list_size)	/*!< out: list sizes
-							in all buffer pools */
+  buf_pools_list_size_t*	buf_pools_list_size)	/*!< out: list sizes
+              in all buffer pools */
 {
-	ut_ad(buf_pools_list_size);
-	memset(buf_pools_list_size, 0, sizeof(*buf_pools_list_size));
-
-	for (ulint i = 0; i < srv_buf_pool_instances; i++) {
-		buf_pool_t*	buf_pool;
-
-		buf_pool = buf_pool_from_array(i);
-		/* We don't need mutex protection since this is
-		for statistics purpose */
-		buf_pools_list_size->LRU_bytes += buf_pool->stat.LRU_bytes;
-		buf_pools_list_size->unzip_LRU_bytes +=
-			UT_LIST_GET_LEN(buf_pool->unzip_LRU)
-			<< srv_page_size_shift;
-		buf_pools_list_size->flush_list_bytes +=
-			buf_pool->stat.flush_list_bytes;
-	}
+  ut_ad(buf_pools_list_size);
+  memset(buf_pools_list_size, 0, sizeof(*buf_pools_list_size));
+
+  for (ulint i = 0; i < srv_buf_pool_instances; i++) {
+    buf_pool_t*	buf_pool;
+
+    buf_pool = buf_pool_from_array(i);
+    /* We don't need mutex protection since this is
+    for statistics purpose */
+    buf_pools_list_size->LRU_bytes += buf_pool->stat.LRU_bytes;
+    buf_pools_list_size->unzip_LRU_bytes +=
+      UT_LIST_GET_LEN(buf_pool->unzip_LRU)
+      << srv_page_size_shift;
+    buf_pools_list_size->flush_list_bytes +=
+      buf_pool->stat.flush_list_bytes;
+  }
 }
 
 /********************************************************************//**
@@ -734,31 +734,31 @@ Get total buffer pool statistics. */
 void
 buf_get_total_stat(
 /*===============*/
-	buf_pool_stat_t*	tot_stat)	/*!< out: buffer pool stats */
+  buf_pool_stat_t*	tot_stat)	/*!< out: buffer pool stats */
 {
-	ulint			i;
+  ulint			i;
 
-	memset(tot_stat, 0, sizeof(*tot_stat));
+  memset(tot_stat, 0, sizeof(*tot_stat));
 
-	for (i = 0; i < srv_buf_pool_instances; i++) {
-		buf_pool_stat_t*buf_stat;
-		buf_pool_t*	buf_pool;
+  for (i = 0; i < srv_buf_pool_instances; i++) {
+    buf_pool_stat_t*buf_stat;
+    buf_pool_t*	buf_pool;
 
-		buf_pool = buf_pool_from_array(i);
+    buf_pool = buf_pool_from_array(i);
 
-		buf_stat = &buf_pool->stat;
-		tot_stat->n_page_gets += buf_stat->n_page_gets;
-		tot_stat->n_pages_read += buf_stat->n_pages_read;
-		tot_stat->n_pages_written += buf_stat->n_pages_written;
-		tot_stat->n_pages_created += buf_stat->n_pages_created;
-		tot_stat->n_ra_pages_read_rnd += buf_stat->n_ra_pages_read_rnd;
-		tot_stat->n_ra_pages_read += buf_stat->n_ra_pages_read;
-		tot_stat->n_ra_pages_evicted += buf_stat->n_ra_pages_evicted;
-		tot_stat->n_pages_made_young += buf_stat->n_pages_made_young;
+    buf_stat = &buf_pool->stat;
+    tot_stat->n_page_gets += buf_stat->n_page_gets;
+    tot_stat->n_pages_read += buf_stat->n_pages_read;
+    tot_stat->n_pages_written += buf_stat->n_pages_written;
+    tot_stat->n_pages_created += buf_stat->n_pages_created;
+    tot_stat->n_ra_pages_read_rnd += buf_stat->n_ra_pages_read_rnd;
+    tot_stat->n_ra_pages_read += buf_stat->n_ra_pages_read;
+    tot_stat->n_ra_pages_evicted += buf_stat->n_ra_pages_evicted;
+    tot_stat->n_pages_made_young += buf_stat->n_pages_made_young;
 
-		tot_stat->n_pages_not_made_young +=
-			buf_stat->n_pages_not_made_young;
-	}
+    tot_stat->n_pages_not_made_young +=
+      buf_stat->n_pages_not_made_young;
+  }
 }
 
 /********************************************************************//**
@@ -767,26 +767,26 @@ Allocates a buffer block.
 buf_block_t*
 buf_block_alloc(
 /*============*/
-	buf_pool_t*	buf_pool)	/*!< in/out: buffer pool instance,
-					or NULL for round-robin selection
-					of the buffer pool */
+  buf_pool_t*	buf_pool)	/*!< in/out: buffer pool instance,
+          or NULL for round-robin selection
+          of the buffer pool */
 {
-	buf_block_t*	block;
-	ulint		index;
-	static ulint	buf_pool_index;
+  buf_block_t*	block;
+  ulint		index;
+  static ulint	buf_pool_index;
 
-	if (buf_pool == NULL) {
-		/* We are allocating memory from any buffer pool, ensure
-		we spread the grace on all buffer pool instances. */
-		index = buf_pool_index++ % srv_buf_pool_instances;
-		buf_pool = buf_pool_from_array(index);
-	}
+  if (buf_pool == NULL) {
+    /* We are allocating memory from any buffer pool, ensure
+    we spread the grace on all buffer pool instances. */
+    index = buf_pool_index++ % srv_buf_pool_instances;
+    buf_pool = buf_pool_from_array(index);
+  }
 
-	block = buf_LRU_get_free_block(buf_pool);
+  block = buf_LRU_get_free_block(buf_pool);
 
-	buf_block_set_state(block, BUF_BLOCK_MEMORY);
+  buf_block_set_state(block, BUF_BLOCK_MEMORY);
 
-	return(block);
+  return(block);
 }
 #endif /* !UNIV_INNOCHECKSUM */
 
@@ -797,28 +797,28 @@ buf_block_alloc(
 @return true if the page is in crc32 checksum format. */
 bool
 buf_page_is_checksum_valid_crc32(
-	const byte*			read_buf,
-	ulint				checksum_field1,
-	ulint				checksum_field2)
+  const byte*			read_buf,
+  ulint				checksum_field1,
+  ulint				checksum_field2)
 {
-	const uint32_t	crc32 = buf_calc_page_crc32(read_buf);
+  const uint32_t	crc32 = buf_calc_page_crc32(read_buf);
 
 #ifdef UNIV_INNOCHECKSUM
-	if (log_file
-	    && srv_checksum_algorithm == SRV_CHECKSUM_ALGORITHM_STRICT_CRC32) {
-		fprintf(log_file, "page::%llu;"
-			" crc32 calculated = %u;"
-			" recorded checksum field1 = " ULINTPF " recorded"
-			" checksum field2 =" ULINTPF "\n", cur_page_num,
-			crc32, checksum_field1, checksum_field2);
-	}
+  if (log_file
+      && srv_checksum_algorithm == SRV_CHECKSUM_ALGORITHM_STRICT_CRC32) {
+    fprintf(log_file, "page::%llu;"
+      " crc32 calculated = %u;"
+      " recorded checksum field1 = " ULINTPF " recorded"
+      " checksum field2 =" ULINTPF "\n", cur_page_num,
+      crc32, checksum_field1, checksum_field2);
+  }
 #endif /* UNIV_INNOCHECKSUM */
 
-	if (checksum_field1 != checksum_field2) {
-		return false;
-	}
+  if (checksum_field1 != checksum_field2) {
+    return false;
+  }
 
-	return checksum_field1 == crc32;
+  return checksum_field1 == crc32;
 }
 
 /** Checks if the page is in innodb checksum format.
@@ -828,83 +828,83 @@ buf_page_is_checksum_valid_crc32(
 @return true if the page is in innodb checksum format. */
 bool
 buf_page_is_checksum_valid_innodb(
-	const byte*			read_buf,
-	ulint				checksum_field1,
-	ulint				checksum_field2)
+  const byte*			read_buf,
+  ulint				checksum_field1,
+  ulint				checksum_field2)
 {
-	/* There are 2 valid formulas for
-	checksum_field2 (old checksum field) which algo=innodb could have
-	written to the page:
+  /* There are 2 valid formulas for
+  checksum_field2 (old checksum field) which algo=innodb could have
+  written to the page:
 
-	1. Very old versions of InnoDB only stored 8 byte lsn to the
-	start and the end of the page.
+  1. Very old versions of InnoDB only stored 8 byte lsn to the
+  start and the end of the page.
 
-	2. Newer InnoDB versions store the old formula checksum
-	(buf_calc_page_old_checksum()). */
+  2. Newer InnoDB versions store the old formula checksum
+  (buf_calc_page_old_checksum()). */
 
-	ulint	old_checksum = buf_calc_page_old_checksum(read_buf);
-	ulint	new_checksum = buf_calc_page_new_checksum(read_buf);
+  ulint	old_checksum = buf_calc_page_old_checksum(read_buf);
+  ulint	new_checksum = buf_calc_page_new_checksum(read_buf);
 
 #ifdef UNIV_INNOCHECKSUM
-	if (log_file
-	    && srv_checksum_algorithm == SRV_CHECKSUM_ALGORITHM_INNODB) {
-		fprintf(log_file, "page::%llu;"
-			" old style: calculated ="
-			" " ULINTPF "; recorded = " ULINTPF "\n",
-			cur_page_num, old_checksum,
-			checksum_field2);
-		fprintf(log_file, "page::%llu;"
-			" new style: calculated ="
-			" " ULINTPF "; crc32 = %u; recorded = " ULINTPF "\n",
-			cur_page_num, new_checksum,
-			buf_calc_page_crc32(read_buf), checksum_field1);
-	}
-
-	if (log_file
-	    && srv_checksum_algorithm == SRV_CHECKSUM_ALGORITHM_STRICT_INNODB) {
-		fprintf(log_file, "page::%llu;"
-			" old style: calculated ="
-			" " ULINTPF "; recorded checksum = " ULINTPF "\n",
-			cur_page_num, old_checksum,
-			checksum_field2);
-		fprintf(log_file, "page::%llu;"
-			" new style: calculated ="
-			" " ULINTPF "; recorded checksum  = " ULINTPF "\n",
-			cur_page_num, new_checksum,
-			checksum_field1);
-	}
+  if (log_file
+      && srv_checksum_algorithm == SRV_CHECKSUM_ALGORITHM_INNODB) {
+    fprintf(log_file, "page::%llu;"
+      " old style: calculated ="
+      " " ULINTPF "; recorded = " ULINTPF "\n",
+      cur_page_num, old_checksum,
+      checksum_field2);
+    fprintf(log_file, "page::%llu;"
+      " new style: calculated ="
+      " " ULINTPF "; crc32 = %u; recorded = " ULINTPF "\n",
+      cur_page_num, new_checksum,
+      buf_calc_page_crc32(read_buf), checksum_field1);
+  }
+
+  if (log_file
+      && srv_checksum_algorithm == SRV_CHECKSUM_ALGORITHM_STRICT_INNODB) {
+    fprintf(log_file, "page::%llu;"
+      " old style: calculated ="
+      " " ULINTPF "; recorded checksum = " ULINTPF "\n",
+      cur_page_num, old_checksum,
+      checksum_field2);
+    fprintf(log_file, "page::%llu;"
+      " new style: calculated ="
+      " " ULINTPF "; recorded checksum  = " ULINTPF "\n",
+      cur_page_num, new_checksum,
+      checksum_field1);
+  }
 #endif /* UNIV_INNOCHECKSUM */
 
 
-	if (checksum_field2 != mach_read_from_4(read_buf + FIL_PAGE_LSN)
-	    && checksum_field2 != old_checksum) {
-		DBUG_LOG("checksum",
-			 "Page checksum crc32 not valid"
-			 << " field1 " << checksum_field1
-			 << " field2 " << checksum_field2
-			 << " crc32 " << buf_calc_page_old_checksum(read_buf)
-			 << " lsn " << mach_read_from_4(
-				 read_buf + FIL_PAGE_LSN));
-		return(false);
-	}
-
-	/* old field is fine, check the new field */
-
-	/* InnoDB versions < 4.0.14 and < 4.1.1 stored the space id
-	(always equal to 0), to FIL_PAGE_SPACE_OR_CHKSUM */
-
-	if (checksum_field1 != 0 && checksum_field1 != new_checksum) {
-		DBUG_LOG("checksum",
-			 "Page checksum crc32 not valid"
-			 << " field1 " << checksum_field1
-			 << " field2 " << checksum_field2
-			 << " crc32 " << buf_calc_page_new_checksum(read_buf)
-			 << " lsn " << mach_read_from_4(
-				 read_buf + FIL_PAGE_LSN));
-		return(false);
-	}
-
-	return(true);
+  if (checksum_field2 != mach_read_from_4(read_buf + FIL_PAGE_LSN)
+      && checksum_field2 != old_checksum) {
+    DBUG_LOG("checksum",
+       "Page checksum crc32 not valid"
+       << " field1 " << checksum_field1
+       << " field2 " << checksum_field2
+       << " crc32 " << buf_calc_page_old_checksum(read_buf)
+       << " lsn " << mach_read_from_4(
+         read_buf + FIL_PAGE_LSN));
+    return(false);
+  }
+
+  /* old field is fine, check the new field */
+
+  /* InnoDB versions < 4.0.14 and < 4.1.1 stored the space id
+  (always equal to 0), to FIL_PAGE_SPACE_OR_CHKSUM */
+
+  if (checksum_field1 != 0 && checksum_field1 != new_checksum) {
+    DBUG_LOG("checksum",
+       "Page checksum crc32 not valid"
+       << " field1 " << checksum_field1
+       << " field2 " << checksum_field2
+       << " crc32 " << buf_calc_page_new_checksum(read_buf)
+       << " lsn " << mach_read_from_4(
+         read_buf + FIL_PAGE_LSN));
+    return(false);
+  }
+
+  return(true);
 }
 
 /** Checks if the page is in none checksum format.
@@ -914,37 +914,37 @@ buf_page_is_checksum_valid_innodb(
 @return true if the page is in none checksum format. */
 bool
 buf_page_is_checksum_valid_none(
-	const byte*			read_buf,
-	ulint				checksum_field1,
-	ulint				checksum_field2)
+  const byte*			read_buf,
+  ulint				checksum_field1,
+  ulint				checksum_field2)
 {
 #ifndef DBUG_OFF
-	if (checksum_field1 != checksum_field2
-	    && checksum_field1 != BUF_NO_CHECKSUM_MAGIC) {
-		DBUG_LOG("checksum",
-			 "Page checksum crc32 not valid"
-			 << " field1 " << checksum_field1
-			 << " field2 " << checksum_field2
-			 << " crc32 " << BUF_NO_CHECKSUM_MAGIC
-			 << " lsn " << mach_read_from_4(read_buf
-							+ FIL_PAGE_LSN));
-	}
+  if (checksum_field1 != checksum_field2
+      && checksum_field1 != BUF_NO_CHECKSUM_MAGIC) {
+    DBUG_LOG("checksum",
+       "Page checksum crc32 not valid"
+       << " field1 " << checksum_field1
+       << " field2 " << checksum_field2
+       << " crc32 " << BUF_NO_CHECKSUM_MAGIC
+       << " lsn " << mach_read_from_4(read_buf
+              + FIL_PAGE_LSN));
+  }
 #endif /* DBUG_OFF */
 
 #ifdef UNIV_INNOCHECKSUM
-	if (log_file
-	    && srv_checksum_algorithm == SRV_CHECKSUM_ALGORITHM_STRICT_NONE) {
-		fprintf(log_file,
-			"page::%llu; none checksum: calculated"
-			" = %lu; recorded checksum_field1 = " ULINTPF
-			" recorded checksum_field2 = " ULINTPF "\n",
-			cur_page_num, BUF_NO_CHECKSUM_MAGIC,
-			checksum_field1, checksum_field2);
-	}
+  if (log_file
+      && srv_checksum_algorithm == SRV_CHECKSUM_ALGORITHM_STRICT_NONE) {
+    fprintf(log_file,
+      "page::%llu; none checksum: calculated"
+      " = %lu; recorded checksum_field1 = " ULINTPF
+      " recorded checksum_field2 = " ULINTPF "\n",
+      cur_page_num, BUF_NO_CHECKSUM_MAGIC,
+      checksum_field1, checksum_field2);
+  }
 #endif /* UNIV_INNOCHECKSUM */
 
-	return(checksum_field1 == checksum_field2
-	       && checksum_field1 == BUF_NO_CHECKSUM_MAGIC);
+  return(checksum_field1 == checksum_field2
+         && checksum_field1 == BUF_NO_CHECKSUM_MAGIC);
 }
 
 /** Checks whether the lsn present in the page is lesser than the
@@ -954,35 +954,35 @@ peek current lsn.
 static void buf_page_check_lsn(bool check_lsn, const byte* read_buf)
 {
 #ifndef UNIV_INNOCHECKSUM
-	if (check_lsn && recv_lsn_checks_on) {
-		lsn_t		current_lsn;
-		const lsn_t	page_lsn
-			= mach_read_from_8(read_buf + FIL_PAGE_LSN);
-
-		/* Since we are going to reset the page LSN during the import
-		phase it makes no sense to spam the log with error messages. */
-
-		if (log_peek_lsn(&current_lsn) && current_lsn < page_lsn) {
-
-			const ulint	space_id = mach_read_from_4(
-				read_buf + FIL_PAGE_SPACE_ID);
-			const ulint	page_no = mach_read_from_4(
-				read_buf + FIL_PAGE_OFFSET);
-
-			ib::error() << "Page " << page_id_t(space_id, page_no)
-				<< " log sequence number " << page_lsn
-				<< " is in the future! Current system"
-				<< " log sequence number "
-				<< current_lsn << ".";
-
-			ib::error() << "Your database may be corrupt or"
-				" you may have copied the InnoDB"
-				" tablespace but not the InnoDB"
-				" log files. "
-				<< FORCE_RECOVERY_MSG;
-
-		}
-	}
+  if (check_lsn && recv_lsn_checks_on) {
+    lsn_t		current_lsn;
+    const lsn_t	page_lsn
+      = mach_read_from_8(read_buf + FIL_PAGE_LSN);
+
+    /* Since we are going to reset the page LSN during the import
+    phase it makes no sense to spam the log with error messages. */
+
+    if (log_peek_lsn(&current_lsn) && current_lsn < page_lsn) {
+
+      const ulint	space_id = mach_read_from_4(
+        read_buf + FIL_PAGE_SPACE_ID);
+      const ulint	page_no = mach_read_from_4(
+        read_buf + FIL_PAGE_OFFSET);
+
+      ib::error() << "Page " << page_id_t(space_id, page_no)
+        << " log sequence number " << page_lsn
+        << " is in the future! Current system"
+        << " log sequence number "
+        << current_lsn << ".";
+
+      ib::error() << "Your database may be corrupt or"
+        " you may have copied the InnoDB"
+        " tablespace but not the InnoDB"
+        " log files. "
+        << FORCE_RECOVERY_MSG;
+
+    }
+  }
 #endif /* !UNIV_INNOCHECKSUM */
 }
 
@@ -992,14 +992,14 @@ static void buf_page_check_lsn(bool check_lsn, const byte* read_buf)
 @return whether the page is all zeroes */
 bool buf_page_is_zeroes(const void* read_buf, size_t page_size)
 {
-	const ulint* b = reinterpret_cast<const ulint*>(read_buf);
-	const ulint* const e = b + page_size / sizeof *b;
-	do {
-		if (*b++) {
-			return false;
-		}
-	} while (b != e);
-	return true;
+  const ulint* b = reinterpret_cast<const ulint*>(read_buf);
+  const ulint* const e = b + page_size / sizeof *b;
+  do {
+    if (*b++) {
+      return false;
+    }
+  } while (b != e);
+  return true;
 }
 
 /** Check if a page is corrupt.
@@ -1010,269 +1010,269 @@ bool buf_page_is_zeroes(const void* read_buf, size_t page_size)
 @return whether the page is corrupted */
 bool
 buf_page_is_corrupted(
-	bool			check_lsn,
-	const byte*		read_buf,
-	ulint			fsp_flags)
+  bool			check_lsn,
+  const byte*		read_buf,
+  ulint			fsp_flags)
 {
 #ifndef UNIV_INNOCHECKSUM
-	DBUG_EXECUTE_IF("buf_page_import_corrupt_failure", return(true); );
+  DBUG_EXECUTE_IF("buf_page_import_corrupt_failure", return(true); );
 #endif
-	if (fil_space_t::full_crc32(fsp_flags)) {
-		bool compressed = false, corrupted = false;
-		const uint size = buf_page_full_crc32_size(
-			read_buf, &compressed, &corrupted);
-		if (corrupted) {
-			return true;
-		}
-		const byte* end = read_buf + (size - FIL_PAGE_FCRC32_CHECKSUM);
-		uint crc32 = mach_read_from_4(end);
-
-		if (!crc32 && size == srv_page_size
-		    && buf_page_is_zeroes(read_buf, size)) {
-			return false;
-		}
-
-		DBUG_EXECUTE_IF(
-			"page_intermittent_checksum_mismatch", {
-			static int page_counter;
-			if (page_counter++ == 2) {
-				crc32++;
-			}
-		});
-
-		if (crc32 != ut_crc32(read_buf,
-				      size - FIL_PAGE_FCRC32_CHECKSUM)) {
-			return true;
-		}
-		if (!compressed
-		    && !mach_read_from_4(FIL_PAGE_FCRC32_KEY_VERSION
-					 + read_buf)
-		    && memcmp(read_buf + (FIL_PAGE_LSN + 4),
-			      end - (FIL_PAGE_FCRC32_END_LSN
-				     - FIL_PAGE_FCRC32_CHECKSUM), 4)) {
-			return true;
-		}
-
-		buf_page_check_lsn(check_lsn, read_buf);
-		return false;
-	}
-
-	size_t		checksum_field1 = 0;
-	size_t		checksum_field2 = 0;
-	uint32_t	crc32 = 0;
-	bool		crc32_inited = false;
-	bool		crc32_chksum = false;
-	const ulint zip_size = fil_space_t::zip_size(fsp_flags);
-	ulint page_type = mach_read_from_2(read_buf + FIL_PAGE_TYPE);
-
-	/* We can trust page type if page compression is set on tablespace
-	flags because page compression flag means file must have been
-	created with 10.1 (later than 5.5 code base). In 10.1 page
-	compressed tables do not contain post compression checksum and
-	FIL_PAGE_END_LSN_OLD_CHKSUM field stored. Note that space can
-	be null if we are in fil_check_first_page() and first page
-	is not compressed or encrypted. Page checksum is verified
-	after decompression (i.e. normally pages are already
-	decompressed at this stage). */
-	if ((page_type == FIL_PAGE_PAGE_COMPRESSED ||
-	     page_type == FIL_PAGE_PAGE_COMPRESSED_ENCRYPTED)
+  if (fil_space_t::full_crc32(fsp_flags)) {
+    bool compressed = false, corrupted = false;
+    const uint size = buf_page_full_crc32_size(
+      read_buf, &compressed, &corrupted);
+    if (corrupted) {
+      return true;
+    }
+    const byte* end = read_buf + (size - FIL_PAGE_FCRC32_CHECKSUM);
+    uint crc32 = mach_read_from_4(end);
+
+    if (!crc32 && size == srv_page_size
+        && buf_page_is_zeroes(read_buf, size)) {
+      return false;
+    }
+
+    DBUG_EXECUTE_IF(
+      "page_intermittent_checksum_mismatch", {
+      static int page_counter;
+      if (page_counter++ == 2) {
+        crc32++;
+      }
+    });
+
+    if (crc32 != ut_crc32(read_buf,
+              size - FIL_PAGE_FCRC32_CHECKSUM)) {
+      return true;
+    }
+    if (!compressed
+        && !mach_read_from_4(FIL_PAGE_FCRC32_KEY_VERSION
+           + read_buf)
+        && memcmp(read_buf + (FIL_PAGE_LSN + 4),
+            end - (FIL_PAGE_FCRC32_END_LSN
+             - FIL_PAGE_FCRC32_CHECKSUM), 4)) {
+      return true;
+    }
+
+    buf_page_check_lsn(check_lsn, read_buf);
+    return false;
+  }
+
+  size_t		checksum_field1 = 0;
+  size_t		checksum_field2 = 0;
+  uint32_t	crc32 = 0;
+  bool		crc32_inited = false;
+  bool		crc32_chksum = false;
+  const ulint zip_size = fil_space_t::zip_size(fsp_flags);
+  ulint page_type = mach_read_from_2(read_buf + FIL_PAGE_TYPE);
+
+  /* We can trust page type if page compression is set on tablespace
+  flags because page compression flag means file must have been
+  created with 10.1 (later than 5.5 code base). In 10.1 page
+  compressed tables do not contain post compression checksum and
+  FIL_PAGE_END_LSN_OLD_CHKSUM field stored. Note that space can
+  be null if we are in fil_check_first_page() and first page
+  is not compressed or encrypted. Page checksum is verified
+  after decompression (i.e. normally pages are already
+  decompressed at this stage). */
+  if ((page_type == FIL_PAGE_PAGE_COMPRESSED ||
+       page_type == FIL_PAGE_PAGE_COMPRESSED_ENCRYPTED)
 #ifndef UNIV_INNOCHECKSUM
-	    && FSP_FLAGS_HAS_PAGE_COMPRESSION(fsp_flags)
+      && FSP_FLAGS_HAS_PAGE_COMPRESSION(fsp_flags)
 #endif
-	) {
-		return(false);
-	}
+  ) {
+    return(false);
+  }
 
-	if (!zip_size && memcmp(read_buf + FIL_PAGE_LSN + 4,
-				read_buf + srv_page_size
-				- FIL_PAGE_END_LSN_OLD_CHKSUM + 4, 4)) {
+  if (!zip_size && memcmp(read_buf + FIL_PAGE_LSN + 4,
+        read_buf + srv_page_size
+        - FIL_PAGE_END_LSN_OLD_CHKSUM + 4, 4)) {
 
-		/* Stored log sequence numbers at the start and the end
-		of page do not match */
+    /* Stored log sequence numbers at the start and the end
+    of page do not match */
 
-		return(true);
-	}
+    return(true);
+  }
 
-	buf_page_check_lsn(check_lsn, read_buf);
+  buf_page_check_lsn(check_lsn, read_buf);
 
-	/* Check whether the checksum fields have correct values */
+  /* Check whether the checksum fields have correct values */
 
-	const srv_checksum_algorithm_t curr_algo =
-		static_cast<srv_checksum_algorithm_t>(srv_checksum_algorithm);
+  const srv_checksum_algorithm_t curr_algo =
+    static_cast<srv_checksum_algorithm_t>(srv_checksum_algorithm);
 
-	if (curr_algo == SRV_CHECKSUM_ALGORITHM_NONE) {
-		return(false);
-	}
+  if (curr_algo == SRV_CHECKSUM_ALGORITHM_NONE) {
+    return(false);
+  }
 
-	if (zip_size) {
-		return !page_zip_verify_checksum(read_buf, zip_size);
-	}
+  if (zip_size) {
+    return !page_zip_verify_checksum(read_buf, zip_size);
+  }
 
-	checksum_field1 = mach_read_from_4(
-		read_buf + FIL_PAGE_SPACE_OR_CHKSUM);
+  checksum_field1 = mach_read_from_4(
+    read_buf + FIL_PAGE_SPACE_OR_CHKSUM);
 
-	checksum_field2 = mach_read_from_4(
-		read_buf + srv_page_size - FIL_PAGE_END_LSN_OLD_CHKSUM);
+  checksum_field2 = mach_read_from_4(
+    read_buf + srv_page_size - FIL_PAGE_END_LSN_OLD_CHKSUM);
 
-	compile_time_assert(!(FIL_PAGE_LSN % 8));
+  compile_time_assert(!(FIL_PAGE_LSN % 8));
 
-	/* A page filled with NUL bytes is considered not corrupted.
-	The FIL_PAGE_FILE_FLUSH_LSN field may be written nonzero for
-	the first page of each file of the system tablespace.
-	We want to ignore it for the system tablespace, but because
-	we do not know the expected tablespace here, we ignore the
-	field for all data files, except for
-	innodb_checksum_algorithm=full_crc32 which we handled above. */
-	if (!checksum_field1 && !checksum_field2) {
-		/* Checksum fields can have valid value as zero.
-		If the page is not empty then do the checksum
-		calculation for the page. */
-		bool all_zeroes = true;
-		for (size_t i = 0; i < srv_page_size; i++) {
+  /* A page filled with NUL bytes is considered not corrupted.
+  The FIL_PAGE_FILE_FLUSH_LSN field may be written nonzero for
+  the first page of each file of the system tablespace.
+  We want to ignore it for the system tablespace, but because
+  we do not know the expected tablespace here, we ignore the
+  field for all data files, except for
+  innodb_checksum_algorithm=full_crc32 which we handled above. */
+  if (!checksum_field1 && !checksum_field2) {
+    /* Checksum fields can have valid value as zero.
+    If the page is not empty then do the checksum
+    calculation for the page. */
+    bool all_zeroes = true;
+    for (size_t i = 0; i < srv_page_size; i++) {
 #ifndef UNIV_INNOCHECKSUM
-			if (i == FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION) {
-				i += 8;
-			}
+      if (i == FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION) {
+        i += 8;
+      }
 #endif
-			if (read_buf[i]) {
-				all_zeroes = false;
-				break;
-			}
-		}
-
-		if (all_zeroes) {
-			return false;
-		}
-	}
-
-	switch (curr_algo) {
-	case SRV_CHECKSUM_ALGORITHM_STRICT_FULL_CRC32:
-	case SRV_CHECKSUM_ALGORITHM_STRICT_CRC32:
-		return !buf_page_is_checksum_valid_crc32(
-			read_buf, checksum_field1, checksum_field2);
-	case SRV_CHECKSUM_ALGORITHM_STRICT_INNODB:
-		return !buf_page_is_checksum_valid_innodb(
-			read_buf, checksum_field1, checksum_field2);
-	case SRV_CHECKSUM_ALGORITHM_STRICT_NONE:
-		return !buf_page_is_checksum_valid_none(
-			read_buf, checksum_field1, checksum_field2);
-	case SRV_CHECKSUM_ALGORITHM_FULL_CRC32:
-	case SRV_CHECKSUM_ALGORITHM_CRC32:
-	case SRV_CHECKSUM_ALGORITHM_INNODB:
-		if (buf_page_is_checksum_valid_none(read_buf,
-			checksum_field1, checksum_field2)) {
+      if (read_buf[i]) {
+        all_zeroes = false;
+        break;
+      }
+    }
+
+    if (all_zeroes) {
+      return false;
+    }
+  }
+
+  switch (curr_algo) {
+  case SRV_CHECKSUM_ALGORITHM_STRICT_FULL_CRC32:
+  case SRV_CHECKSUM_ALGORITHM_STRICT_CRC32:
+    return !buf_page_is_checksum_valid_crc32(
+      read_buf, checksum_field1, checksum_field2);
+  case SRV_CHECKSUM_ALGORITHM_STRICT_INNODB:
+    return !buf_page_is_checksum_valid_innodb(
+      read_buf, checksum_field1, checksum_field2);
+  case SRV_CHECKSUM_ALGORITHM_STRICT_NONE:
+    return !buf_page_is_checksum_valid_none(
+      read_buf, checksum_field1, checksum_field2);
+  case SRV_CHECKSUM_ALGORITHM_FULL_CRC32:
+  case SRV_CHECKSUM_ALGORITHM_CRC32:
+  case SRV_CHECKSUM_ALGORITHM_INNODB:
+    if (buf_page_is_checksum_valid_none(read_buf,
+      checksum_field1, checksum_field2)) {
 #ifdef UNIV_INNOCHECKSUM
-			if (log_file) {
-				fprintf(log_file, "page::%llu;"
-					" old style: calculated = %u;"
-					" recorded = " ULINTPF ";\n",
-					cur_page_num,
-					buf_calc_page_old_checksum(read_buf),
-					checksum_field2);
-				fprintf(log_file, "page::%llu;"
-					" new style: calculated = %u;"
-					" crc32 = %u; recorded = " ULINTPF ";\n",
-					cur_page_num,
-					buf_calc_page_new_checksum(read_buf),
-					buf_calc_page_crc32(read_buf),
-					checksum_field1);
-			}
+      if (log_file) {
+        fprintf(log_file, "page::%llu;"
+          " old style: calculated = %u;"
+          " recorded = " ULINTPF ";\n",
+          cur_page_num,
+          buf_calc_page_old_checksum(read_buf),
+          checksum_field2);
+        fprintf(log_file, "page::%llu;"
+          " new style: calculated = %u;"
+          " crc32 = %u; recorded = " ULINTPF ";\n",
+          cur_page_num,
+          buf_calc_page_new_checksum(read_buf),
+          buf_calc_page_crc32(read_buf),
+          checksum_field1);
+      }
 #endif /* UNIV_INNOCHECKSUM */
-			return false;
-		}
-
-		crc32_chksum = curr_algo == SRV_CHECKSUM_ALGORITHM_CRC32
-			|| curr_algo == SRV_CHECKSUM_ALGORITHM_FULL_CRC32;
-
-		/* Very old versions of InnoDB only stored 8 byte lsn to the
-		start and the end of the page. */
-
-		/* Since innodb_checksum_algorithm is not strict_* allow
-		any of the algos to match for the old field */
-
-		if (checksum_field2
-		    != mach_read_from_4(read_buf + FIL_PAGE_LSN)
-		    && checksum_field2 != BUF_NO_CHECKSUM_MAGIC) {
-
-			if (crc32_chksum) {
-				crc32 = buf_calc_page_crc32(read_buf);
-				crc32_inited = true;
-
-				DBUG_EXECUTE_IF(
-					"page_intermittent_checksum_mismatch", {
-					static int page_counter;
-					if (page_counter++ == 2) {
-						crc32++;
-					}
-				});
-
-				if (checksum_field2 != crc32
-				    && checksum_field2
-				       != buf_calc_page_old_checksum(read_buf)) {
-					return true;
-				}
-			} else {
-				ut_ad(curr_algo
-				      == SRV_CHECKSUM_ALGORITHM_INNODB);
-
-				if (checksum_field2
-				    != buf_calc_page_old_checksum(read_buf)) {
-					crc32 = buf_calc_page_crc32(read_buf);
-					crc32_inited = true;
-
-					if (checksum_field2 != crc32) {
-						return true;
-					}
-				}
-			}
-		}
-
-		if (checksum_field1 == 0
-		    || checksum_field1 == BUF_NO_CHECKSUM_MAGIC) {
-		} else if (crc32_chksum) {
-
-			if (!crc32_inited) {
-				crc32 = buf_calc_page_crc32(read_buf);
-				crc32_inited = true;
-			}
-
-			if (checksum_field1 != crc32
-			    && checksum_field1
-			    != buf_calc_page_new_checksum(read_buf)) {
-				return true;
-			}
-		} else {
-			ut_ad(curr_algo == SRV_CHECKSUM_ALGORITHM_INNODB);
-
-			if (checksum_field1
-			    != buf_calc_page_new_checksum(read_buf)) {
-
-				if (!crc32_inited) {
-					crc32 = buf_calc_page_crc32(read_buf);
-					crc32_inited = true;
-				}
-
-				if (checksum_field1 != crc32) {
-					return true;
-				}
-			}
-		}
-
-		if (crc32_inited
-		    && ((checksum_field1 == crc32
-			 && checksum_field2 != crc32)
-			|| (checksum_field1 != crc32
-			    && checksum_field2 == crc32))) {
-			return true;
-		}
-
-		break;
-	case SRV_CHECKSUM_ALGORITHM_NONE:
-		/* should have returned false earlier */
-		break;
-	}
-
-	return false;
+      return false;
+    }
+
+    crc32_chksum = curr_algo == SRV_CHECKSUM_ALGORITHM_CRC32
+      || curr_algo == SRV_CHECKSUM_ALGORITHM_FULL_CRC32;
+
+    /* Very old versions of InnoDB only stored 8 byte lsn to the
+    start and the end of the page. */
+
+    /* Since innodb_checksum_algorithm is not strict_* allow
+    any of the algos to match for the old field */
+
+    if (checksum_field2
+        != mach_read_from_4(read_buf + FIL_PAGE_LSN)
+        && checksum_field2 != BUF_NO_CHECKSUM_MAGIC) {
+
+      if (crc32_chksum) {
+        crc32 = buf_calc_page_crc32(read_buf);
+        crc32_inited = true;
+
+        DBUG_EXECUTE_IF(
+          "page_intermittent_checksum_mismatch", {
+          static int page_counter;
+          if (page_counter++ == 2) {
+            crc32++;
+          }
+        });
+
+        if (checksum_field2 != crc32
+            && checksum_field2
+               != buf_calc_page_old_checksum(read_buf)) {
+          return true;
+        }
+      } else {
+        ut_ad(curr_algo
+              == SRV_CHECKSUM_ALGORITHM_INNODB);
+
+        if (checksum_field2
+            != buf_calc_page_old_checksum(read_buf)) {
+          crc32 = buf_calc_page_crc32(read_buf);
+          crc32_inited = true;
+
+          if (checksum_field2 != crc32) {
+            return true;
+          }
+        }
+      }
+    }
+
+    if (checksum_field1 == 0
+        || checksum_field1 == BUF_NO_CHECKSUM_MAGIC) {
+    } else if (crc32_chksum) {
+
+      if (!crc32_inited) {
+        crc32 = buf_calc_page_crc32(read_buf);
+        crc32_inited = true;
+      }
+
+      if (checksum_field1 != crc32
+          && checksum_field1
+          != buf_calc_page_new_checksum(read_buf)) {
+        return true;
+      }
+    } else {
+      ut_ad(curr_algo == SRV_CHECKSUM_ALGORITHM_INNODB);
+
+      if (checksum_field1
+          != buf_calc_page_new_checksum(read_buf)) {
+
+        if (!crc32_inited) {
+          crc32 = buf_calc_page_crc32(read_buf);
+          crc32_inited = true;
+        }
+
+        if (checksum_field1 != crc32) {
+          return true;
+        }
+      }
+    }
+
+    if (crc32_inited
+        && ((checksum_field1 == crc32
+       && checksum_field2 != crc32)
+      || (checksum_field1 != crc32
+          && checksum_field2 == crc32))) {
+      return true;
+    }
+
+    break;
+  case SRV_CHECKSUM_ALGORITHM_NONE:
+    /* should have returned false earlier */
+    break;
+  }
+
+  return false;
 }
 
 #ifndef UNIV_INNOCHECKSUM
@@ -1289,40 +1289,40 @@ Returns number of errors found in madvise calls. */
 int
 buf_madvise_do_dump()
 {
-	int ret= 0;
-	buf_pool_t*	buf_pool;
-	buf_chunk_t*	chunk;
-
-	/* mirrors allocation in log_t::create() */
-	if (log_sys.buf) {
-		ret+= madvise(log_sys.first_in_use
-			      ? log_sys.buf
-			      : log_sys.buf - srv_log_buffer_size,
-			      srv_log_buffer_size * 2,
-			      MADV_DODUMP);
-	}
-	/* mirrors recv_sys_t::create() */
-	if (recv_sys.buf)
-	{
-		ret+= madvise(recv_sys.buf, recv_sys.len, MADV_DODUMP);
-	}
-
-	buf_pool_mutex_enter_all();
-
-	for (ulong i= 0; i < srv_buf_pool_instances; i++)
-	{
-		buf_pool = buf_pool_from_array(i);
-		chunk = buf_pool->chunks;
-
-		for (int n = buf_pool->n_chunks; n--; chunk++)
-		{
-			ret+= madvise(chunk->mem, chunk->mem_size(), MADV_DODUMP);
-		}
-	}
-
-	buf_pool_mutex_exit_all();
-
-	return ret;
+  int ret= 0;
+  buf_pool_t*	buf_pool;
+  buf_chunk_t*	chunk;
+
+  /* mirrors allocation in log_t::create() */
+  if (log_sys.buf) {
+    ret+= madvise(log_sys.first_in_use
+            ? log_sys.buf
+            : log_sys.buf - srv_log_buffer_size,
+            srv_log_buffer_size * 2,
+            MADV_DODUMP);
+  }
+  /* mirrors recv_sys_t::create() */
+  if (recv_sys.buf)
+  {
+    ret+= madvise(recv_sys.buf, recv_sys.len, MADV_DODUMP);
+  }
+
+  buf_pool_mutex_enter_all();
+
+  for (ulong i= 0; i < srv_buf_pool_instances; i++)
+  {
+    buf_pool = buf_pool_from_array(i);
+    chunk = buf_pool->chunks;
+
+    for (int n = buf_pool->n_chunks; n--; chunk++)
+    {
+      ret+= madvise(chunk->mem, chunk->mem_size(), MADV_DODUMP);
+    }
+  }
+
+  buf_pool_mutex_exit_all();
+
+  return ret;
 }
 #endif
 
@@ -1331,166 +1331,166 @@ buf_madvise_do_dump()
 @param[in]	zip_size	compressed page size, or 0 */
 void buf_page_print(const byte* read_buf, ulint zip_size)
 {
-	dict_index_t*	index;
+  dict_index_t*	index;
 
 #ifndef UNIV_DEBUG
-	const ulint size = zip_size ? zip_size : srv_page_size;
-	ib::info() << "Page dump in ascii and hex ("
-		<< size << " bytes):";
+  const ulint size = zip_size ? zip_size : srv_page_size;
+  ib::info() << "Page dump in ascii and hex ("
+    << size << " bytes):";
 
-	ut_print_buf(stderr, read_buf, size);
-	fputs("\nInnoDB: End of page dump\n", stderr);
+  ut_print_buf(stderr, read_buf, size);
+  fputs("\nInnoDB: End of page dump\n", stderr);
 #endif
 
-	if (zip_size) {
-		/* Print compressed page. */
-		ib::info() << "Compressed page type ("
-			<< fil_page_get_type(read_buf)
-			<< "); stored checksum in field1 "
-			<< mach_read_from_4(
-				read_buf + FIL_PAGE_SPACE_OR_CHKSUM)
-			<< "; calculated checksums for field1: "
-			<< buf_checksum_algorithm_name(
-				SRV_CHECKSUM_ALGORITHM_CRC32)
-			<< " "
-			<< page_zip_calc_checksum(
-				read_buf, zip_size,
-				SRV_CHECKSUM_ALGORITHM_CRC32)
-			<< ", "
-			<< buf_checksum_algorithm_name(
-				SRV_CHECKSUM_ALGORITHM_INNODB)
-			<< " "
-			<< page_zip_calc_checksum(
-				read_buf, zip_size,
-				SRV_CHECKSUM_ALGORITHM_INNODB)
-			<< ", "
-			<< buf_checksum_algorithm_name(
-				SRV_CHECKSUM_ALGORITHM_NONE)
-			<< " "
-			<< page_zip_calc_checksum(
-				read_buf, zip_size,
-				SRV_CHECKSUM_ALGORITHM_NONE)
-			<< "; page LSN "
-			<< mach_read_from_8(read_buf + FIL_PAGE_LSN)
-			<< "; page number (if stored to page"
-			<< " already) "
-			<< mach_read_from_4(read_buf + FIL_PAGE_OFFSET)
-			<< "; space id (if stored to page already) "
-			<< mach_read_from_4(
-				read_buf + FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID);
-
-	} else {
-		const uint32_t	crc32 = buf_calc_page_crc32(read_buf);
-		ulint page_type = fil_page_get_type(read_buf);
-
-		ib::info() << "Uncompressed page, stored checksum in field1 "
-			<< mach_read_from_4(
-				read_buf + FIL_PAGE_SPACE_OR_CHKSUM)
-			<< ", calculated checksums for field1: "
-			<< buf_checksum_algorithm_name(
-				SRV_CHECKSUM_ALGORITHM_CRC32) << " "
-			<< crc32
-			<< ", "
-			<< buf_checksum_algorithm_name(
-				SRV_CHECKSUM_ALGORITHM_INNODB) << " "
-			<< buf_calc_page_new_checksum(read_buf)
-			<< ", "
-			<< " page type " << page_type << " == "
-			<< fil_get_page_type_name(page_type) << "."
-			<< buf_checksum_algorithm_name(
-				SRV_CHECKSUM_ALGORITHM_NONE) << " "
-			<< BUF_NO_CHECKSUM_MAGIC
-			<< ", stored checksum in field2 "
-			<< mach_read_from_4(read_buf + srv_page_size
-					    - FIL_PAGE_END_LSN_OLD_CHKSUM)
-			<< ", calculated checksums for field2: "
-			<< buf_checksum_algorithm_name(
-				SRV_CHECKSUM_ALGORITHM_CRC32) << " "
-			<< crc32
-			<< ", "
-			<< buf_checksum_algorithm_name(
-				SRV_CHECKSUM_ALGORITHM_INNODB) << " "
-			<< buf_calc_page_old_checksum(read_buf)
-			<< ", "
-			<< buf_checksum_algorithm_name(
-				SRV_CHECKSUM_ALGORITHM_NONE) << " "
-			<< BUF_NO_CHECKSUM_MAGIC
-			<< ",  page LSN "
-			<< mach_read_from_4(read_buf + FIL_PAGE_LSN)
-			<< " "
-			<< mach_read_from_4(read_buf + FIL_PAGE_LSN + 4)
-			<< ", low 4 bytes of LSN at page end "
-			<< mach_read_from_4(read_buf + srv_page_size
-					    - FIL_PAGE_END_LSN_OLD_CHKSUM + 4)
-			<< ", page number (if stored to page already) "
-			<< mach_read_from_4(read_buf + FIL_PAGE_OFFSET)
-			<< ", space id (if created with >= MySQL-4.1.1"
-			   " and stored already) "
-			<< mach_read_from_4(
-				read_buf + FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID);
-	}
-
-	switch (fil_page_get_type(read_buf)) {
-		index_id_t	index_id;
-	case FIL_PAGE_INDEX:
-	case FIL_PAGE_TYPE_INSTANT:
-	case FIL_PAGE_RTREE:
-		index_id = btr_page_get_index_id(read_buf);
-		ib::info() << "Page may be an index page where"
-			" index id is " << index_id;
-
-		index = dict_index_find_on_id_low(index_id);
-		if (index) {
-			ib::info()
-				<< "Index " << index_id
-				<< " is " << index->name
-				<< " in table " << index->table->name;
-		}
-		break;
-	case FIL_PAGE_UNDO_LOG:
-		fputs("InnoDB: Page may be an undo log page\n", stderr);
-		break;
-	case FIL_PAGE_INODE:
-		fputs("InnoDB: Page may be an 'inode' page\n", stderr);
-		break;
-	case FIL_PAGE_IBUF_FREE_LIST:
-		fputs("InnoDB: Page may be an insert buffer free list page\n",
-		      stderr);
-		break;
-	case FIL_PAGE_TYPE_ALLOCATED:
-		fputs("InnoDB: Page may be a freshly allocated page\n",
-		      stderr);
-		break;
-	case FIL_PAGE_IBUF_BITMAP:
-		fputs("InnoDB: Page may be an insert buffer bitmap page\n",
-		      stderr);
-		break;
-	case FIL_PAGE_TYPE_SYS:
-		fputs("InnoDB: Page may be a system page\n",
-		      stderr);
-		break;
-	case FIL_PAGE_TYPE_TRX_SYS:
-		fputs("InnoDB: Page may be a transaction system page\n",
-		      stderr);
-		break;
-	case FIL_PAGE_TYPE_FSP_HDR:
-		fputs("InnoDB: Page may be a file space header page\n",
-		      stderr);
-		break;
-	case FIL_PAGE_TYPE_XDES:
-		fputs("InnoDB: Page may be an extent descriptor page\n",
-		      stderr);
-		break;
-	case FIL_PAGE_TYPE_BLOB:
-		fputs("InnoDB: Page may be a BLOB page\n",
-		      stderr);
-		break;
-	case FIL_PAGE_TYPE_ZBLOB:
-	case FIL_PAGE_TYPE_ZBLOB2:
-		fputs("InnoDB: Page may be a compressed BLOB page\n",
-		      stderr);
-		break;
-	}
+  if (zip_size) {
+    /* Print compressed page. */
+    ib::info() << "Compressed page type ("
+      << fil_page_get_type(read_buf)
+      << "); stored checksum in field1 "
+      << mach_read_from_4(
+        read_buf + FIL_PAGE_SPACE_OR_CHKSUM)
+      << "; calculated checksums for field1: "
+      << buf_checksum_algorithm_name(
+        SRV_CHECKSUM_ALGORITHM_CRC32)
+      << " "
+      << page_zip_calc_checksum(
+        read_buf, zip_size,
+        SRV_CHECKSUM_ALGORITHM_CRC32)
+      << ", "
+      << buf_checksum_algorithm_name(
+        SRV_CHECKSUM_ALGORITHM_INNODB)
+      << " "
+      << page_zip_calc_checksum(
+        read_buf, zip_size,
+        SRV_CHECKSUM_ALGORITHM_INNODB)
+      << ", "
+      << buf_checksum_algorithm_name(
+        SRV_CHECKSUM_ALGORITHM_NONE)
+      << " "
+      << page_zip_calc_checksum(
+        read_buf, zip_size,
+        SRV_CHECKSUM_ALGORITHM_NONE)
+      << "; page LSN "
+      << mach_read_from_8(read_buf + FIL_PAGE_LSN)
+      << "; page number (if stored to page"
+      << " already) "
+      << mach_read_from_4(read_buf + FIL_PAGE_OFFSET)
+      << "; space id (if stored to page already) "
+      << mach_read_from_4(
+        read_buf + FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID);
+
+  } else {
+    const uint32_t	crc32 = buf_calc_page_crc32(read_buf);
+    ulint page_type = fil_page_get_type(read_buf);
+
+    ib::info() << "Uncompressed page, stored checksum in field1 "
+      << mach_read_from_4(
+        read_buf + FIL_PAGE_SPACE_OR_CHKSUM)
+      << ", calculated checksums for field1: "
+      << buf_checksum_algorithm_name(
+        SRV_CHECKSUM_ALGORITHM_CRC32) << " "
+      << crc32
+      << ", "
+      << buf_checksum_algorithm_name(
+        SRV_CHECKSUM_ALGORITHM_INNODB) << " "
+      << buf_calc_page_new_checksum(read_buf)
+      << ", "
+      << " page type " << page_type << " == "
+      << fil_get_page_type_name(page_type) << "."
+      << buf_checksum_algorithm_name(
+        SRV_CHECKSUM_ALGORITHM_NONE) << " "
+      << BUF_NO_CHECKSUM_MAGIC
+      << ", stored checksum in field2 "
+      << mach_read_from_4(read_buf + srv_page_size
+              - FIL_PAGE_END_LSN_OLD_CHKSUM)
+      << ", calculated checksums for field2: "
+      << buf_checksum_algorithm_name(
+        SRV_CHECKSUM_ALGORITHM_CRC32) << " "
+      << crc32
+      << ", "
+      << buf_checksum_algorithm_name(
+        SRV_CHECKSUM_ALGORITHM_INNODB) << " "
+      << buf_calc_page_old_checksum(read_buf)
+      << ", "
+      << buf_checksum_algorithm_name(
+        SRV_CHECKSUM_ALGORITHM_NONE) << " "
+      << BUF_NO_CHECKSUM_MAGIC
+      << ",  page LSN "
+      << mach_read_from_4(read_buf + FIL_PAGE_LSN)
+      << " "
+      << mach_read_from_4(read_buf + FIL_PAGE_LSN + 4)
+      << ", low 4 bytes of LSN at page end "
+      << mach_read_from_4(read_buf + srv_page_size
+              - FIL_PAGE_END_LSN_OLD_CHKSUM + 4)
+      << ", page number (if stored to page already) "
+      << mach_read_from_4(read_buf + FIL_PAGE_OFFSET)
+      << ", space id (if created with >= MySQL-4.1.1"
+         " and stored already) "
+      << mach_read_from_4(
+        read_buf + FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID);
+  }
+
+  switch (fil_page_get_type(read_buf)) {
+    index_id_t	index_id;
+  case FIL_PAGE_INDEX:
+  case FIL_PAGE_TYPE_INSTANT:
+  case FIL_PAGE_RTREE:
+    index_id = btr_page_get_index_id(read_buf);
+    ib::info() << "Page may be an index page where"
+      " index id is " << index_id;
+
+    index = dict_index_find_on_id_low(index_id);
+    if (index) {
+      ib::info()
+        << "Index " << index_id
+        << " is " << index->name
+        << " in table " << index->table->name;
+    }
+    break;
+  case FIL_PAGE_UNDO_LOG:
+    fputs("InnoDB: Page may be an undo log page\n", stderr);
+    break;
+  case FIL_PAGE_INODE:
+    fputs("InnoDB: Page may be an 'inode' page\n", stderr);
+    break;
+  case FIL_PAGE_IBUF_FREE_LIST:
+    fputs("InnoDB: Page may be an insert buffer free list page\n",
+          stderr);
+    break;
+  case FIL_PAGE_TYPE_ALLOCATED:
+    fputs("InnoDB: Page may be a freshly allocated page\n",
+          stderr);
+    break;
+  case FIL_PAGE_IBUF_BITMAP:
+    fputs("InnoDB: Page may be an insert buffer bitmap page\n",
+          stderr);
+    break;
+  case FIL_PAGE_TYPE_SYS:
+    fputs("InnoDB: Page may be a system page\n",
+          stderr);
+    break;
+  case FIL_PAGE_TYPE_TRX_SYS:
+    fputs("InnoDB: Page may be a transaction system page\n",
+          stderr);
+    break;
+  case FIL_PAGE_TYPE_FSP_HDR:
+    fputs("InnoDB: Page may be a file space header page\n",
+          stderr);
+    break;
+  case FIL_PAGE_TYPE_XDES:
+    fputs("InnoDB: Page may be an extent descriptor page\n",
+          stderr);
+    break;
+  case FIL_PAGE_TYPE_BLOB:
+    fputs("InnoDB: Page may be a BLOB page\n",
+          stderr);
+    break;
+  case FIL_PAGE_TYPE_ZBLOB:
+  case FIL_PAGE_TYPE_ZBLOB2:
+    fputs("InnoDB: Page may be a compressed BLOB page\n",
+          stderr);
+    break;
+  }
 }
 
 # ifdef PFS_GROUP_BUFFER_SYNC
@@ -1506,45 +1506,45 @@ static
 void
 pfs_register_buffer_block(
 /*======================*/
-	buf_chunk_t*	chunk)		/*!< in/out: chunk of buffers */
+  buf_chunk_t*	chunk)		/*!< in/out: chunk of buffers */
 {
-	buf_block_t*    block;
-	ulint		num_to_register;
+  buf_block_t*    block;
+  ulint		num_to_register;
 
-	block = chunk->blocks;
+  block = chunk->blocks;
 
-	num_to_register = ut_min(
-		chunk->size, PFS_MAX_BUFFER_MUTEX_LOCK_REGISTER);
+  num_to_register = ut_min(
+    chunk->size, PFS_MAX_BUFFER_MUTEX_LOCK_REGISTER);
 
-	for (ulint i = 0; i < num_to_register; i++) {
+  for (ulint i = 0; i < num_to_register; i++) {
 #  ifdef UNIV_PFS_MUTEX
-		BPageMutex*	mutex;
+    BPageMutex*	mutex;
 
-		mutex = &block->mutex;
-		mutex->pfs_add(buffer_block_mutex_key);
+    mutex = &block->mutex;
+    mutex->pfs_add(buffer_block_mutex_key);
 #  endif /* UNIV_PFS_MUTEX */
 
-		rw_lock_t*	rwlock;
+    rw_lock_t*	rwlock;
 
 #  ifdef UNIV_PFS_RWLOCK
-		rwlock = &block->lock;
-		ut_a(!rwlock->pfs_psi);
-		rwlock->pfs_psi = (PSI_server)
-			? PSI_server->init_rwlock(buf_block_lock_key, rwlock)
-			: NULL;
+    rwlock = &block->lock;
+    ut_a(!rwlock->pfs_psi);
+    rwlock->pfs_psi = (PSI_server)
+      ? PSI_server->init_rwlock(buf_block_lock_key, rwlock)
+      : NULL;
 
 #   ifdef UNIV_DEBUG
-		rwlock = block->debug_latch;
-		ut_a(!rwlock->pfs_psi);
-		rwlock->pfs_psi = (PSI_server)
-			? PSI_server->init_rwlock(buf_block_debug_latch_key,
-						  rwlock)
-			: NULL;
+    rwlock = block->debug_latch;
+    ut_a(!rwlock->pfs_psi);
+    rwlock->pfs_psi = (PSI_server)
+      ? PSI_server->init_rwlock(buf_block_debug_latch_key,
+              rwlock)
+      : NULL;
 #   endif /* UNIV_DEBUG */
 
 #  endif /* UNIV_PFS_RWLOCK */
-		block++;
-	}
+    block++;
+  }
 }
 # endif /* PFS_GROUP_BUFFER_SYNC */
 
@@ -1554,75 +1554,75 @@ static
 void
 buf_block_init(
 /*===========*/
-	buf_pool_t*	buf_pool,	/*!< in: buffer pool instance */
-	buf_block_t*	block,		/*!< in: pointer to control block */
-	byte*		frame)		/*!< in: pointer to buffer frame */
+  buf_pool_t*	buf_pool,	/*!< in: buffer pool instance */
+  buf_block_t*	block,		/*!< in: pointer to control block */
+  byte*		frame)		/*!< in: pointer to buffer frame */
 {
-	UNIV_MEM_DESC(frame, srv_page_size);
+  UNIV_MEM_DESC(frame, srv_page_size);
 
-	/* This function should only be executed at database startup or by
-	buf_pool_resize(). Either way, adaptive hash index must not exist. */
-	assert_block_ahi_empty_on_init(block);
+  /* This function should only be executed at database startup or by
+  buf_pool_resize(). Either way, adaptive hash index must not exist. */
+  assert_block_ahi_empty_on_init(block);
 
-	block->frame = frame;
+  block->frame = frame;
 
-	block->page.buf_pool_index = buf_pool_index(buf_pool);
-	block->page.flush_type = BUF_FLUSH_LRU;
-	block->page.state = BUF_BLOCK_NOT_USED;
-	block->page.buf_fix_count = 0;
-	block->page.io_fix = BUF_IO_NONE;
-	block->page.flush_observer = NULL;
-	block->page.init_on_flush = false;
-	block->page.real_size = 0;
-	block->page.write_size = 0;
-	block->modify_clock = 0;
-	block->page.slot = NULL;
+  block->page.buf_pool_index = buf_pool_index(buf_pool);
+  block->page.flush_type = BUF_FLUSH_LRU;
+  block->page.state = BUF_BLOCK_NOT_USED;
+  block->page.buf_fix_count = 0;
+  block->page.io_fix = BUF_IO_NONE;
+  block->page.flush_observer = NULL;
+  block->page.init_on_flush = false;
+  block->page.real_size = 0;
+  block->page.write_size = 0;
+  block->modify_clock = 0;
+  block->page.slot = NULL;
 
-	ut_d(block->page.file_page_was_freed = FALSE);
+  ut_d(block->page.file_page_was_freed = FALSE);
 
 #ifdef BTR_CUR_HASH_ADAPT
-	block->index = NULL;
+  block->index = NULL;
 #endif /* BTR_CUR_HASH_ADAPT */
-	block->skip_flush_check = false;
+  block->skip_flush_check = false;
 
-	ut_d(block->page.in_page_hash = FALSE);
-	ut_d(block->page.in_zip_hash = FALSE);
-	ut_d(block->page.in_flush_list = FALSE);
-	ut_d(block->page.in_free_list = FALSE);
-	ut_d(block->page.in_LRU_list = FALSE);
-	ut_d(block->in_unzip_LRU_list = FALSE);
-	ut_d(block->in_withdraw_list = FALSE);
+  ut_d(block->page.in_page_hash = FALSE);
+  ut_d(block->page.in_zip_hash = FALSE);
+  ut_d(block->page.in_flush_list = FALSE);
+  ut_d(block->page.in_free_list = FALSE);
+  ut_d(block->page.in_LRU_list = FALSE);
+  ut_d(block->in_unzip_LRU_list = FALSE);
+  ut_d(block->in_withdraw_list = FALSE);
 
-	page_zip_des_init(&block->page.zip);
+  page_zip_des_init(&block->page.zip);
 
-	mutex_create(LATCH_ID_BUF_BLOCK_MUTEX, &block->mutex);
-	ut_d(block->debug_latch = (rw_lock_t *) ut_malloc_nokey(sizeof(rw_lock_t)));
+  mutex_create(LATCH_ID_BUF_BLOCK_MUTEX, &block->mutex);
+  ut_d(block->debug_latch = (rw_lock_t *) ut_malloc_nokey(sizeof(rw_lock_t)));
 
 #if defined PFS_SKIP_BUFFER_MUTEX_RWLOCK || defined PFS_GROUP_BUFFER_SYNC
-	/* If PFS_SKIP_BUFFER_MUTEX_RWLOCK is defined, skip registration
-	of buffer block rwlock with performance schema.
+  /* If PFS_SKIP_BUFFER_MUTEX_RWLOCK is defined, skip registration
+  of buffer block rwlock with performance schema.
 
-	If PFS_GROUP_BUFFER_SYNC is defined, skip the registration
-	since buffer block rwlock will be registered later in
-	pfs_register_buffer_block(). */
+  If PFS_GROUP_BUFFER_SYNC is defined, skip the registration
+  since buffer block rwlock will be registered later in
+  pfs_register_buffer_block(). */
 
-	rw_lock_create(PFS_NOT_INSTRUMENTED, &block->lock, SYNC_LEVEL_VARYING);
+  rw_lock_create(PFS_NOT_INSTRUMENTED, &block->lock, SYNC_LEVEL_VARYING);
 
-	ut_d(rw_lock_create(PFS_NOT_INSTRUMENTED, block->debug_latch,
-			    SYNC_LEVEL_VARYING));
+  ut_d(rw_lock_create(PFS_NOT_INSTRUMENTED, block->debug_latch,
+          SYNC_LEVEL_VARYING));
 
 #else /* PFS_SKIP_BUFFER_MUTEX_RWLOCK || PFS_GROUP_BUFFER_SYNC */
 
-	rw_lock_create(buf_block_lock_key, &block->lock, SYNC_LEVEL_VARYING);
+  rw_lock_create(buf_block_lock_key, &block->lock, SYNC_LEVEL_VARYING);
 
-	ut_d(rw_lock_create(buf_block_debug_latch_key,
-			    block->debug_latch, SYNC_LEVEL_VARYING));
+  ut_d(rw_lock_create(buf_block_debug_latch_key,
+          block->debug_latch, SYNC_LEVEL_VARYING));
 
 #endif /* PFS_SKIP_BUFFER_MUTEX_RWLOCK || PFS_GROUP_BUFFER_SYNC */
 
-	block->lock.is_block_lock = 1;
+  block->lock.is_block_lock = 1;
 
-	ut_ad(rw_lock_validate(&(block->lock)));
+  ut_ad(rw_lock_validate(&(block->lock)));
 }
 
 /********************************************************************//**
@@ -1632,96 +1632,101 @@ static
 buf_chunk_t*
 buf_chunk_init(
 /*===========*/
-	buf_pool_t*	buf_pool,	/*!< in: buffer pool instance */
-	buf_chunk_t*	chunk,		/*!< out: chunk of buffers */
-	ulint		mem_size)	/*!< in: requested size in bytes */
+  buf_pool_t*  buf_pool,            /*!< in: buffer pool instance */
+  buf_chunk_t* chunk,               /*!< out: chunk of buffers */
+  ulint	       mem_size,            /*!< in: requested size in bytes */
+  bool         is_parallel = false) /*!< in: if true, get mutex to append free list */
 {
-	buf_block_t*	block;
-	byte*		frame;
-	ulint		i;
+  buf_block_t*	block;
+  byte*		frame;
+  ulint		i;
 
-	/* Round down to a multiple of page size,
-	although it already should be. */
-	mem_size = ut_2pow_round<ulint>(mem_size, srv_page_size);
+  /* Round down to a multiple of page size,
+  although it already should be. */
+  mem_size = ut_2pow_round<ulint>(mem_size, srv_page_size);
 
-	DBUG_EXECUTE_IF("ib_buf_chunk_init_fails", return(NULL););
+  DBUG_EXECUTE_IF("ib_buf_chunk_init_fails", return(NULL););
 
-	chunk->mem = buf_pool->allocator.allocate_large_dontdump(mem_size, &chunk->mem_pfx);
+  chunk->mem = buf_pool->allocator.allocate_large_dontdump(mem_size, &chunk->mem_pfx);
 
-	if (UNIV_UNLIKELY(chunk->mem == NULL)) {
+  if (UNIV_UNLIKELY(chunk->mem == NULL)) {
 
-		return(NULL);
-	}
+    return(NULL);
+  }
 
 #ifdef HAVE_LIBNUMA
-	if (srv_numa_interleave) {
-		struct bitmask *numa_mems_allowed = numa_get_mems_allowed();
-		int	st = mbind(chunk->mem, chunk->mem_size(),
-				   MPOL_INTERLEAVE,
-				   numa_mems_allowed->maskp,
-				   numa_mems_allowed->size,
-				   MPOL_MF_MOVE);
-		if (st != 0) {
-			ib::warn() << "Failed to set NUMA memory policy of"
-				" buffer pool page frames to MPOL_INTERLEAVE"
-				" (error: " << strerror(errno) << ").";
-		}
-	}
+  if (srv_numa_interleave) {
+    struct bitmask *numa_mems_allowed = numa_get_mems_allowed();
+    int	st = mbind(chunk->mem, chunk->mem_size(),
+           MPOL_INTERLEAVE,
+           numa_mems_allowed->maskp,
+           numa_mems_allowed->size,
+           MPOL_MF_MOVE);
+    if (st != 0) {
+      ib::warn() << "Failed to set NUMA memory policy of"
+        " buffer pool page frames to MPOL_INTERLEAVE"
+        " (error: " << strerror(errno) << ").";
+    }
+  }
 #endif /* HAVE_LIBNUMA */
 
 
-	/* Allocate the block descriptors from
-	the start of the memory block. */
-	chunk->blocks = (buf_block_t*) chunk->mem;
+  /* Allocate the block descriptors from
+  the start of the memory block. */
+  chunk->blocks = (buf_block_t*) chunk->mem;
 
-	/* Align a pointer to the first frame.  Note that when
-	opt_large_page_size is smaller than srv_page_size,
-	we may allocate one fewer block than requested.  When
-	it is bigger, we may allocate more blocks than requested. */
+  /* Align a pointer to the first frame.  Note that when
+  opt_large_page_size is smaller than srv_page_size,
+  we may allocate one fewer block than requested.  When
+  it is bigger, we may allocate more blocks than requested. */
 
-	frame = (byte*) ut_align(chunk->mem, srv_page_size);
-	chunk->size = (chunk->mem_pfx.m_size >> srv_page_size_shift)
-		- (frame != chunk->mem);
+  frame = (byte*) ut_align(chunk->mem, srv_page_size);
+  chunk->size = (chunk->mem_pfx.m_size >> srv_page_size_shift)
+    - (frame != chunk->mem);
 
-	/* Subtract the space needed for block descriptors. */
-	{
-		ulint	size = chunk->size;
+  /* Subtract the space needed for block descriptors. */
+  {
+    ulint	size = chunk->size;
 
-		while (frame < (byte*) (chunk->blocks + size)) {
-			frame += srv_page_size;
-			size--;
-		}
+    while (frame < (byte*) (chunk->blocks + size)) {
+      frame += srv_page_size;
+      size--;
+    }
 
-		chunk->size = size;
-	}
+    chunk->size = size;
+  }
 
-	/* Init block structs and assign frames for them. Then we
-	assign the frames to the first blocks (we already mapped the
-	memory above). */
+  /* Init block structs and assign frames for them. Then we
+  assign the frames to the first blocks (we already mapped the
+  memory above). */
 
-	block = chunk->blocks;
+  block = chunk->blocks;
 
-	for (i = chunk->size; i--; ) {
+  for (i = chunk->size; i--; ) {
 
-		buf_block_init(buf_pool, block, frame);
-		UNIV_MEM_INVALID(block->frame, srv_page_size);
+    buf_block_init(buf_pool, block, frame);
+    UNIV_MEM_INVALID(block->frame, srv_page_size);
 
-		/* Add the block to the free list */
-		UT_LIST_ADD_LAST(buf_pool->free, &block->page);
+    if (is_parallel)
+      buf_pool_mutex_enter(buf_pool);
+    /* Add the block to the free list */
+    UT_LIST_ADD_LAST(buf_pool->free, &block->page);
+    if (is_parallel)
+      buf_pool_mutex_exit(buf_pool);
 
-		ut_d(block->page.in_free_list = TRUE);
-		ut_ad(buf_pool_from_block(block) == buf_pool);
+    ut_d(block->page.in_free_list = TRUE);
+    ut_ad(buf_pool_from_block(block) == buf_pool);
 
-		block++;
-		frame += srv_page_size;
-	}
+    block++;
+    frame += srv_page_size;
+  }
 
-	buf_pool_register_chunk(chunk);
+  buf_pool_register_chunk(chunk);
 
 #ifdef PFS_GROUP_BUFFER_SYNC
-	pfs_register_buffer_block(chunk);
+  pfs_register_buffer_block(chunk);
 #endif /* PFS_GROUP_BUFFER_SYNC */
-	return(chunk);
+  return(chunk);
 }
 
 #ifdef UNIV_DEBUG
@@ -1733,22 +1738,22 @@ static
 buf_block_t*
 buf_chunk_contains_zip(
 /*===================*/
-	buf_chunk_t*	chunk,	/*!< in: chunk being checked */
-	const void*	data)	/*!< in: pointer to compressed page */
+  buf_chunk_t*	chunk,	/*!< in: chunk being checked */
+  const void*	data)	/*!< in: pointer to compressed page */
 {
-	buf_block_t*	block;
-	ulint		i;
+  buf_block_t*	block;
+  ulint		i;
 
-	block = chunk->blocks;
+  block = chunk->blocks;
 
-	for (i = chunk->size; i--; block++) {
-		if (block->page.zip.data == data) {
+  for (i = chunk->size; i--; block++) {
+    if (block->page.zip.data == data) {
 
-			return(block);
-		}
-	}
+      return(block);
+    }
+  }
 
-	return(NULL);
+  return(NULL);
 }
 
 /*********************************************************************//**
@@ -1758,24 +1763,24 @@ given compressed page.
 buf_block_t*
 buf_pool_contains_zip(
 /*==================*/
-	buf_pool_t*	buf_pool,	/*!< in: buffer pool instance */
-	const void*	data)		/*!< in: pointer to compressed page */
+  buf_pool_t*	buf_pool,	/*!< in: buffer pool instance */
+  const void*	data)		/*!< in: pointer to compressed page */
 {
-	ulint		n;
-	buf_chunk_t*	chunk = buf_pool->chunks;
+  ulint		n;
+  buf_chunk_t*	chunk = buf_pool->chunks;
 
-	ut_ad(buf_pool);
-	ut_ad(buf_pool_mutex_own(buf_pool));
-	for (n = buf_pool->n_chunks; n--; chunk++) {
+  ut_ad(buf_pool);
+  ut_ad(buf_pool_mutex_own(buf_pool));
+  for (n = buf_pool->n_chunks; n--; chunk++) {
 
-		buf_block_t* block = buf_chunk_contains_zip(chunk, data);
+    buf_block_t* block = buf_chunk_contains_zip(chunk, data);
 
-		if (block) {
-			return(block);
-		}
-	}
+    if (block) {
+      return(block);
+    }
+  }
 
-	return(NULL);
+  return(NULL);
 }
 #endif /* UNIV_DEBUG */
 
@@ -1786,61 +1791,61 @@ static
 const buf_block_t*
 buf_chunk_not_freed(
 /*================*/
-	buf_chunk_t*	chunk)	/*!< in: chunk being checked */
+  buf_chunk_t*	chunk)	/*!< in: chunk being checked */
 {
-	buf_block_t*	block;
-	ulint		i;
-
-	block = chunk->blocks;
-
-	for (i = chunk->size; i--; block++) {
-		ibool	ready;
-
-		switch (buf_block_get_state(block)) {
-		case BUF_BLOCK_POOL_WATCH:
-		case BUF_BLOCK_ZIP_PAGE:
-		case BUF_BLOCK_ZIP_DIRTY:
-			/* The uncompressed buffer pool should never
-			contain compressed block descriptors. */
-			ut_error;
-			break;
-		case BUF_BLOCK_NOT_USED:
-		case BUF_BLOCK_READY_FOR_USE:
-		case BUF_BLOCK_MEMORY:
-		case BUF_BLOCK_REMOVE_HASH:
-			/* Skip blocks that are not being used for
-			file pages. */
-			break;
-		case BUF_BLOCK_FILE_PAGE:
-			if (srv_read_only_mode) {
-				/* The page cleaner is disabled in
-				read-only mode.  No pages can be
-				dirtied, so all of them must be clean. */
-				ut_ad(block->page.oldest_modification
-				      == block->page.newest_modification);
-				ut_ad(block->page.oldest_modification == 0
-				      || block->page.oldest_modification
-				      == recv_sys.recovered_lsn
-				      || srv_force_recovery
-				      == SRV_FORCE_NO_LOG_REDO);
-				ut_ad(block->page.buf_fix_count == 0);
-				ut_ad(block->page.io_fix == BUF_IO_NONE);
-				break;
-			}
-
-			buf_page_mutex_enter(block);
-			ready = buf_flush_ready_for_replace(&block->page);
-			buf_page_mutex_exit(block);
-
-			if (!ready) {
-				return(block);
-			}
-
-			break;
-		}
-	}
-
-	return(NULL);
+  buf_block_t*	block;
+  ulint		i;
+
+  block = chunk->blocks;
+
+  for (i = chunk->size; i--; block++) {
+    ibool	ready;
+
+    switch (buf_block_get_state(block)) {
+    case BUF_BLOCK_POOL_WATCH:
+    case BUF_BLOCK_ZIP_PAGE:
+    case BUF_BLOCK_ZIP_DIRTY:
+      /* The uncompressed buffer pool should never
+      contain compressed block descriptors. */
+      ut_error;
+      break;
+    case BUF_BLOCK_NOT_USED:
+    case BUF_BLOCK_READY_FOR_USE:
+    case BUF_BLOCK_MEMORY:
+    case BUF_BLOCK_REMOVE_HASH:
+      /* Skip blocks that are not being used for
+      file pages. */
+      break;
+    case BUF_BLOCK_FILE_PAGE:
+      if (srv_read_only_mode) {
+        /* The page cleaner is disabled in
+        read-only mode.  No pages can be
+        dirtied, so all of them must be clean. */
+        ut_ad(block->page.oldest_modification
+              == block->page.newest_modification);
+        ut_ad(block->page.oldest_modification == 0
+              || block->page.oldest_modification
+              == recv_sys.recovered_lsn
+              || srv_force_recovery
+              == SRV_FORCE_NO_LOG_REDO);
+        ut_ad(block->page.buf_fix_count == 0);
+        ut_ad(block->page.io_fix == BUF_IO_NONE);
+        break;
+      }
+
+      buf_page_mutex_enter(block);
+      ready = buf_flush_ready_for_replace(&block->page);
+      buf_page_mutex_exit(block);
+
+      if (!ready) {
+        return(block);
+      }
+
+      break;
+    }
+  }
+
+  return(NULL);
 }
 
 /********************************************************************//**
@@ -1850,33 +1855,68 @@ void
 buf_pool_set_sizes(void)
 /*====================*/
 {
-	ulint	i;
-	ulint	curr_size = 0;
+  ulint	i;
+  ulint	curr_size = 0;
 
-	buf_pool_mutex_enter_all();
+  buf_pool_mutex_enter_all();
 
-	for (i = 0; i < srv_buf_pool_instances; i++) {
-		buf_pool_t*	buf_pool;
+  for (i = 0; i < srv_buf_pool_instances; i++) {
+    buf_pool_t*	buf_pool;
 
-		buf_pool = buf_pool_from_array(i);
-		curr_size += buf_pool->curr_pool_size;
-	}
+    buf_pool = buf_pool_from_array(i);
+    curr_size += buf_pool->curr_pool_size;
+  }
 
-	srv_buf_pool_curr_size = curr_size;
-	srv_buf_pool_old_size = srv_buf_pool_size;
-	srv_buf_pool_base_size = srv_buf_pool_size;
+  srv_buf_pool_curr_size = curr_size;
+  srv_buf_pool_old_size = srv_buf_pool_size;
+  srv_buf_pool_base_size = srv_buf_pool_size;
 
-	buf_pool_mutex_exit_all();
+  buf_pool_mutex_exit_all();
 }
 
 /** Free the synchronization objects of a buffer pool block descriptor
 @param[in,out]	block	buffer pool block descriptor */
 static void buf_block_free_mutexes(buf_block_t* block)
 {
-	mutex_free(&block->mutex);
-	rw_lock_free(&block->lock);
-	ut_d(rw_lock_free(block->debug_latch));
-	ut_d(ut_free(block->debug_latch));
+  mutex_free(&block->mutex);
+  rw_lock_free(&block->lock);
+  ut_d(rw_lock_free(block->debug_latch));
+  ut_d(ut_free(block->debug_latch));
+}
+
+static
+void
+parallel_buf_chunk_init(
+  buf_pool_t*  buf_pool,      /*!< in: buffer pool instance */
+  buf_chunk_t* start_chunk,   /*!< out: start chunk of buffers */
+  buf_chunk_t* end_chunk,     /*!< out: end chunk of buffers */
+  ulint        chunk_size,    /*!< in: requested size in bytes */
+  ulint*       mem_allocated) /*!< out: result of chunk allocation */
+{
+  buf_chunk_t *chunk = start_chunk;
+  ulint i;
+  ulint total_allocated = 0;
+
+  do {
+    if (!buf_chunk_init(buf_pool, chunk, chunk_size, true)) {
+      while (--chunk >= start_chunk) {
+        buf_block_t*	block = chunk->blocks;
+
+        for (i = chunk->size; i--; block++) {
+          buf_block_free_mutexes(block);
+        }
+
+        buf_pool->allocator.deallocate_large_dodump(
+          chunk->mem, &chunk->mem_pfx, chunk->mem_size());
+      }
+      *mem_allocated = 0;
+      return;
+    }
+
+    total_allocated += chunk->size;
+  } while (++chunk < end_chunk);
+
+  *mem_allocated = total_allocated;
 }
 
 /********************************************************************//**
@@ -1886,149 +1926,212 @@ static
 ulint
 buf_pool_init_instance(
 /*===================*/
-	buf_pool_t*	buf_pool,	/*!< in: buffer pool instance */
-	ulint		buf_pool_size,	/*!< in: size in bytes */
-	ulint		instance_no)	/*!< in: id of the instance */
+  buf_pool_t*	buf_pool,	/*!< in: buffer pool instance */
+  ulint		buf_pool_size,	/*!< in: size in bytes */
+  ulint		instance_no)	/*!< in: id of the instance */
 {
-	ulint		i;
-	ulint		chunk_size;
-	buf_chunk_t*	chunk;
+  ulint		i;
+  ulint		chunk_size;
+  buf_chunk_t*	chunk;
 
-	ut_ad(buf_pool_size % srv_buf_pool_chunk_unit == 0);
+  ut_ad(buf_pool_size % srv_buf_pool_chunk_unit == 0);
 
-	/* 1. Initialize general fields
-	------------------------------- */
-	mutex_create(LATCH_ID_BUF_POOL, &buf_pool->mutex);
+  /* 1. Initialize general fields
+  ------------------------------- */
+  mutex_create(LATCH_ID_BUF_POOL, &buf_pool->mutex);
 
-	mutex_create(LATCH_ID_BUF_POOL_ZIP, &buf_pool->zip_mutex);
+  mutex_create(LATCH_ID_BUF_POOL_ZIP, &buf_pool->zip_mutex);
 
-	new(&buf_pool->allocator)
-		ut_allocator<unsigned char>(mem_key_buf_buf_pool);
+  new(&buf_pool->allocator)
+    ut_allocator<unsigned char>(mem_key_buf_buf_pool);
 
-	buf_pool_mutex_enter(buf_pool);
+  buf_pool_mutex_enter(buf_pool);
 
-	if (buf_pool_size > 0) {
-		buf_pool->n_chunks
-			= buf_pool_size / srv_buf_pool_chunk_unit;
-		chunk_size = srv_buf_pool_chunk_unit;
+  if (buf_pool_size > 0) {
+    buf_pool->n_chunks
+      = buf_pool_size / srv_buf_pool_chunk_unit;
+    chunk_size = srv_buf_pool_chunk_unit;
 
-		buf_pool->chunks =
-			reinterpret_cast<buf_chunk_t*>(ut_zalloc_nokey(
-				buf_pool->n_chunks * sizeof(*chunk)));
-		buf_pool->chunks_old = NULL;
+    buf_pool->chunks =
+      reinterpret_cast<buf_chunk_t*>(ut_zalloc_nokey(
+        buf_pool->n_chunks * sizeof(*chunk)));
+    buf_pool->chunks_old = NULL;
 
-		UT_LIST_INIT(buf_pool->LRU, &buf_page_t::LRU);
-		UT_LIST_INIT(buf_pool->free, &buf_page_t::list);
-		UT_LIST_INIT(buf_pool->withdraw, &buf_page_t::list);
-		buf_pool->withdraw_target = 0;
-		UT_LIST_INIT(buf_pool->flush_list, &buf_page_t::list);
-		UT_LIST_INIT(buf_pool->unzip_LRU, &buf_block_t::unzip_LRU);
+    UT_LIST_INIT(buf_pool->LRU, &buf_page_t::LRU);
+    UT_LIST_INIT(buf_pool->free, &buf_page_t::list);
+    UT_LIST_INIT(buf_pool->withdraw, &buf_page_t::list);
+    buf_pool->withdraw_target = 0;
+    UT_LIST_INIT(buf_pool->flush_list, &buf_page_t::list);
+    UT_LIST_INIT(buf_pool->unzip_LRU, &buf_block_t::unzip_LRU);
 
 #if defined UNIV_DEBUG || defined UNIV_BUF_DEBUG
-		UT_LIST_INIT(buf_pool->zip_clean, &buf_page_t::list);
+    UT_LIST_INIT(buf_pool->zip_clean, &buf_page_t::list);
 #endif /* UNIV_DEBUG || UNIV_BUF_DEBUG */
 
-		for (i = 0; i < UT_ARR_SIZE(buf_pool->zip_free); ++i) {
-			UT_LIST_INIT(
-				buf_pool->zip_free[i], &buf_buddy_free_t::list);
-		}
-
-		buf_pool->curr_size = 0;
-		chunk = buf_pool->chunks;
-
-		do {
-			if (!buf_chunk_init(buf_pool, chunk, chunk_size)) {
-				while (--chunk >= buf_pool->chunks) {
-					buf_block_t*	block = chunk->blocks;
-
-					for (i = chunk->size; i--; block++) {
-						buf_block_free_mutexes(block);
-					}
-
-					buf_pool->allocator.deallocate_large_dodump(
-						chunk->mem, &chunk->mem_pfx, chunk->mem_size());
-				}
-				ut_free(buf_pool->chunks);
-				buf_pool_mutex_exit(buf_pool);
-
-				return(DB_ERROR);
-			}
+    for (i = 0; i < UT_ARR_SIZE(buf_pool->zip_free); ++i) {
+      UT_LIST_INIT(
+        buf_pool->zip_free[i], &buf_buddy_free_t::list);
+    }
 
-			buf_pool->curr_size += chunk->size;
-		} while (++chunk < buf_pool->chunks + buf_pool->n_chunks);
+    buf_pool->curr_size = 0;
+    chunk = buf_pool->chunks;
+
+    ulint cpu_cores = sysconf(_SC_NPROCESSORS_ONLN);
+    cpu_cores = cpu_cores <= 2 ? 1 : cpu_cores;
+    ulint chunks_per_thread = buf_pool->n_chunks / cpu_cores;
+
+    if (cpu_cores == 1 || chunks_per_thread == 0) {
+      do {
+        if (!buf_chunk_init(buf_pool, chunk, chunk_size)) {
+          while (--chunk >= buf_pool->chunks) {
+            buf_block_t*	block = chunk->blocks;
+
+            for (i = chunk->size; i--; block++) {
+              buf_block_free_mutexes(block);
+            }
+
+            buf_pool->allocator.deallocate_large_dodump(
+              chunk->mem, &chunk->mem_pfx, chunk->mem_size());
+          }
+          ut_free(buf_pool->chunks);
+          buf_pool_mutex_exit(buf_pool);
+
+          return(DB_ERROR);
+        }
+
+        buf_pool->curr_size += chunk->size;
+      } while (++chunk < buf_pool->chunks + buf_pool->n_chunks);
+    } else {
+      ulint *mem_allocated = UT_NEW_ARRAY_NOKEY(ulint, cpu_cores);
+      std::thread *threads = UT_NEW_ARRAY_NOKEY(std::thread, cpu_cores);
+
+      // exit mutex for parallel free list appending
+      buf_pool_mutex_exit(buf_pool);
+
+      for (i = 0; i < cpu_cores; i++) {
+        buf_chunk_t *last_chunk = (i == cpu_cores - 1) ? buf_pool->chunks + buf_pool->n_chunks : buf_pool->chunks + (i+1) * chunks_per_thread;
+        threads[i] = std::thread(parallel_buf_chunk_init,
+                                  buf_pool,
+                                  buf_pool->chunks + i * chunks_per_thread,
+                                  last_chunk,
+                                  chunk_size,
+                                  &mem_allocated[i]);
+      }
+
+      bool allocation_succeed = true;
+      for (i = 0; i < cpu_cores; i++) {
+        threads[i].join();
+        if (mem_allocated[i] == 0)
+          allocation_succeed = false;
+      }
+
+      // re-enter mutex
+      buf_pool_mutex_enter(buf_pool);
+
+      if (allocation_succeed) {
+        for (i = 0; i < cpu_cores; i++)
+          buf_pool->curr_size += mem_allocated[i];
+        UT_DELETE_ARRAY(mem_allocated);
+        UT_DELETE_ARRAY(threads);
+      } else {
+        for (i = 0; i < cpu_cores; i++) {
+          if (mem_allocated[i] != 0) {
+            buf_chunk_t* start_chunk = buf_pool->chunks + i * chunks_per_thread;
+            buf_chunk_t* last_chunk = (i == cpu_cores - 1) ? buf_pool->chunks + buf_pool->n_chunks : buf_pool->chunks + (i+1) * chunks_per_thread;
+            chunk = last_chunk;
+            while (--chunk >= start_chunk) {
+              buf_block_t*	block = chunk->blocks;
+
+              for (ulint j = chunk->size; j--; block++) {
+                buf_block_free_mutexes(block);
+              }
+
+              buf_pool->allocator.deallocate_large_dodump(
+                chunk->mem, &chunk->mem_pfx, chunk->mem_size());
+            }
+          }
+        }
+        UT_DELETE_ARRAY(mem_allocated);
+        UT_DELETE_ARRAY(threads);
+        ut_free(buf_pool->chunks);
+        buf_pool_mutex_exit(buf_pool);
+
+        return(DB_ERROR);
+      }
+    }
 
-		buf_pool->instance_no = instance_no;
-		buf_pool->read_ahead_area =
-			ut_min(BUF_READ_AHEAD_PAGES,
-			       ut_2_power_up(buf_pool->curr_size /
-					     BUF_READ_AHEAD_PORTION));
-		buf_pool->curr_pool_size = buf_pool_size;
+    buf_pool->instance_no = instance_no;
+    buf_pool->read_ahead_area =
+      ut_min(BUF_READ_AHEAD_PAGES,
+             ut_2_power_up(buf_pool->curr_size /
+               BUF_READ_AHEAD_PORTION));
+    buf_pool->curr_pool_size = buf_pool_size;
 
-		buf_pool->old_size = buf_pool->curr_size;
-		buf_pool->n_chunks_new = buf_pool->n_chunks;
+    buf_pool->old_size = buf_pool->curr_size;
+    buf_pool->n_chunks_new = buf_pool->n_chunks;
 
-		/* Number of locks protecting page_hash must be a
-		power of two */
-		srv_n_page_hash_locks = static_cast<ulong>(
-			 ut_2_power_up(srv_n_page_hash_locks));
-		ut_a(srv_n_page_hash_locks != 0);
-		ut_a(srv_n_page_hash_locks <= MAX_PAGE_HASH_LOCKS);
+    /* Number of locks protecting page_hash must be a
+    power of two */
+    srv_n_page_hash_locks = static_cast<ulong>(
+       ut_2_power_up(srv_n_page_hash_locks));
+    ut_a(srv_n_page_hash_locks != 0);
+    ut_a(srv_n_page_hash_locks <= MAX_PAGE_HASH_LOCKS);
 
-		buf_pool->page_hash = ib_create(
-			2 * buf_pool->curr_size,
-			LATCH_ID_HASH_TABLE_RW_LOCK,
-			srv_n_page_hash_locks, MEM_HEAP_FOR_PAGE_HASH);
+    buf_pool->page_hash = ib_create(
+      2 * buf_pool->curr_size,
+      LATCH_ID_HASH_TABLE_RW_LOCK,
+      srv_n_page_hash_locks, MEM_HEAP_FOR_PAGE_HASH);
 
-		buf_pool->page_hash_old = NULL;
+    buf_pool->page_hash_old = NULL;
 
-		buf_pool->zip_hash = hash_create(2 * buf_pool->curr_size);
+    buf_pool->zip_hash = hash_create(2 * buf_pool->curr_size);
 
-		buf_pool->last_printout_time = time(NULL);
-	}
-	/* 2. Initialize flushing fields
-	-------------------------------- */
+    buf_pool->last_printout_time = time(NULL);
+  }
+  /* 2. Initialize flushing fields
+  -------------------------------- */
 
-	mutex_create(LATCH_ID_FLUSH_LIST, &buf_pool->flush_list_mutex);
+  mutex_create(LATCH_ID_FLUSH_LIST, &buf_pool->flush_list_mutex);
 
-	for (i = BUF_FLUSH_LRU; i < BUF_FLUSH_N_TYPES; i++) {
-		buf_pool->no_flush[i] = os_event_create(0);
-	}
+  for (i = BUF_FLUSH_LRU; i < BUF_FLUSH_N_TYPES; i++) {
+    buf_pool->no_flush[i] = os_event_create(0);
+  }
 
-	buf_pool->watch = (buf_page_t*) ut_zalloc_nokey(
-		sizeof(*buf_pool->watch) * BUF_POOL_WATCH_SIZE);
-	for (i = 0; i < BUF_POOL_WATCH_SIZE; i++) {
-		buf_pool->watch[i].buf_pool_index
-			= unsigned(buf_pool->instance_no);
-	}
+  buf_pool->watch = (buf_page_t*) ut_zalloc_nokey(
+    sizeof(*buf_pool->watch) * BUF_POOL_WATCH_SIZE);
+  for (i = 0; i < BUF_POOL_WATCH_SIZE; i++) {
+    buf_pool->watch[i].buf_pool_index
+      = unsigned(buf_pool->instance_no);
+  }
 
-	/* All fields are initialized by ut_zalloc_nokey(). */
+  /* All fields are initialized by ut_zalloc_nokey(). */
 
-	buf_pool->try_LRU_scan = TRUE;
+  buf_pool->try_LRU_scan = TRUE;
 
-	/* Initialize the hazard pointer for flush_list batches */
-	new(&buf_pool->flush_hp)
-		FlushHp(buf_pool, &buf_pool->flush_list_mutex);
+  /* Initialize the hazard pointer for flush_list batches */
+  new(&buf_pool->flush_hp)
+    FlushHp(buf_pool, &buf_pool->flush_list_mutex);
 
-	/* Initialize the hazard pointer for LRU batches */
-	new(&buf_pool->lru_hp) LRUHp(buf_pool, &buf_pool->mutex);
+  /* Initialize the hazard pointer for LRU batches */
+  new(&buf_pool->lru_hp) LRUHp(buf_pool, &buf_pool->mutex);
 
-	/* Initialize the iterator for LRU scan search */
-	new(&buf_pool->lru_scan_itr) LRUItr(buf_pool, &buf_pool->mutex);
+  /* Initialize the iterator for LRU scan search */
+  new(&buf_pool->lru_scan_itr) LRUItr(buf_pool, &buf_pool->mutex);
 
-	/* Initialize the iterator for single page scan search */
-	new(&buf_pool->single_scan_itr) LRUItr(buf_pool, &buf_pool->mutex);
+  /* Initialize the iterator for single page scan search */
+  new(&buf_pool->single_scan_itr) LRUItr(buf_pool, &buf_pool->mutex);
 
-	/* Initialize the temporal memory array and slots */
-	new(&buf_pool->io_buf) buf_pool_t::io_buf_t(
-		(srv_n_read_io_threads + srv_n_write_io_threads)
-		* (8 * OS_AIO_N_PENDING_IOS_PER_THREAD));
+  /* Initialize the temporal memory array and slots */
+  new(&buf_pool->io_buf) buf_pool_t::io_buf_t(
+    (srv_n_read_io_threads + srv_n_write_io_threads)
+    * (8 * OS_AIO_N_PENDING_IOS_PER_THREAD));
 
-	buf_pool_mutex_exit(buf_pool);
+  buf_pool_mutex_exit(buf_pool);
 
-	DBUG_EXECUTE_IF("buf_pool_init_instance_force_oom",
-		return(DB_ERROR); );
+  DBUG_EXECUTE_IF("buf_pool_init_instance_force_oom",
+    return(DB_ERROR); );
 
-	return(DB_SUCCESS);
+  return(DB_SUCCESS);
 }
 
 /********************************************************************//**
@@ -2037,70 +2140,70 @@ static
 void
 buf_pool_free_instance(
 /*===================*/
-	buf_pool_t*	buf_pool)	/* in,own: buffer pool instance
-					to free */
+  buf_pool_t*	buf_pool)	/* in,own: buffer pool instance
+          to free */
 {
-	buf_chunk_t*	chunk;
-	buf_chunk_t*	chunks;
-	buf_page_t*	bpage;
-	buf_page_t*	prev_bpage = 0;
-
-	mutex_free(&buf_pool->mutex);
-	mutex_free(&buf_pool->zip_mutex);
-	mutex_free(&buf_pool->flush_list_mutex);
-
-	if (buf_pool->flush_rbt) {
-		rbt_free(buf_pool->flush_rbt);
-		buf_pool->flush_rbt = NULL;
-	}
-
-	for (bpage = UT_LIST_GET_LAST(buf_pool->LRU);
-	     bpage != NULL;
-	     bpage = prev_bpage) {
-
-		prev_bpage = UT_LIST_GET_PREV(LRU, bpage);
-		buf_page_state	state = buf_page_get_state(bpage);
-
-		ut_ad(buf_page_in_file(bpage));
-		ut_ad(bpage->in_LRU_list);
-
-		if (state != BUF_BLOCK_FILE_PAGE) {
-			/* We must not have any dirty block except
-			when doing a fast shutdown. */
-			ut_ad(state == BUF_BLOCK_ZIP_PAGE
-			      || srv_fast_shutdown == 2);
-			buf_page_free_descriptor(bpage);
-		}
-	}
-
-	ut_free(buf_pool->watch);
-	buf_pool->watch = NULL;
-
-	chunks = buf_pool->chunks;
-	chunk = chunks + buf_pool->n_chunks;
-
-	while (--chunk >= chunks) {
-		buf_block_t*	block = chunk->blocks;
-
-		for (ulint i = chunk->size; i--; block++) {
-			buf_block_free_mutexes(block);
-		}
-
-		buf_pool->allocator.deallocate_large_dodump(
-			chunk->mem, &chunk->mem_pfx, chunk->mem_size());
-	}
-
-	for (ulint i = BUF_FLUSH_LRU; i < BUF_FLUSH_N_TYPES; ++i) {
-		os_event_destroy(buf_pool->no_flush[i]);
-	}
-
-	ut_free(buf_pool->chunks);
-	ha_clear(buf_pool->page_hash);
-	hash_table_free(buf_pool->page_hash);
-	hash_table_free(buf_pool->zip_hash);
-
-	buf_pool->io_buf.~io_buf_t();
-	buf_pool->allocator.~ut_allocator();
+  buf_chunk_t*	chunk;
+  buf_chunk_t*	chunks;
+  buf_page_t*	bpage;
+  buf_page_t*	prev_bpage = 0;
+
+  mutex_free(&buf_pool->mutex);
+  mutex_free(&buf_pool->zip_mutex);
+  mutex_free(&buf_pool->flush_list_mutex);
+
+  if (buf_pool->flush_rbt) {
+    rbt_free(buf_pool->flush_rbt);
+    buf_pool->flush_rbt = NULL;
+  }
+
+  for (bpage = UT_LIST_GET_LAST(buf_pool->LRU);
+       bpage != NULL;
+       bpage = prev_bpage) {
+
+    prev_bpage = UT_LIST_GET_PREV(LRU, bpage);
+    buf_page_state	state = buf_page_get_state(bpage);
+
+    ut_ad(buf_page_in_file(bpage));
+    ut_ad(bpage->in_LRU_list);
+
+    if (state != BUF_BLOCK_FILE_PAGE) {
+      /* We must not have any dirty block except
+      when doing a fast shutdown. */
+      ut_ad(state == BUF_BLOCK_ZIP_PAGE
+            || srv_fast_shutdown == 2);
+      buf_page_free_descriptor(bpage);
+    }
+  }
+
+  ut_free(buf_pool->watch);
+  buf_pool->watch = NULL;
+
+  chunks = buf_pool->chunks;
+  chunk = chunks + buf_pool->n_chunks;
+
+  while (--chunk >= chunks) {
+    buf_block_t*	block = chunk->blocks;
+
+    for (ulint i = chunk->size; i--; block++) {
+      buf_block_free_mutexes(block);
+    }
+
+    buf_pool->allocator.deallocate_large_dodump(
+      chunk->mem, &chunk->mem_pfx, chunk->mem_size());
+  }
+
+  for (ulint i = BUF_FLUSH_LRU; i < BUF_FLUSH_N_TYPES; ++i) {
+    os_event_destroy(buf_pool->no_flush[i]);
+  }
+
+  ut_free(buf_pool->chunks);
+  ha_clear(buf_pool->page_hash);
+  hash_table_free(buf_pool->page_hash);
+  hash_table_free(buf_pool->zip_hash);
+
+  buf_pool->io_buf.~io_buf_t();
+  buf_pool->allocator.~ut_allocator();
 }
 
 /********************************************************************//**
@@ -2109,47 +2212,47 @@ Creates the buffer pool.
 dberr_t
 buf_pool_init(
 /*==========*/
-	ulint	total_size,	/*!< in: size of the total pool in bytes */
-	ulint	n_instances)	/*!< in: number of instances */
+  ulint	total_size,	/*!< in: size of the total pool in bytes */
+  ulint	n_instances)	/*!< in: number of instances */
 {
-	ulint		i;
-	const ulint	size	= total_size / n_instances;
+  ulint		i;
+  const ulint	size	= total_size / n_instances;
 
-	ut_ad(n_instances > 0);
-	ut_ad(n_instances <= MAX_BUFFER_POOLS);
-	ut_ad(n_instances == srv_buf_pool_instances);
+  ut_ad(n_instances > 0);
+  ut_ad(n_instances <= MAX_BUFFER_POOLS);
+  ut_ad(n_instances == srv_buf_pool_instances);
 
-	NUMA_MEMPOLICY_INTERLEAVE_IN_SCOPE;
+  NUMA_MEMPOLICY_INTERLEAVE_IN_SCOPE;
 
-	buf_pool_resizing = false;
-	buf_pool_withdrawing = false;
-	buf_withdraw_clock = 0;
+  buf_pool_resizing = false;
+  buf_pool_withdrawing = false;
+  buf_withdraw_clock = 0;
 
-	buf_pool_ptr = (buf_pool_t*) ut_zalloc_nokey(
-		n_instances * sizeof *buf_pool_ptr);
+  buf_pool_ptr = (buf_pool_t*) ut_zalloc_nokey(
+    n_instances * sizeof *buf_pool_ptr);
 
-	buf_chunk_map_reg = UT_NEW_NOKEY(buf_pool_chunk_map_t());
+  buf_chunk_map_reg = UT_NEW_NOKEY(buf_pool_chunk_map_t());
 
-	for (i = 0; i < n_instances; i++) {
-		buf_pool_t*	ptr	= &buf_pool_ptr[i];
+  for (i = 0; i < n_instances; i++) {
+    buf_pool_t*	ptr	= &buf_pool_ptr[i];
 
-		if (buf_pool_init_instance(ptr, size, i) != DB_SUCCESS) {
+    if (buf_pool_init_instance(ptr, size, i) != DB_SUCCESS) {
 
-			/* Free all the instances created so far. */
-			buf_pool_free(i);
+      /* Free all the instances created so far. */
+      buf_pool_free(i);
 
-			return(DB_ERROR);
-		}
-	}
+      return(DB_ERROR);
+    }
+  }
 
-	buf_chunk_map_ref = buf_chunk_map_reg;
+  buf_chunk_map_ref = buf_chunk_map_reg;
 
-	buf_pool_set_sizes();
-	buf_LRU_old_ratio_update(100 * 3/ 8, FALSE);
+  buf_pool_set_sizes();
+  buf_LRU_old_ratio_update(100 * 3/ 8, FALSE);
 
-	btr_search_sys_create(buf_pool_get_curr_size() / sizeof(void*) / 64);
+  btr_search_sys_create(buf_pool_get_curr_size() / sizeof(void*) / 64);
 
-	return(DB_SUCCESS);
+  return(DB_SUCCESS);
 }
 
 /********************************************************************//**
@@ -2158,17 +2261,17 @@ freeing all mutexes. */
 void
 buf_pool_free(
 /*==========*/
-	ulint	n_instances)	/*!< in: numbere of instances to free */
+  ulint	n_instances)	/*!< in: numbere of instances to free */
 {
-	for (ulint i = 0; i < n_instances; i++) {
-		buf_pool_free_instance(buf_pool_from_array(i));
-	}
+  for (ulint i = 0; i < n_instances; i++) {
+    buf_pool_free_instance(buf_pool_from_array(i));
+  }
 
-	UT_DELETE(buf_chunk_map_reg);
-	buf_chunk_map_reg = buf_chunk_map_ref = NULL;
+  UT_DELETE(buf_chunk_map_reg);
+  buf_chunk_map_reg = buf_chunk_map_ref = NULL;
 
-	ut_free(buf_pool_ptr);
-	buf_pool_ptr = NULL;
+  ut_free(buf_pool_ptr);
+  buf_pool_ptr = NULL;
 }
 
 /** Reallocate a control block.
@@ -2178,142 +2281,142 @@ buf_pool_free(
 static
 bool
 buf_page_realloc(
-	buf_pool_t*	buf_pool,
-	buf_block_t*	block)
+  buf_pool_t*	buf_pool,
+  buf_block_t*	block)
 {
-	buf_block_t*	new_block;
-
-	ut_ad(buf_pool_withdrawing);
-	ut_ad(buf_pool_mutex_own(buf_pool));
-	ut_ad(buf_block_get_state(block) == BUF_BLOCK_FILE_PAGE);
-
-	new_block = buf_LRU_get_free_only(buf_pool);
-
-	if (new_block == NULL) {
-		return(false); /* free_list was not enough */
-	}
-
-	rw_lock_t*	hash_lock = buf_page_hash_lock_get(buf_pool, block->page.id);
-
-	rw_lock_x_lock(hash_lock);
-	mutex_enter(&block->mutex);
-
-	if (buf_page_can_relocate(&block->page)) {
-		mutex_enter(&new_block->mutex);
-
-		memcpy(new_block->frame, block->frame, srv_page_size);
-		new (&new_block->page) buf_page_t(block->page);
-
-		/* relocate LRU list */
-		ut_ad(block->page.in_LRU_list);
-		ut_ad(!block->page.in_zip_hash);
-		ut_d(block->page.in_LRU_list = FALSE);
-
-		buf_LRU_adjust_hp(buf_pool, &block->page);
-
-		buf_page_t*	prev_b = UT_LIST_GET_PREV(LRU, &block->page);
-		UT_LIST_REMOVE(buf_pool->LRU, &block->page);
-
-		if (prev_b != NULL) {
-			UT_LIST_INSERT_AFTER(buf_pool->LRU, prev_b, &new_block->page);
-		} else {
-			UT_LIST_ADD_FIRST(buf_pool->LRU, &new_block->page);
-		}
-
-		if (buf_pool->LRU_old == &block->page) {
-			buf_pool->LRU_old = &new_block->page;
-		}
-
-		ut_ad(new_block->page.in_LRU_list);
-
-		/* relocate unzip_LRU list */
-		if (block->page.zip.data != NULL) {
-			ut_ad(block->in_unzip_LRU_list);
-			ut_d(new_block->in_unzip_LRU_list = TRUE);
-			UNIV_MEM_DESC(&new_block->page.zip.data,
-				      page_zip_get_size(&new_block->page.zip));
-
-			buf_block_t*	prev_block = UT_LIST_GET_PREV(unzip_LRU, block);
-			UT_LIST_REMOVE(buf_pool->unzip_LRU, block);
-
-			ut_d(block->in_unzip_LRU_list = FALSE);
-			block->page.zip.data = NULL;
-			page_zip_set_size(&block->page.zip, 0);
-
-			if (prev_block != NULL) {
-				UT_LIST_INSERT_AFTER(buf_pool->unzip_LRU, prev_block, new_block);
-			} else {
-				UT_LIST_ADD_FIRST(buf_pool->unzip_LRU, new_block);
-			}
-		} else {
-			ut_ad(!block->in_unzip_LRU_list);
-			ut_d(new_block->in_unzip_LRU_list = FALSE);
-		}
-
-		/* relocate buf_pool->page_hash */
-		ut_ad(block->page.in_page_hash);
-		ut_ad(&block->page == buf_page_hash_get_low(buf_pool,
-							    block->page.id));
-		ut_d(block->page.in_page_hash = FALSE);
-		ulint	fold = block->page.id.fold();
-		ut_ad(fold == new_block->page.id.fold());
-		HASH_DELETE(buf_page_t, hash, buf_pool->page_hash, fold, (&block->page));
-		HASH_INSERT(buf_page_t, hash, buf_pool->page_hash, fold, (&new_block->page));
-
-		ut_ad(new_block->page.in_page_hash);
-
-		buf_block_modify_clock_inc(block);
-		memset(block->frame + FIL_PAGE_OFFSET, 0xff, 4);
-		memset(block->frame + FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID, 0xff, 4);
-		UNIV_MEM_INVALID(block->frame, srv_page_size);
-		buf_block_set_state(block, BUF_BLOCK_REMOVE_HASH);
-		block->page.id
-		    = page_id_t(ULINT32_UNDEFINED, ULINT32_UNDEFINED);
-
-		/* Relocate buf_pool->flush_list. */
-		if (block->page.oldest_modification) {
-			buf_flush_relocate_on_flush_list(
-				&block->page, &new_block->page);
-		}
-
-		/* set other flags of buf_block_t */
+  buf_block_t*	new_block;
+
+  ut_ad(buf_pool_withdrawing);
+  ut_ad(buf_pool_mutex_own(buf_pool));
+  ut_ad(buf_block_get_state(block) == BUF_BLOCK_FILE_PAGE);
+
+  new_block = buf_LRU_get_free_only(buf_pool);
+
+  if (new_block == NULL) {
+    return(false); /* free_list was not enough */
+  }
+
+  rw_lock_t*	hash_lock = buf_page_hash_lock_get(buf_pool, block->page.id);
+
+  rw_lock_x_lock(hash_lock);
+  mutex_enter(&block->mutex);
+
+  if (buf_page_can_relocate(&block->page)) {
+    mutex_enter(&new_block->mutex);
+
+    memcpy(new_block->frame, block->frame, srv_page_size);
+    new (&new_block->page) buf_page_t(block->page);
+
+    /* relocate LRU list */
+    ut_ad(block->page.in_LRU_list);
+    ut_ad(!block->page.in_zip_hash);
+    ut_d(block->page.in_LRU_list = FALSE);
+
+    buf_LRU_adjust_hp(buf_pool, &block->page);
+
+    buf_page_t*	prev_b = UT_LIST_GET_PREV(LRU, &block->page);
+    UT_LIST_REMOVE(buf_pool->LRU, &block->page);
+
+    if (prev_b != NULL) {
+      UT_LIST_INSERT_AFTER(buf_pool->LRU, prev_b, &new_block->page);
+    } else {
+      UT_LIST_ADD_FIRST(buf_pool->LRU, &new_block->page);
+    }
+
+    if (buf_pool->LRU_old == &block->page) {
+      buf_pool->LRU_old = &new_block->page;
+    }
+
+    ut_ad(new_block->page.in_LRU_list);
+
+    /* relocate unzip_LRU list */
+    if (block->page.zip.data != NULL) {
+      ut_ad(block->in_unzip_LRU_list);
+      ut_d(new_block->in_unzip_LRU_list = TRUE);
+      UNIV_MEM_DESC(&new_block->page.zip.data,
+              page_zip_get_size(&new_block->page.zip));
+
+      buf_block_t*	prev_block = UT_LIST_GET_PREV(unzip_LRU, block);
+      UT_LIST_REMOVE(buf_pool->unzip_LRU, block);
+
+      ut_d(block->in_unzip_LRU_list = FALSE);
+      block->page.zip.data = NULL;
+      page_zip_set_size(&block->page.zip, 0);
+
+      if (prev_block != NULL) {
+        UT_LIST_INSERT_AFTER(buf_pool->unzip_LRU, prev_block, new_block);
+      } else {
+        UT_LIST_ADD_FIRST(buf_pool->unzip_LRU, new_block);
+      }
+    } else {
+      ut_ad(!block->in_unzip_LRU_list);
+      ut_d(new_block->in_unzip_LRU_list = FALSE);
+    }
+
+    /* relocate buf_pool->page_hash */
+    ut_ad(block->page.in_page_hash);
+    ut_ad(&block->page == buf_page_hash_get_low(buf_pool,
+                  block->page.id));
+    ut_d(block->page.in_page_hash = FALSE);
+    ulint	fold = block->page.id.fold();
+    ut_ad(fold == new_block->page.id.fold());
+    HASH_DELETE(buf_page_t, hash, buf_pool->page_hash, fold, (&block->page));
+    HASH_INSERT(buf_page_t, hash, buf_pool->page_hash, fold, (&new_block->page));
+
+    ut_ad(new_block->page.in_page_hash);
+
+    buf_block_modify_clock_inc(block);
+    memset(block->frame + FIL_PAGE_OFFSET, 0xff, 4);
+    memset(block->frame + FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID, 0xff, 4);
+    UNIV_MEM_INVALID(block->frame, srv_page_size);
+    buf_block_set_state(block, BUF_BLOCK_REMOVE_HASH);
+    block->page.id
+        = page_id_t(ULINT32_UNDEFINED, ULINT32_UNDEFINED);
+
+    /* Relocate buf_pool->flush_list. */
+    if (block->page.oldest_modification) {
+      buf_flush_relocate_on_flush_list(
+        &block->page, &new_block->page);
+    }
+
+    /* set other flags of buf_block_t */
 
 #ifdef BTR_CUR_HASH_ADAPT
-		/* This code should only be executed by buf_pool_resize(),
-		while the adaptive hash index is disabled. */
-		assert_block_ahi_empty(block);
-		assert_block_ahi_empty_on_init(new_block);
-		ut_ad(!block->index);
-		new_block->index	= NULL;
-		new_block->n_hash_helps	= 0;
-		new_block->n_fields	= 1;
-		new_block->left_side	= TRUE;
+    /* This code should only be executed by buf_pool_resize(),
+    while the adaptive hash index is disabled. */
+    assert_block_ahi_empty(block);
+    assert_block_ahi_empty_on_init(new_block);
+    ut_ad(!block->index);
+    new_block->index	= NULL;
+    new_block->n_hash_helps	= 0;
+    new_block->n_fields	= 1;
+    new_block->left_side	= TRUE;
 #endif /* BTR_CUR_HASH_ADAPT */
 
-		new_block->lock_hash_val = block->lock_hash_val;
-		ut_ad(new_block->lock_hash_val == lock_rec_hash(
-			new_block->page.id.space(),
-			new_block->page.id.page_no()));
+    new_block->lock_hash_val = block->lock_hash_val;
+    ut_ad(new_block->lock_hash_val == lock_rec_hash(
+      new_block->page.id.space(),
+      new_block->page.id.page_no()));
 
-		rw_lock_x_unlock(hash_lock);
-		mutex_exit(&new_block->mutex);
+    rw_lock_x_unlock(hash_lock);
+    mutex_exit(&new_block->mutex);
 
-		/* free block */
-		buf_block_set_state(block, BUF_BLOCK_MEMORY);
-		buf_LRU_block_free_non_file_page(block);
+    /* free block */
+    buf_block_set_state(block, BUF_BLOCK_MEMORY);
+    buf_LRU_block_free_non_file_page(block);
 
-		mutex_exit(&block->mutex);
-	} else {
-		rw_lock_x_unlock(hash_lock);
-		mutex_exit(&block->mutex);
+    mutex_exit(&block->mutex);
+  } else {
+    rw_lock_x_unlock(hash_lock);
+    mutex_exit(&block->mutex);
 
-		/* free new_block */
-		mutex_enter(&new_block->mutex);
-		buf_LRU_block_free_non_file_page(new_block);
-		mutex_exit(&new_block->mutex);
-	}
+    /* free new_block */
+    mutex_enter(&new_block->mutex);
+    buf_LRU_block_free_non_file_page(new_block);
+    mutex_exit(&new_block->mutex);
+  }
 
-	return(true); /* free_list was enough */
+  return(true); /* free_list was enough */
 }
 
 /** Sets the global variable that feeds MySQL's innodb_buffer_pool_resize_status
@@ -2324,21 +2427,21 @@ same as the ones used for printf(3).
 static
 void
 buf_resize_status(
-	const char*	fmt,
-	...)
+  const char*	fmt,
+  ...)
 {
-	va_list	ap;
+  va_list	ap;
 
-	va_start(ap, fmt);
+  va_start(ap, fmt);
 
-	vsnprintf(
-		export_vars.innodb_buffer_pool_resize_status,
-		sizeof(export_vars.innodb_buffer_pool_resize_status),
-		fmt, ap);
+  vsnprintf(
+    export_vars.innodb_buffer_pool_resize_status,
+    sizeof(export_vars.innodb_buffer_pool_resize_status),
+    fmt, ap);
 
-	va_end(ap);
+  va_end(ap);
 
-	ib::info() << export_vars.innodb_buffer_pool_resize_status;
+  ib::info() << export_vars.innodb_buffer_pool_resize_status;
 }
 
 /** Determines if a block is intended to be withdrawn.
@@ -2347,26 +2450,26 @@ buf_resize_status(
 @retval true	if will be withdrawn */
 bool
 buf_block_will_withdrawn(
-	buf_pool_t*		buf_pool,
-	const buf_block_t*	block)
+  buf_pool_t*		buf_pool,
+  const buf_block_t*	block)
 {
-	ut_ad(buf_pool->curr_size < buf_pool->old_size);
-	ut_ad(!buf_pool_resizing || buf_pool_mutex_own(buf_pool));
-
-	const buf_chunk_t*	chunk
-		= buf_pool->chunks + buf_pool->n_chunks_new;
-	const buf_chunk_t*	echunk
-		= buf_pool->chunks + buf_pool->n_chunks;
-
-	while (chunk < echunk) {
-		if (block >= chunk->blocks
-		    && block < chunk->blocks + chunk->size) {
-			return(true);
-		}
-		++chunk;
-	}
-
-	return(false);
+  ut_ad(buf_pool->curr_size < buf_pool->old_size);
+  ut_ad(!buf_pool_resizing || buf_pool_mutex_own(buf_pool));
+
+  const buf_chunk_t*	chunk
+    = buf_pool->chunks + buf_pool->n_chunks_new;
+  const buf_chunk_t*	echunk
+    = buf_pool->chunks + buf_pool->n_chunks;
+
+  while (chunk < echunk) {
+    if (block >= chunk->blocks
+        && block < chunk->blocks + chunk->size) {
+      return(true);
+    }
+    ++chunk;
+  }
+
+  return(false);
 }
 
 /** Determines if a frame is intended to be withdrawn.
@@ -2375,27 +2478,27 @@ buf_block_will_withdrawn(
 @retval true	if will be withdrawn */
 bool
 buf_frame_will_withdrawn(
-	buf_pool_t*	buf_pool,
-	const byte*	ptr)
+  buf_pool_t*	buf_pool,
+  const byte*	ptr)
 {
-	ut_ad(buf_pool->curr_size < buf_pool->old_size);
-	ut_ad(!buf_pool_resizing || buf_pool_mutex_own(buf_pool));
-
-	const buf_chunk_t*	chunk
-		= buf_pool->chunks + buf_pool->n_chunks_new;
-	const buf_chunk_t*	echunk
-		= buf_pool->chunks + buf_pool->n_chunks;
-
-	while (chunk < echunk) {
-		if (ptr >= chunk->blocks->frame
-		    && ptr < (chunk->blocks + chunk->size - 1)->frame
-			     + srv_page_size) {
-			return(true);
-		}
-		++chunk;
-	}
-
-	return(false);
+  ut_ad(buf_pool->curr_size < buf_pool->old_size);
+  ut_ad(!buf_pool_resizing || buf_pool_mutex_own(buf_pool));
+
+  const buf_chunk_t*	chunk
+    = buf_pool->chunks + buf_pool->n_chunks_new;
+  const buf_chunk_t*	echunk
+    = buf_pool->chunks + buf_pool->n_chunks;
+
+  while (chunk < echunk) {
+    if (ptr >= chunk->blocks->frame
+        && ptr < (chunk->blocks + chunk->size - 1)->frame
+           + srv_page_size) {
+      return(true);
+    }
+    ++chunk;
+  }
+
+  return(false);
 }
 
 /** Withdraw the buffer pool blocks from end of the buffer pool instance
@@ -2405,212 +2508,212 @@ until withdrawn by buf_pool->withdraw_target.
 static
 bool
 buf_pool_withdraw_blocks(
-	buf_pool_t*	buf_pool)
+  buf_pool_t*	buf_pool)
 {
-	buf_block_t*	block;
-	ulint		loop_count = 0;
-	ulint		i = buf_pool_index(buf_pool);
-
-	ib::info() << "buffer pool " << i
-		<< " : start to withdraw the last "
-		<< buf_pool->withdraw_target << " blocks.";
-
-	/* Minimize buf_pool->zip_free[i] lists */
-	buf_pool_mutex_enter(buf_pool);
-	buf_buddy_condense_free(buf_pool);
-	buf_pool_mutex_exit(buf_pool);
-
-	while (UT_LIST_GET_LEN(buf_pool->withdraw)
-	       < buf_pool->withdraw_target) {
-
-		/* try to withdraw from free_list */
-		ulint	count1 = 0;
-
-		buf_pool_mutex_enter(buf_pool);
-		block = reinterpret_cast<buf_block_t*>(
-			UT_LIST_GET_FIRST(buf_pool->free));
-		while (block != NULL
-		       && UT_LIST_GET_LEN(buf_pool->withdraw)
-			  < buf_pool->withdraw_target) {
-			ut_ad(block->page.in_free_list);
-			ut_ad(!block->page.in_flush_list);
-			ut_ad(!block->page.in_LRU_list);
-			ut_a(!buf_page_in_file(&block->page));
-
-			buf_block_t*	next_block;
-			next_block = reinterpret_cast<buf_block_t*>(
-				UT_LIST_GET_NEXT(
-					list, &block->page));
-
-			if (buf_block_will_withdrawn(buf_pool, block)) {
-				/* This should be withdrawn */
-				UT_LIST_REMOVE(
-					buf_pool->free,
-					&block->page);
-				UT_LIST_ADD_LAST(
-					buf_pool->withdraw,
-					&block->page);
-				ut_d(block->in_withdraw_list = TRUE);
-				count1++;
-			}
-
-			block = next_block;
-		}
-		buf_pool_mutex_exit(buf_pool);
-
-		/* reserve free_list length */
-		if (UT_LIST_GET_LEN(buf_pool->withdraw)
-		    < buf_pool->withdraw_target) {
-			ulint	scan_depth;
-			flush_counters_t n;
-
-			/* cap scan_depth with current LRU size. */
-			buf_pool_mutex_enter(buf_pool);
-			scan_depth = UT_LIST_GET_LEN(buf_pool->LRU);
-			buf_pool_mutex_exit(buf_pool);
-
-			scan_depth = ut_min(
-				ut_max(buf_pool->withdraw_target
-				       - UT_LIST_GET_LEN(buf_pool->withdraw),
-				       static_cast<ulint>(srv_LRU_scan_depth)),
-				scan_depth);
-
-			buf_flush_do_batch(buf_pool, BUF_FLUSH_LRU,
-				scan_depth, 0, &n);
-			buf_flush_wait_batch_end(buf_pool, BUF_FLUSH_LRU);
-
-			if (n.flushed) {
-				MONITOR_INC_VALUE_CUMULATIVE(
-					MONITOR_LRU_BATCH_FLUSH_TOTAL_PAGE,
-					MONITOR_LRU_BATCH_FLUSH_COUNT,
-					MONITOR_LRU_BATCH_FLUSH_PAGES,
-					n.flushed);
-			}
-		}
-
-		/* relocate blocks/buddies in withdrawn area */
-		ulint	count2 = 0;
-
-		buf_pool_mutex_enter(buf_pool);
-		buf_page_t*	bpage;
-		bpage = UT_LIST_GET_FIRST(buf_pool->LRU);
-		while (bpage != NULL) {
-			BPageMutex*	block_mutex;
-			buf_page_t*	next_bpage;
-
-			block_mutex = buf_page_get_mutex(bpage);
-			mutex_enter(block_mutex);
-
-			next_bpage = UT_LIST_GET_NEXT(LRU, bpage);
-
-			if (bpage->zip.data != NULL
-			    && buf_frame_will_withdrawn(
-				buf_pool,
-				static_cast<byte*>(bpage->zip.data))) {
-
-				if (buf_page_can_relocate(bpage)) {
-					mutex_exit(block_mutex);
-					buf_pool_mutex_exit_forbid(buf_pool);
-					if(!buf_buddy_realloc(
-						buf_pool, bpage->zip.data,
-						page_zip_get_size(
-							&bpage->zip))) {
-
-						/* failed to allocate block */
-						buf_pool_mutex_exit_allow(
-							buf_pool);
-						break;
-					}
-					buf_pool_mutex_exit_allow(buf_pool);
-					mutex_enter(block_mutex);
-					count2++;
-				}
-				/* NOTE: if the page is in use,
-				not reallocated yet */
-			}
-
-			if (buf_page_get_state(bpage)
-			    == BUF_BLOCK_FILE_PAGE
-			    && buf_block_will_withdrawn(
-				buf_pool,
-				reinterpret_cast<buf_block_t*>(bpage))) {
-
-				if (buf_page_can_relocate(bpage)) {
-					mutex_exit(block_mutex);
-					buf_pool_mutex_exit_forbid(buf_pool);
-					if(!buf_page_realloc(
-						buf_pool,
-						reinterpret_cast<buf_block_t*>(
-							bpage))) {
-						/* failed to allocate block */
-						buf_pool_mutex_exit_allow(
-							buf_pool);
-						break;
-					}
-					buf_pool_mutex_exit_allow(buf_pool);
-					count2++;
-				} else {
-					mutex_exit(block_mutex);
-				}
-				/* NOTE: if the page is in use,
-				not reallocated yet */
-			} else {
-				mutex_exit(block_mutex);
-			}
-
-			bpage = next_bpage;
-		}
-		buf_pool_mutex_exit(buf_pool);
-
-		buf_resize_status(
-			"buffer pool %lu : withdrawing blocks. (%lu/%lu)",
-			i, UT_LIST_GET_LEN(buf_pool->withdraw),
-			buf_pool->withdraw_target);
-
-		ib::info() << "buffer pool " << i << " : withdrew "
-			<< count1 << " blocks from free list."
-			<< " Tried to relocate " << count2 << " pages ("
-			<< UT_LIST_GET_LEN(buf_pool->withdraw) << "/"
-			<< buf_pool->withdraw_target << ").";
-
-		if (++loop_count >= 10) {
-			/* give up for now.
-			retried after user threads paused. */
-
-			ib::info() << "buffer pool " << i
-				<< " : will retry to withdraw later.";
-
-			/* need retry later */
-			return(true);
-		}
-	}
-
-	/* confirm withdrawn enough */
-	const buf_chunk_t*	chunk
-		= buf_pool->chunks + buf_pool->n_chunks_new;
-	const buf_chunk_t*	echunk
-		= buf_pool->chunks + buf_pool->n_chunks;
-
-	while (chunk < echunk) {
-		block = chunk->blocks;
-		for (ulint j = chunk->size; j--; block++) {
-			/* If !=BUF_BLOCK_NOT_USED block in the
-			withdrawn area, it means corruption
-			something */
-			ut_a(buf_block_get_state(block)
-				== BUF_BLOCK_NOT_USED);
-			ut_ad(block->in_withdraw_list);
-		}
-		++chunk;
-	}
-
-	ib::info() << "buffer pool " << i << " : withdrawn target "
-		<< UT_LIST_GET_LEN(buf_pool->withdraw) << " blocks.";
-
-	/* retry is not needed */
-	++buf_withdraw_clock;
-
-	return(false);
+  buf_block_t*	block;
+  ulint		loop_count = 0;
+  ulint		i = buf_pool_index(buf_pool);
+
+  ib::info() << "buffer pool " << i
+    << " : start to withdraw the last "
+    << buf_pool->withdraw_target << " blocks.";
+
+  /* Minimize buf_pool->zip_free[i] lists */
+  buf_pool_mutex_enter(buf_pool);
+  buf_buddy_condense_free(buf_pool);
+  buf_pool_mutex_exit(buf_pool);
+
+  while (UT_LIST_GET_LEN(buf_pool->withdraw)
+         < buf_pool->withdraw_target) {
+
+    /* try to withdraw from free_list */
+    ulint	count1 = 0;
+
+    buf_pool_mutex_enter(buf_pool);
+    block = reinterpret_cast<buf_block_t*>(
+      UT_LIST_GET_FIRST(buf_pool->free));
+    while (block != NULL
+           && UT_LIST_GET_LEN(buf_pool->withdraw)
+        < buf_pool->withdraw_target) {
+      ut_ad(block->page.in_free_list);
+      ut_ad(!block->page.in_flush_list);
+      ut_ad(!block->page.in_LRU_list);
+      ut_a(!buf_page_in_file(&block->page));
+
+      buf_block_t*	next_block;
+      next_block = reinterpret_cast<buf_block_t*>(
+        UT_LIST_GET_NEXT(
+          list, &block->page));
+
+      if (buf_block_will_withdrawn(buf_pool, block)) {
+        /* This should be withdrawn */
+        UT_LIST_REMOVE(
+          buf_pool->free,
+          &block->page);
+        UT_LIST_ADD_LAST(
+          buf_pool->withdraw,
+          &block->page);
+        ut_d(block->in_withdraw_list = TRUE);
+        count1++;
+      }
+
+      block = next_block;
+    }
+    buf_pool_mutex_exit(buf_pool);
+
+    /* reserve free_list length */
+    if (UT_LIST_GET_LEN(buf_pool->withdraw)
+        < buf_pool->withdraw_target) {
+      ulint	scan_depth;
+      flush_counters_t n;
+
+      /* cap scan_depth with current LRU size. */
+      buf_pool_mutex_enter(buf_pool);
+      scan_depth = UT_LIST_GET_LEN(buf_pool->LRU);
+      buf_pool_mutex_exit(buf_pool);
+
+      scan_depth = ut_min(
+        ut_max(buf_pool->withdraw_target
+               - UT_LIST_GET_LEN(buf_pool->withdraw),
+               static_cast<ulint>(srv_LRU_scan_depth)),
+        scan_depth);
+
+      buf_flush_do_batch(buf_pool, BUF_FLUSH_LRU,
+        scan_depth, 0, &n);
+      buf_flush_wait_batch_end(buf_pool, BUF_FLUSH_LRU);
+
+      if (n.flushed) {
+        MONITOR_INC_VALUE_CUMULATIVE(
+          MONITOR_LRU_BATCH_FLUSH_TOTAL_PAGE,
+          MONITOR_LRU_BATCH_FLUSH_COUNT,
+          MONITOR_LRU_BATCH_FLUSH_PAGES,
+          n.flushed);
+      }
+    }
+
+    /* relocate blocks/buddies in withdrawn area */
+    ulint	count2 = 0;
+
+    buf_pool_mutex_enter(buf_pool);
+    buf_page_t*	bpage;
+    bpage = UT_LIST_GET_FIRST(buf_pool->LRU);
+    while (bpage != NULL) {
+      BPageMutex*	block_mutex;
+      buf_page_t*	next_bpage;
+
+      block_mutex = buf_page_get_mutex(bpage);
+      mutex_enter(block_mutex);
+
+      next_bpage = UT_LIST_GET_NEXT(LRU, bpage);
+
+      if (bpage->zip.data != NULL
+          && buf_frame_will_withdrawn(
+        buf_pool,
+        static_cast<byte*>(bpage->zip.data))) {
+
+        if (buf_page_can_relocate(bpage)) {
+          mutex_exit(block_mutex);
+          buf_pool_mutex_exit_forbid(buf_pool);
+          if(!buf_buddy_realloc(
+            buf_pool, bpage->zip.data,
+            page_zip_get_size(
+              &bpage->zip))) {
+
+            /* failed to allocate block */
+            buf_pool_mutex_exit_allow(
+              buf_pool);
+            break;
+          }
+          buf_pool_mutex_exit_allow(buf_pool);
+          mutex_enter(block_mutex);
+          count2++;
+        }
+        /* NOTE: if the page is in use,
+        not reallocated yet */
+      }
+
+      if (buf_page_get_state(bpage)
+          == BUF_BLOCK_FILE_PAGE
+          && buf_block_will_withdrawn(
+        buf_pool,
+        reinterpret_cast<buf_block_t*>(bpage))) {
+
+        if (buf_page_can_relocate(bpage)) {
+          mutex_exit(block_mutex);
+          buf_pool_mutex_exit_forbid(buf_pool);
+          if(!buf_page_realloc(
+            buf_pool,
+            reinterpret_cast<buf_block_t*>(
+              bpage))) {
+            /* failed to allocate block */
+            buf_pool_mutex_exit_allow(
+              buf_pool);
+            break;
+          }
+          buf_pool_mutex_exit_allow(buf_pool);
+          count2++;
+        } else {
+          mutex_exit(block_mutex);
+        }
+        /* NOTE: if the page is in use,
+        not reallocated yet */
+      } else {
+        mutex_exit(block_mutex);
+      }
+
+      bpage = next_bpage;
+    }
+    buf_pool_mutex_exit(buf_pool);
+
+    buf_resize_status(
+      "buffer pool %lu : withdrawing blocks. (%lu/%lu)",
+      i, UT_LIST_GET_LEN(buf_pool->withdraw),
+      buf_pool->withdraw_target);
+
+    ib::info() << "buffer pool " << i << " : withdrew "
+      << count1 << " blocks from free list."
+      << " Tried to relocate " << count2 << " pages ("
+      << UT_LIST_GET_LEN(buf_pool->withdraw) << "/"
+      << buf_pool->withdraw_target << ").";
+
+    if (++loop_count >= 10) {
+      /* give up for now.
+      retried after user threads paused. */
+
+      ib::info() << "buffer pool " << i
+        << " : will retry to withdraw later.";
+
+      /* need retry later */
+      return(true);
+    }
+  }
+
+  /* confirm withdrawn enough */
+  const buf_chunk_t*	chunk
+    = buf_pool->chunks + buf_pool->n_chunks_new;
+  const buf_chunk_t*	echunk
+    = buf_pool->chunks + buf_pool->n_chunks;
+
+  while (chunk < echunk) {
+    block = chunk->blocks;
+    for (ulint j = chunk->size; j--; block++) {
+      /* If !=BUF_BLOCK_NOT_USED block in the
+      withdrawn area, it means corruption
+      something */
+      ut_a(buf_block_get_state(block)
+        == BUF_BLOCK_NOT_USED);
+      ut_ad(block->in_withdraw_list);
+    }
+    ++chunk;
+  }
+
+  ib::info() << "buffer pool " << i << " : withdrawn target "
+    << UT_LIST_GET_LEN(buf_pool->withdraw) << " blocks.";
+
+  /* retry is not needed */
+  ++buf_withdraw_clock;
+
+  return(false);
 }
 
 /** resize page_hash and zip_hash for a buffer pool instance.
@@ -2618,79 +2721,79 @@ buf_pool_withdraw_blocks(
 static
 void
 buf_pool_resize_hash(
-	buf_pool_t*	buf_pool)
+  buf_pool_t*	buf_pool)
 {
-	hash_table_t*	new_hash_table;
+  hash_table_t*	new_hash_table;
 
-	ut_ad(buf_pool->page_hash_old == NULL);
+  ut_ad(buf_pool->page_hash_old == NULL);
 
-	/* recreate page_hash */
-	new_hash_table = ib_recreate(
-		buf_pool->page_hash, 2 * buf_pool->curr_size);
+  /* recreate page_hash */
+  new_hash_table = ib_recreate(
+    buf_pool->page_hash, 2 * buf_pool->curr_size);
 
-	for (ulint i = 0; i < hash_get_n_cells(buf_pool->page_hash); i++) {
-		buf_page_t*	bpage;
+  for (ulint i = 0; i < hash_get_n_cells(buf_pool->page_hash); i++) {
+    buf_page_t*	bpage;
 
-		bpage = static_cast<buf_page_t*>(
-			HASH_GET_FIRST(
-				buf_pool->page_hash, i));
+    bpage = static_cast<buf_page_t*>(
+      HASH_GET_FIRST(
+        buf_pool->page_hash, i));
 
-		while (bpage) {
-			buf_page_t*	prev_bpage = bpage;
-			ulint		fold;
+    while (bpage) {
+      buf_page_t*	prev_bpage = bpage;
+      ulint		fold;
 
-			bpage = static_cast<buf_page_t*>(
-				HASH_GET_NEXT(
-					hash, prev_bpage));
+      bpage = static_cast<buf_page_t*>(
+        HASH_GET_NEXT(
+          hash, prev_bpage));
 
-			fold = prev_bpage->id.fold();
+      fold = prev_bpage->id.fold();
 
-			HASH_DELETE(buf_page_t, hash,
-				buf_pool->page_hash, fold,
-				prev_bpage);
+      HASH_DELETE(buf_page_t, hash,
+        buf_pool->page_hash, fold,
+        prev_bpage);
 
-			HASH_INSERT(buf_page_t, hash,
-				new_hash_table, fold,
-				prev_bpage);
-		}
-	}
+      HASH_INSERT(buf_page_t, hash,
+        new_hash_table, fold,
+        prev_bpage);
+    }
+  }
 
-	buf_pool->page_hash_old = buf_pool->page_hash;
-	buf_pool->page_hash = new_hash_table;
+  buf_pool->page_hash_old = buf_pool->page_hash;
+  buf_pool->page_hash = new_hash_table;
 
-	/* recreate zip_hash */
-	new_hash_table = hash_create(2 * buf_pool->curr_size);
+  /* recreate zip_hash */
+  new_hash_table = hash_create(2 * buf_pool->curr_size);
 
-	for (ulint i = 0; i < hash_get_n_cells(buf_pool->zip_hash); i++) {
-		buf_page_t*	bpage;
+  for (ulint i = 0; i < hash_get_n_cells(buf_pool->zip_hash); i++) {
+    buf_page_t*	bpage;
 
-		bpage = static_cast<buf_page_t*>(
-			HASH_GET_FIRST(buf_pool->zip_hash, i));
+    bpage = static_cast<buf_page_t*>(
+      HASH_GET_FIRST(buf_pool->zip_hash, i));
 
-		while (bpage) {
-			buf_page_t*	prev_bpage = bpage;
-			ulint		fold;
+    while (bpage) {
+      buf_page_t*	prev_bpage = bpage;
+      ulint		fold;
 
-			bpage = static_cast<buf_page_t*>(
-				HASH_GET_NEXT(
-					hash, prev_bpage));
+      bpage = static_cast<buf_page_t*>(
+        HASH_GET_NEXT(
+          hash, prev_bpage));
 
-			fold = BUF_POOL_ZIP_FOLD(
-				reinterpret_cast<buf_block_t*>(
-					prev_bpage));
+      fold = BUF_POOL_ZIP_FOLD(
+        reinterpret_cast<buf_block_t*>(
+          prev_bpage));
 
-			HASH_DELETE(buf_page_t, hash,
-				buf_pool->zip_hash, fold,
-				prev_bpage);
+      HASH_DELETE(buf_page_t, hash,
+        buf_pool->zip_hash, fold,
+        prev_bpage);
 
-			HASH_INSERT(buf_page_t, hash,
-				new_hash_table, fold,
-				prev_bpage);
-		}
-	}
+      HASH_INSERT(buf_page_t, hash,
+        new_hash_table, fold,
+        prev_bpage);
+    }
+  }
 
-	hash_table_free(buf_pool->zip_hash);
-	buf_pool->zip_hash = new_hash_table;
+  hash_table_free(buf_pool->zip_hash);
+  buf_pool->zip_hash = new_hash_table;
 }
 
 #ifndef DBUG_OFF
@@ -2699,14 +2802,14 @@ static
 void
 buf_pool_resize_chunk_make_null(buf_chunk_t** new_chunks)
 {
-	static int count = 0;
+  static int count = 0;
 
-	if (count == 1) {
-		ut_free(*new_chunks);
-		*new_chunks = NULL;
-	}
+  if (count == 1) {
+    ut_free(*new_chunks);
+    *new_chunks = NULL;
+  }
 
-	count++;
+  count++;
 }
 #endif // DBUG_OFF
 
@@ -2716,474 +2819,474 @@ static
 void
 buf_pool_resize()
 {
-	buf_pool_t*	buf_pool;
-	ulint		new_instance_size;
-	bool		warning = false;
+  buf_pool_t*	buf_pool;
+  ulint		new_instance_size;
+  bool		warning = false;
 
-	NUMA_MEMPOLICY_INTERLEAVE_IN_SCOPE;
+  NUMA_MEMPOLICY_INTERLEAVE_IN_SCOPE;
 
-	ut_ad(!buf_pool_resizing);
-	ut_ad(!buf_pool_withdrawing);
-	ut_ad(srv_buf_pool_chunk_unit > 0);
+  ut_ad(!buf_pool_resizing);
+  ut_ad(!buf_pool_withdrawing);
+  ut_ad(srv_buf_pool_chunk_unit > 0);
 
-	new_instance_size = srv_buf_pool_size / srv_buf_pool_instances;
-	new_instance_size >>= srv_page_size_shift;
+  new_instance_size = srv_buf_pool_size / srv_buf_pool_instances;
+  new_instance_size >>= srv_page_size_shift;
 
-	buf_resize_status("Resizing buffer pool from " ULINTPF " to "
-			  ULINTPF " (unit=" ULINTPF ").",
-			  srv_buf_pool_old_size, srv_buf_pool_size,
-			  srv_buf_pool_chunk_unit);
+  buf_resize_status("Resizing buffer pool from " ULINTPF " to "
+        ULINTPF " (unit=" ULINTPF ").",
+        srv_buf_pool_old_size, srv_buf_pool_size,
+        srv_buf_pool_chunk_unit);
 
-	/* set new limit for all buffer pool for resizing */
-	for (ulint i = 0; i < srv_buf_pool_instances; i++) {
-		buf_pool = buf_pool_from_array(i);
-		buf_pool_mutex_enter(buf_pool);
+  /* set new limit for all buffer pool for resizing */
+  for (ulint i = 0; i < srv_buf_pool_instances; i++) {
+    buf_pool = buf_pool_from_array(i);
+    buf_pool_mutex_enter(buf_pool);
 
-		ut_ad(buf_pool->curr_size == buf_pool->old_size);
-		ut_ad(buf_pool->n_chunks_new == buf_pool->n_chunks);
-		ut_ad(UT_LIST_GET_LEN(buf_pool->withdraw) == 0);
-		ut_ad(buf_pool->flush_rbt == NULL);
+    ut_ad(buf_pool->curr_size == buf_pool->old_size);
+    ut_ad(buf_pool->n_chunks_new == buf_pool->n_chunks);
+    ut_ad(UT_LIST_GET_LEN(buf_pool->withdraw) == 0);
+    ut_ad(buf_pool->flush_rbt == NULL);
 
-		buf_pool->n_chunks_new =
-			(new_instance_size << srv_page_size_shift)
-			/ srv_buf_pool_chunk_unit;
+    buf_pool->n_chunks_new =
+      (new_instance_size << srv_page_size_shift)
+      / srv_buf_pool_chunk_unit;
 
-		buf_pool->curr_size = buf_pool->n_chunks_new * buf_pool->chunks->size;
+    buf_pool->curr_size = buf_pool->n_chunks_new * buf_pool->chunks->size;
 
-		buf_pool_mutex_exit(buf_pool);
-	}
+    buf_pool_mutex_exit(buf_pool);
+  }
 #ifdef BTR_CUR_HASH_ADAPT
-	/* disable AHI if needed */
-	bool	btr_search_disabled = false;
+  /* disable AHI if needed */
+  bool	btr_search_disabled = false;
 
-	buf_resize_status("Disabling adaptive hash index.");
+  buf_resize_status("Disabling adaptive hash index.");
 
-	btr_search_s_lock_all();
-	if (btr_search_enabled) {
-		btr_search_s_unlock_all();
-		btr_search_disabled = true;
-	} else {
-		btr_search_s_unlock_all();
-	}
+  btr_search_s_lock_all();
+  if (btr_search_enabled) {
+    btr_search_s_unlock_all();
+    btr_search_disabled = true;
+  } else {
+    btr_search_s_unlock_all();
+  }
 
-	btr_search_disable(true);
+  btr_search_disable(true);
 
-	if (btr_search_disabled) {
-		ib::info() << "disabled adaptive hash index.";
-	}
+  if (btr_search_disabled) {
+    ib::info() << "disabled adaptive hash index.";
+  }
 #endif /* BTR_CUR_HASH_ADAPT */
 
-	/* set withdraw target */
-	for (ulint i = 0; i < srv_buf_pool_instances; i++) {
-		buf_pool = buf_pool_from_array(i);
-		if (buf_pool->curr_size < buf_pool->old_size) {
-			ulint	withdraw_target = 0;
+  /* set withdraw target */
+  for (ulint i = 0; i < srv_buf_pool_instances; i++) {
+    buf_pool = buf_pool_from_array(i);
+    if (buf_pool->curr_size < buf_pool->old_size) {
+      ulint	withdraw_target = 0;
+
+      const buf_chunk_t*	chunk
+        = buf_pool->chunks + buf_pool->n_chunks_new;
+      const buf_chunk_t*	echunk
+        = buf_pool->chunks + buf_pool->n_chunks;
+
+      while (chunk < echunk) {
+        withdraw_target += chunk->size;
+        ++chunk;
+      }
+
+      ut_ad(buf_pool->withdraw_target == 0);
+      buf_pool->withdraw_target = withdraw_target;
+      buf_pool_withdrawing = true;
+    }
+  }
 
-			const buf_chunk_t*	chunk
-				= buf_pool->chunks + buf_pool->n_chunks_new;
-			const buf_chunk_t*	echunk
-				= buf_pool->chunks + buf_pool->n_chunks;
+  buf_resize_status("Withdrawing blocks to be shrunken.");
 
-			while (chunk < echunk) {
-				withdraw_target += chunk->size;
-				++chunk;
-			}
+  time_t		withdraw_started = time(NULL);
+  ulint		message_interval = 60;
+  ulint		retry_interval = 1;
 
-			ut_ad(buf_pool->withdraw_target == 0);
-			buf_pool->withdraw_target = withdraw_target;
-			buf_pool_withdrawing = true;
-		}
-	}
+withdraw_retry:
+  bool	should_retry_withdraw = false;
 
-	buf_resize_status("Withdrawing blocks to be shrunken.");
+  /* wait for the number of blocks fit to the new size (if needed)*/
+  for (ulint i = 0; i < srv_buf_pool_instances; i++) {
+    buf_pool = buf_pool_from_array(i);
+    if (buf_pool->curr_size < buf_pool->old_size) {
 
-	time_t		withdraw_started = time(NULL);
-	ulint		message_interval = 60;
-	ulint		retry_interval = 1;
+      should_retry_withdraw |=
+        buf_pool_withdraw_blocks(buf_pool);
+    }
+  }
 
-withdraw_retry:
-	bool	should_retry_withdraw = false;
-
-	/* wait for the number of blocks fit to the new size (if needed)*/
-	for (ulint i = 0; i < srv_buf_pool_instances; i++) {
-		buf_pool = buf_pool_from_array(i);
-		if (buf_pool->curr_size < buf_pool->old_size) {
-
-			should_retry_withdraw |=
-				buf_pool_withdraw_blocks(buf_pool);
-		}
-	}
-
-	if (srv_shutdown_state != SRV_SHUTDOWN_NONE) {
-		/* abort to resize for shutdown. */
-		buf_pool_withdrawing = false;
-		return;
-	}
-
-	/* abort buffer pool load */
-	buf_load_abort();
-
-	const time_t current_time = time(NULL);
-
-	if (should_retry_withdraw
-	    && difftime(current_time, withdraw_started) >= message_interval) {
-
-		if (message_interval > 900) {
-			message_interval = 1800;
-		} else {
-			message_interval *= 2;
-		}
-
-		lock_mutex_enter();
-		mutex_enter(&trx_sys.mutex);
-		bool	found = false;
-		for (trx_t* trx = UT_LIST_GET_FIRST(trx_sys.trx_list);
-		     trx != NULL;
-		     trx = UT_LIST_GET_NEXT(trx_list, trx)) {
-			if (trx->state != TRX_STATE_NOT_STARTED
-			    && trx->mysql_thd != NULL
-			    && withdraw_started > trx->start_time) {
-				if (!found) {
-					ib::warn() <<
-						"The following trx might hold"
-						" the blocks in buffer pool to"
-					        " be withdrawn. Buffer pool"
-						" resizing can complete only"
-						" after all the transactions"
-						" below release the blocks.";
-					found = true;
-				}
-
-				lock_trx_print_wait_and_mvcc_state(
-					stderr, trx, current_time);
-			}
-		}
-		mutex_exit(&trx_sys.mutex);
-		lock_mutex_exit();
-
-		withdraw_started = current_time;
-	}
-
-	if (should_retry_withdraw) {
-		ib::info() << "Will retry to withdraw " << retry_interval
-			<< " seconds later.";
-		os_thread_sleep(retry_interval * 1000000);
-
-		if (retry_interval > 5) {
-			retry_interval = 10;
-		} else {
-			retry_interval *= 2;
-		}
-
-		goto withdraw_retry;
-	}
-
-	buf_pool_withdrawing = false;
-
-	buf_resize_status("Latching whole of buffer pool.");
+  if (srv_shutdown_state != SRV_SHUTDOWN_NONE) {
+    /* abort to resize for shutdown. */
+    buf_pool_withdrawing = false;
+    return;
+  }
 
-#ifndef DBUG_OFF
-	{
-		bool	should_wait = true;
-
-		while (should_wait) {
-			should_wait = false;
-			DBUG_EXECUTE_IF(
-				"ib_buf_pool_resize_wait_before_resize",
-				should_wait = true; os_thread_sleep(10000););
-		}
-	}
-#endif /* !DBUG_OFF */
+  /* abort buffer pool load */
+  buf_load_abort();
 
-	if (srv_shutdown_state != SRV_SHUTDOWN_NONE) {
-		return;
-	}
+  const time_t current_time = time(NULL);
 
-	/* Indicate critical path */
-	buf_pool_resizing = true;
-
-	/* Acquire all buf_pool_mutex/hash_lock */
-	for (ulint i = 0; i < srv_buf_pool_instances; ++i) {
-		buf_pool_t*	buf_pool = buf_pool_from_array(i);
+  if (should_retry_withdraw
+      && difftime(current_time, withdraw_started) >= message_interval) {
 
-		buf_pool_mutex_enter(buf_pool);
-	}
-	for (ulint i = 0; i < srv_buf_pool_instances; ++i) {
-		buf_pool_t*	buf_pool = buf_pool_from_array(i);
+    if (message_interval > 900) {
+      message_interval = 1800;
+    } else {
+      message_interval *= 2;
+    }
 
-		hash_lock_x_all(buf_pool->page_hash);
-	}
+    lock_mutex_enter();
+    mutex_enter(&trx_sys.mutex);
+    bool	found = false;
+    for (trx_t* trx = UT_LIST_GET_FIRST(trx_sys.trx_list);
+         trx != NULL;
+         trx = UT_LIST_GET_NEXT(trx_list, trx)) {
+      if (trx->state != TRX_STATE_NOT_STARTED
+          && trx->mysql_thd != NULL
+          && withdraw_started > trx->start_time) {
+        if (!found) {
+          ib::warn() <<
+            "The following trx might hold"
+            " the blocks in buffer pool to"
+                  " be withdrawn. Buffer pool"
+            " resizing can complete only"
+            " after all the transactions"
+            " below release the blocks.";
+          found = true;
+        }
+
+        lock_trx_print_wait_and_mvcc_state(
+          stderr, trx, current_time);
+      }
+    }
+    mutex_exit(&trx_sys.mutex);
+    lock_mutex_exit();
 
-	buf_chunk_map_reg = UT_NEW_NOKEY(buf_pool_chunk_map_t());
+    withdraw_started = current_time;
+  }
 
-	/* add/delete chunks */
-	for (ulint i = 0; i < srv_buf_pool_instances; ++i) {
-		buf_pool_t*	buf_pool = buf_pool_from_array(i);
-		buf_chunk_t*	chunk;
-		buf_chunk_t*	echunk;
+  if (should_retry_withdraw) {
+    ib::info() << "Will retry to withdraw " << retry_interval
+      << " seconds later.";
+    os_thread_sleep(retry_interval * 1000000);
 
-		buf_resize_status("buffer pool %lu :"
-			" resizing with chunks %lu to %lu.",
-			i, buf_pool->n_chunks, buf_pool->n_chunks_new);
+    if (retry_interval > 5) {
+      retry_interval = 10;
+    } else {
+      retry_interval *= 2;
+    }
 
-		if (buf_pool->n_chunks_new < buf_pool->n_chunks) {
-			/* delete chunks */
-			chunk = buf_pool->chunks
-				+ buf_pool->n_chunks_new;
-			echunk = buf_pool->chunks + buf_pool->n_chunks;
+    goto withdraw_retry;
+  }
 
-			ulint	sum_freed = 0;
+  buf_pool_withdrawing = false;
 
-			while (chunk < echunk) {
-				buf_block_t*	block = chunk->blocks;
+  buf_resize_status("Latching whole of buffer pool.");
 
-				for (ulint j = chunk->size;
-				     j--; block++) {
-					buf_block_free_mutexes(block);
-				}
+#ifndef DBUG_OFF
+  {
+    bool	should_wait = true;
+
+    while (should_wait) {
+      should_wait = false;
+      DBUG_EXECUTE_IF(
+        "ib_buf_pool_resize_wait_before_resize",
+        should_wait = true; os_thread_sleep(10000););
+    }
+  }
+#endif /* !DBUG_OFF */
+
+  if (srv_shutdown_state != SRV_SHUTDOWN_NONE) {
+    return;
+  }
+
+  /* Indicate critical path */
+  buf_pool_resizing = true;
 
-				buf_pool->allocator.deallocate_large_dodump(
-					chunk->mem, &chunk->mem_pfx, chunk->mem_size());
+  /* Acquire all buf_pool_mutex/hash_lock */
+  for (ulint i = 0; i < srv_buf_pool_instances; ++i) {
+    buf_pool_t*	buf_pool = buf_pool_from_array(i);
 
-				sum_freed += chunk->size;
+    buf_pool_mutex_enter(buf_pool);
+  }
+  for (ulint i = 0; i < srv_buf_pool_instances; ++i) {
+    buf_pool_t*	buf_pool = buf_pool_from_array(i);
 
-				++chunk;
-			}
+    hash_lock_x_all(buf_pool->page_hash);
+  }
 
-			/* discard withdraw list */
-			UT_LIST_INIT(buf_pool->withdraw,
-				     &buf_page_t::list);
-			buf_pool->withdraw_target = 0;
+  buf_chunk_map_reg = UT_NEW_NOKEY(buf_pool_chunk_map_t());
 
-			ib::info() << "buffer pool " << i << " : "
-				<< buf_pool->n_chunks - buf_pool->n_chunks_new
-				<< " chunks (" << sum_freed
-				<< " blocks) were freed.";
+  /* add/delete chunks */
+  for (ulint i = 0; i < srv_buf_pool_instances; ++i) {
+    buf_pool_t*	buf_pool = buf_pool_from_array(i);
+    buf_chunk_t*	chunk;
+    buf_chunk_t*	echunk;
 
-			buf_pool->n_chunks = buf_pool->n_chunks_new;
-		}
+    buf_resize_status("buffer pool %lu :"
+      " resizing with chunks %lu to %lu.",
+      i, buf_pool->n_chunks, buf_pool->n_chunks_new);
 
-		{
-			/* reallocate buf_pool->chunks */
-			const ulint	new_chunks_size
-				= buf_pool->n_chunks_new * sizeof(*chunk);
+    if (buf_pool->n_chunks_new < buf_pool->n_chunks) {
+      /* delete chunks */
+      chunk = buf_pool->chunks
+        + buf_pool->n_chunks_new;
+      echunk = buf_pool->chunks + buf_pool->n_chunks;
 
-			buf_chunk_t*	new_chunks
-				= reinterpret_cast<buf_chunk_t*>(
-					ut_zalloc_nokey_nofatal(new_chunks_size));
+      ulint	sum_freed = 0;
 
-			DBUG_EXECUTE_IF("buf_pool_resize_chunk_null",
-				buf_pool_resize_chunk_make_null(&new_chunks););
+      while (chunk < echunk) {
+        buf_block_t*	block = chunk->blocks;
 
-			if (new_chunks == NULL) {
-				ib::error() << "buffer pool " << i
-					<< " : failed to allocate"
-					" the chunk array.";
-				buf_pool->n_chunks_new
-					= buf_pool->n_chunks;
-				warning = true;
-				buf_pool->chunks_old = NULL;
-				for (ulint j = 0; j < buf_pool->n_chunks_new; j++) {
-					buf_pool_register_chunk(&(buf_pool->chunks[j]));
-				}
-				goto calc_buf_pool_size;
-			}
+        for (ulint j = chunk->size;
+             j--; block++) {
+          buf_block_free_mutexes(block);
+        }
 
-			ulint	n_chunks_copy = ut_min(buf_pool->n_chunks_new,
-						       buf_pool->n_chunks);
+        buf_pool->allocator.deallocate_large_dodump(
+          chunk->mem, &chunk->mem_pfx, chunk->mem_size());
 
-			memcpy(new_chunks, buf_pool->chunks,
-			       n_chunks_copy * sizeof(*chunk));
+        sum_freed += chunk->size;
 
-			for (ulint j = 0; j < n_chunks_copy; j++) {
-				buf_pool_register_chunk(&new_chunks[j]);
-			}
+        ++chunk;
+      }
 
-			buf_pool->chunks_old = buf_pool->chunks;
-			buf_pool->chunks = new_chunks;
-		}
+      /* discard withdraw list */
+      UT_LIST_INIT(buf_pool->withdraw,
+             &buf_page_t::list);
+      buf_pool->withdraw_target = 0;
 
+      ib::info() << "buffer pool " << i << " : "
+        << buf_pool->n_chunks - buf_pool->n_chunks_new
+        << " chunks (" << sum_freed
+        << " blocks) were freed.";
 
-		if (buf_pool->n_chunks_new > buf_pool->n_chunks) {
-			/* add chunks */
-			chunk = buf_pool->chunks + buf_pool->n_chunks;
-			echunk = buf_pool->chunks
-				+ buf_pool->n_chunks_new;
+      buf_pool->n_chunks = buf_pool->n_chunks_new;
+    }
+
+    {
+      /* reallocate buf_pool->chunks */
+      const ulint	new_chunks_size
+        = buf_pool->n_chunks_new * sizeof(*chunk);
+
+      buf_chunk_t*	new_chunks
+        = reinterpret_cast<buf_chunk_t*>(
+          ut_zalloc_nokey_nofatal(new_chunks_size));
+
+      DBUG_EXECUTE_IF("buf_pool_resize_chunk_null",
+        buf_pool_resize_chunk_make_null(&new_chunks););
+
+      if (new_chunks == NULL) {
+        ib::error() << "buffer pool " << i
+          << " : failed to allocate"
+          " the chunk array.";
+        buf_pool->n_chunks_new
+          = buf_pool->n_chunks;
+        warning = true;
+        buf_pool->chunks_old = NULL;
+        for (ulint j = 0; j < buf_pool->n_chunks_new; j++) {
+          buf_pool_register_chunk(&(buf_pool->chunks[j]));
+        }
+        goto calc_buf_pool_size;
+      }
+
+      ulint	n_chunks_copy = ut_min(buf_pool->n_chunks_new,
+                   buf_pool->n_chunks);
+
+      memcpy(new_chunks, buf_pool->chunks,
+             n_chunks_copy * sizeof(*chunk));
+
+      for (ulint j = 0; j < n_chunks_copy; j++) {
+        buf_pool_register_chunk(&new_chunks[j]);
+      }
+
+      buf_pool->chunks_old = buf_pool->chunks;
+      buf_pool->chunks = new_chunks;
+    }
 
-			ulint	sum_added = 0;
-			ulint	n_chunks = buf_pool->n_chunks;
 
-			while (chunk < echunk) {
-				ulong	unit = srv_buf_pool_chunk_unit;
+    if (buf_pool->n_chunks_new > buf_pool->n_chunks) {
+      /* add chunks */
+      chunk = buf_pool->chunks + buf_pool->n_chunks;
+      echunk = buf_pool->chunks
+        + buf_pool->n_chunks_new;
 
-				if (!buf_chunk_init(buf_pool, chunk, unit)) {
+      ulint	sum_added = 0;
+      ulint	n_chunks = buf_pool->n_chunks;
 
-					ib::error() << "buffer pool " << i
-						<< " : failed to allocate"
-						" new memory.";
+      while (chunk < echunk) {
+        ulong	unit = srv_buf_pool_chunk_unit;
 
-					warning = true;
+        if (!buf_chunk_init(buf_pool, chunk, unit)) {
 
-					buf_pool->n_chunks_new
-						= n_chunks;
+          ib::error() << "buffer pool " << i
+            << " : failed to allocate"
+            " new memory.";
 
-					break;
-				}
+          warning = true;
 
-				sum_added += chunk->size;
+          buf_pool->n_chunks_new
+            = n_chunks;
 
-				++n_chunks;
-				++chunk;
-			}
+          break;
+        }
 
-			ib::info() << "buffer pool " << i << " : "
-				<< buf_pool->n_chunks_new - buf_pool->n_chunks
-				<< " chunks (" << sum_added
-				<< " blocks) were added.";
+        sum_added += chunk->size;
 
-			buf_pool->n_chunks = n_chunks;
-		}
+        ++n_chunks;
+        ++chunk;
+      }
+
+      ib::info() << "buffer pool " << i << " : "
+        << buf_pool->n_chunks_new - buf_pool->n_chunks
+        << " chunks (" << sum_added
+        << " blocks) were added.";
+
+      buf_pool->n_chunks = n_chunks;
+    }
 calc_buf_pool_size:
 
-		/* recalc buf_pool->curr_size */
-		ulint	new_size = 0;
+    /* recalc buf_pool->curr_size */
+    ulint	new_size = 0;
 
-		chunk = buf_pool->chunks;
-		do {
-			new_size += chunk->size;
-		} while (++chunk < buf_pool->chunks
-				   + buf_pool->n_chunks);
+    chunk = buf_pool->chunks;
+    do {
+      new_size += chunk->size;
+    } while (++chunk < buf_pool->chunks
+           + buf_pool->n_chunks);
 
-		buf_pool->curr_size = new_size;
-		buf_pool->n_chunks_new = buf_pool->n_chunks;
+    buf_pool->curr_size = new_size;
+    buf_pool->n_chunks_new = buf_pool->n_chunks;
 
-		if (buf_pool->chunks_old) {
-			ut_free(buf_pool->chunks_old);
-			buf_pool->chunks_old = NULL;
-		}
-	}
+    if (buf_pool->chunks_old) {
+      ut_free(buf_pool->chunks_old);
+      buf_pool->chunks_old = NULL;
+    }
+  }
 
-	buf_pool_chunk_map_t*	chunk_map_old = buf_chunk_map_ref;
-	buf_chunk_map_ref = buf_chunk_map_reg;
+  buf_pool_chunk_map_t*	chunk_map_old = buf_chunk_map_ref;
+  buf_chunk_map_ref = buf_chunk_map_reg;
 
-	/* set instance sizes */
-	{
-		ulint	curr_size = 0;
+  /* set instance sizes */
+  {
+    ulint	curr_size = 0;
 
-		for (ulint i = 0; i < srv_buf_pool_instances; i++) {
-			buf_pool = buf_pool_from_array(i);
+    for (ulint i = 0; i < srv_buf_pool_instances; i++) {
+      buf_pool = buf_pool_from_array(i);
 
-			ut_ad(UT_LIST_GET_LEN(buf_pool->withdraw) == 0);
+      ut_ad(UT_LIST_GET_LEN(buf_pool->withdraw) == 0);
 
-			buf_pool->read_ahead_area =
-				ut_min(BUF_READ_AHEAD_PAGES,
-				       ut_2_power_up(buf_pool->curr_size /
-						      BUF_READ_AHEAD_PORTION));
-			buf_pool->curr_pool_size
-				= buf_pool->n_chunks * srv_buf_pool_chunk_unit;
-			curr_size += buf_pool->curr_pool_size;
-			buf_pool->old_size = buf_pool->curr_size;
-		}
-		srv_buf_pool_curr_size = curr_size;
-		innodb_set_buf_pool_size(buf_pool_size_align(curr_size));
-	}
+      buf_pool->read_ahead_area =
+        ut_min(BUF_READ_AHEAD_PAGES,
+               ut_2_power_up(buf_pool->curr_size /
+                  BUF_READ_AHEAD_PORTION));
+      buf_pool->curr_pool_size
+        = buf_pool->n_chunks * srv_buf_pool_chunk_unit;
+      curr_size += buf_pool->curr_pool_size;
+      buf_pool->old_size = buf_pool->curr_size;
+    }
+    srv_buf_pool_curr_size = curr_size;
+    innodb_set_buf_pool_size(buf_pool_size_align(curr_size));
+  }
 
-	const bool	new_size_too_diff
-		= srv_buf_pool_base_size > srv_buf_pool_size * 2
-			|| srv_buf_pool_base_size * 2 < srv_buf_pool_size;
+  const bool	new_size_too_diff
+    = srv_buf_pool_base_size > srv_buf_pool_size * 2
+      || srv_buf_pool_base_size * 2 < srv_buf_pool_size;
 
-	/* Normalize page_hash and zip_hash,
-	if the new size is too different */
-	if (!warning && new_size_too_diff) {
+  /* Normalize page_hash and zip_hash,
+  if the new size is too different */
+  if (!warning && new_size_too_diff) {
 
-		buf_resize_status("Resizing hash tables.");
+    buf_resize_status("Resizing hash tables.");
 
-		for (ulint i = 0; i < srv_buf_pool_instances; ++i) {
-			buf_pool_t*	buf_pool = buf_pool_from_array(i);
+    for (ulint i = 0; i < srv_buf_pool_instances; ++i) {
+      buf_pool_t*	buf_pool = buf_pool_from_array(i);
 
-			buf_pool_resize_hash(buf_pool);
+      buf_pool_resize_hash(buf_pool);
 
-			ib::info() << "buffer pool " << i
-				<< " : hash tables were resized.";
-		}
-	}
+      ib::info() << "buffer pool " << i
+        << " : hash tables were resized.";
+    }
+  }
 
-	/* Release all buf_pool_mutex/page_hash */
-	for (ulint i = 0; i < srv_buf_pool_instances; ++i) {
-		buf_pool_t*	buf_pool = buf_pool_from_array(i);
+  /* Release all buf_pool_mutex/page_hash */
+  for (ulint i = 0; i < srv_buf_pool_instances; ++i) {
+    buf_pool_t*	buf_pool = buf_pool_from_array(i);
 
-		hash_unlock_x_all(buf_pool->page_hash);
-		buf_pool_mutex_exit(buf_pool);
+    hash_unlock_x_all(buf_pool->page_hash);
+    buf_pool_mutex_exit(buf_pool);
 
-		if (buf_pool->page_hash_old != NULL) {
-			hash_table_free(buf_pool->page_hash_old);
-			buf_pool->page_hash_old = NULL;
-		}
-	}
+    if (buf_pool->page_hash_old != NULL) {
+      hash_table_free(buf_pool->page_hash_old);
+      buf_pool->page_hash_old = NULL;
+    }
+  }
 
-	UT_DELETE(chunk_map_old);
+  UT_DELETE(chunk_map_old);
 
-	buf_pool_resizing = false;
+  buf_pool_resizing = false;
 
-	/* Normalize other components, if the new size is too different */
-	if (!warning && new_size_too_diff) {
-		srv_buf_pool_base_size = srv_buf_pool_size;
+  /* Normalize other components, if the new size is too different */
+  if (!warning && new_size_too_diff) {
+    srv_buf_pool_base_size = srv_buf_pool_size;
 
-		buf_resize_status("Resizing also other hash tables.");
+    buf_resize_status("Resizing also other hash tables.");
 
-		/* normalize lock_sys */
-		srv_lock_table_size = 5
-			* (srv_buf_pool_size >> srv_page_size_shift);
-		lock_sys.resize(srv_lock_table_size);
+    /* normalize lock_sys */
+    srv_lock_table_size = 5
+      * (srv_buf_pool_size >> srv_page_size_shift);
+    lock_sys.resize(srv_lock_table_size);
 
-		/* normalize btr_search_sys */
-		btr_search_sys_resize(
-			buf_pool_get_curr_size() / sizeof(void*) / 64);
+    /* normalize btr_search_sys */
+    btr_search_sys_resize(
+      buf_pool_get_curr_size() / sizeof(void*) / 64);
 
-		dict_sys.resize();
+    dict_sys.resize();
 
-		ib::info() << "Resized hash tables at lock_sys,"
+    ib::info() << "Resized hash tables at lock_sys,"
 #ifdef BTR_CUR_HASH_ADAPT
-			" adaptive hash index,"
+      " adaptive hash index,"
 #endif /* BTR_CUR_HASH_ADAPT */
-			" dictionary.";
-	}
+      " dictionary.";
+  }
 
-	/* normalize ibuf.max_size */
-	ibuf_max_size_update(srv_change_buffer_max_size);
+  /* normalize ibuf.max_size */
+  ibuf_max_size_update(srv_change_buffer_max_size);
 
-	if (srv_buf_pool_old_size != srv_buf_pool_size) {
+  if (srv_buf_pool_old_size != srv_buf_pool_size) {
 
-		ib::info() << "Completed to resize buffer pool from "
-			<< srv_buf_pool_old_size
-			<< " to " << srv_buf_pool_size << ".";
-		srv_buf_pool_old_size = srv_buf_pool_size;
-	}
+    ib::info() << "Completed to resize buffer pool from "
+      << srv_buf_pool_old_size
+      << " to " << srv_buf_pool_size << ".";
+    srv_buf_pool_old_size = srv_buf_pool_size;
+  }
 
 #ifdef BTR_CUR_HASH_ADAPT
-	/* enable AHI if needed */
-	if (btr_search_disabled) {
-		btr_search_enable();
-		ib::info() << "Re-enabled adaptive hash index.";
-	}
+  /* enable AHI if needed */
+  if (btr_search_disabled) {
+    btr_search_enable();
+    ib::info() << "Re-enabled adaptive hash index.";
+  }
 #endif /* BTR_CUR_HASH_ADAPT */
 
-	char	now[32];
+  char	now[32];
 
-	ut_sprintf_timestamp(now);
-	if (!warning) {
-		buf_resize_status("Completed resizing buffer pool at %s.",
-			now);
-	} else {
-		buf_resize_status("Resizing buffer pool failed,"
-			" finished resizing at %s.", now);
-	}
+  ut_sprintf_timestamp(now);
+  if (!warning) {
+    buf_resize_status("Completed resizing buffer pool at %s.",
+      now);
+  } else {
+    buf_resize_status("Resizing buffer pool failed,"
+      " finished resizing at %s.", now);
+  }
 
 #if defined UNIV_DEBUG || defined UNIV_BUF_DEBUG
-	ut_a(buf_validate());
+  ut_a(buf_validate());
 #endif /* UNIV_DEBUG || UNIV_BUF_DEBUG */
 
-	return;
+  return;
 }
 
 /** This is the thread for resizing buffer pool. It waits for an event and
@@ -3194,38 +3297,38 @@ extern "C"
 os_thread_ret_t
 DECLARE_THREAD(buf_resize_thread)(void*)
 {
-	my_thread_init();
+  my_thread_init();
 
-	while (srv_shutdown_state == SRV_SHUTDOWN_NONE) {
-		os_event_wait(srv_buf_resize_event);
-		os_event_reset(srv_buf_resize_event);
+  while (srv_shutdown_state == SRV_SHUTDOWN_NONE) {
+    os_event_wait(srv_buf_resize_event);
+    os_event_reset(srv_buf_resize_event);
 
-		if (srv_shutdown_state != SRV_SHUTDOWN_NONE) {
-			break;
-		}
+    if (srv_shutdown_state != SRV_SHUTDOWN_NONE) {
+      break;
+    }
 
-		buf_pool_mutex_enter_all();
-		if (srv_buf_pool_old_size == srv_buf_pool_size) {
-			buf_pool_mutex_exit_all();
-			std::ostringstream sout;
-			sout << "Size did not change (old size = new size = "
-				<< srv_buf_pool_size << ". Nothing to do.";
-			buf_resize_status(sout.str().c_str());
+    buf_pool_mutex_enter_all();
+    if (srv_buf_pool_old_size == srv_buf_pool_size) {
+      buf_pool_mutex_exit_all();
+      std::ostringstream sout;
+      sout << "Size did not change (old size = new size = "
+        << srv_buf_pool_size << ". Nothing to do.";
+      buf_resize_status(sout.str().c_str());
 
-			/* nothing to do */
-			continue;
-		}
-		buf_pool_mutex_exit_all();
+      /* nothing to do */
+      continue;
+    }
+    buf_pool_mutex_exit_all();
 
-		buf_pool_resize();
-	}
+    buf_pool_resize();
+  }
 
-	srv_buf_resize_thread_active = false;
+  srv_buf_resize_thread_active = false;
 
-	my_thread_end();
-	os_thread_exit();
+  my_thread_end();
+  os_thread_exit();
 
-	OS_THREAD_DUMMY_RETURN;
+  OS_THREAD_DUMMY_RETURN;
 }
 
 #ifdef BTR_CUR_HASH_ADAPT
@@ -3233,58 +3336,58 @@ DECLARE_THREAD(buf_resize_thread)(void*)
 void
 buf_pool_clear_hash_index()
 {
-	ulint	p;
+  ulint	p;
 
-	ut_ad(btr_search_own_all(RW_LOCK_X));
-	ut_ad(!buf_pool_resizing);
-	ut_ad(!btr_search_enabled);
+  ut_ad(btr_search_own_all(RW_LOCK_X));
+  ut_ad(!buf_pool_resizing);
+  ut_ad(!btr_search_enabled);
 
-	for (p = 0; p < srv_buf_pool_instances; p++) {
-		buf_pool_t*	buf_pool = buf_pool_from_array(p);
-		buf_chunk_t*	chunks	= buf_pool->chunks;
-		buf_chunk_t*	chunk	= chunks + buf_pool->n_chunks;
+  for (p = 0; p < srv_buf_pool_instances; p++) {
+    buf_pool_t*	buf_pool = buf_pool_from_array(p);
+    buf_chunk_t*	chunks	= buf_pool->chunks;
+    buf_chunk_t*	chunk	= chunks + buf_pool->n_chunks;
 
-		while (--chunk >= chunks) {
-			buf_block_t*	block	= chunk->blocks;
-			ulint		i	= chunk->size;
+    while (--chunk >= chunks) {
+      buf_block_t*	block	= chunk->blocks;
+      ulint		i	= chunk->size;
 
-			for (; i--; block++) {
-				dict_index_t*	index	= block->index;
-				assert_block_ahi_valid(block);
+      for (; i--; block++) {
+        dict_index_t*	index	= block->index;
+        assert_block_ahi_valid(block);
 
-				/* We can set block->index = NULL
-				and block->n_pointers = 0
-				when btr_search_own_all(RW_LOCK_X);
-				see the comments in buf0buf.h */
+        /* We can set block->index = NULL
+        and block->n_pointers = 0
+        when btr_search_own_all(RW_LOCK_X);
+        see the comments in buf0buf.h */
 
-				if (!index) {
+        if (!index) {
 # if defined UNIV_AHI_DEBUG || defined UNIV_DEBUG
-					ut_a(!block->n_pointers);
+          ut_a(!block->n_pointers);
 # endif /* UNIV_AHI_DEBUG || UNIV_DEBUG */
-					continue;
-				}
-
-				ut_d(buf_page_state state
-				     = buf_block_get_state(block));
-				/* Another thread may have set the
-				state to BUF_BLOCK_REMOVE_HASH in
-				buf_LRU_block_remove_hashed().
-
-				The state change in buf_page_realloc()
-				is not observable here, because in
-				that case we would have !block->index.
-
-				In the end, the entire adaptive hash
-				index will be removed. */
-				ut_ad(state == BUF_BLOCK_FILE_PAGE
-				      || state == BUF_BLOCK_REMOVE_HASH);
+          continue;
+        }
+
+        ut_d(buf_page_state state
+             = buf_block_get_state(block));
+        /* Another thread may have set the
+        state to BUF_BLOCK_REMOVE_HASH in
+        buf_LRU_block_remove_hashed().
+
+        The state change in buf_page_realloc()
+        is not observable here, because in
+        that case we would have !block->index.
+
+        In the end, the entire adaptive hash
+        index will be removed. */
+        ut_ad(state == BUF_BLOCK_FILE_PAGE
+              || state == BUF_BLOCK_REMOVE_HASH);
 # if defined UNIV_AHI_DEBUG || defined UNIV_DEBUG
-				block->n_pointers = 0;
+        block->n_pointers = 0;
 # endif /* UNIV_AHI_DEBUG || UNIV_DEBUG */
-				block->index = NULL;
-			}
-		}
-	}
+        block->index = NULL;
+      }
+    }
+  }
 }
 #endif /* BTR_CUR_HASH_ADAPT */
 
@@ -3296,83 +3399,83 @@ static
 void
 buf_relocate(
 /*=========*/
-	buf_page_t*	bpage,	/*!< in/out: control block being relocated;
-				buf_page_get_state(bpage) must be
-				BUF_BLOCK_ZIP_DIRTY or BUF_BLOCK_ZIP_PAGE */
-	buf_page_t*	dpage)	/*!< in/out: destination control block */
+  buf_page_t*	bpage,	/*!< in/out: control block being relocated;
+        buf_page_get_state(bpage) must be
+        BUF_BLOCK_ZIP_DIRTY or BUF_BLOCK_ZIP_PAGE */
+  buf_page_t*	dpage)	/*!< in/out: destination control block */
 {
-	buf_page_t*	b;
-	buf_pool_t*	buf_pool = buf_pool_from_bpage(bpage);
-
-	ut_ad(buf_pool_mutex_own(buf_pool));
-	ut_ad(buf_page_hash_lock_held_x(buf_pool, bpage));
-	ut_ad(mutex_own(buf_page_get_mutex(bpage)));
-	ut_a(buf_page_get_io_fix(bpage) == BUF_IO_NONE);
-	ut_a(bpage->buf_fix_count == 0);
-	ut_ad(bpage->in_LRU_list);
-	ut_ad(!bpage->in_zip_hash);
-	ut_ad(bpage->in_page_hash);
-	ut_ad(bpage == buf_page_hash_get_low(buf_pool, bpage->id));
-
-	ut_ad(!buf_pool_watch_is_sentinel(buf_pool, bpage));
+  buf_page_t*	b;
+  buf_pool_t*	buf_pool = buf_pool_from_bpage(bpage);
+
+  ut_ad(buf_pool_mutex_own(buf_pool));
+  ut_ad(buf_page_hash_lock_held_x(buf_pool, bpage));
+  ut_ad(mutex_own(buf_page_get_mutex(bpage)));
+  ut_a(buf_page_get_io_fix(bpage) == BUF_IO_NONE);
+  ut_a(bpage->buf_fix_count == 0);
+  ut_ad(bpage->in_LRU_list);
+  ut_ad(!bpage->in_zip_hash);
+  ut_ad(bpage->in_page_hash);
+  ut_ad(bpage == buf_page_hash_get_low(buf_pool, bpage->id));
+
+  ut_ad(!buf_pool_watch_is_sentinel(buf_pool, bpage));
 #ifdef UNIV_DEBUG
-	switch (buf_page_get_state(bpage)) {
-	case BUF_BLOCK_POOL_WATCH:
-	case BUF_BLOCK_NOT_USED:
-	case BUF_BLOCK_READY_FOR_USE:
-	case BUF_BLOCK_FILE_PAGE:
-	case BUF_BLOCK_MEMORY:
-	case BUF_BLOCK_REMOVE_HASH:
-		ut_error;
-	case BUF_BLOCK_ZIP_DIRTY:
-	case BUF_BLOCK_ZIP_PAGE:
-		break;
-	}
+  switch (buf_page_get_state(bpage)) {
+  case BUF_BLOCK_POOL_WATCH:
+  case BUF_BLOCK_NOT_USED:
+  case BUF_BLOCK_READY_FOR_USE:
+  case BUF_BLOCK_FILE_PAGE:
+  case BUF_BLOCK_MEMORY:
+  case BUF_BLOCK_REMOVE_HASH:
+    ut_error;
+  case BUF_BLOCK_ZIP_DIRTY:
+  case BUF_BLOCK_ZIP_PAGE:
+    break;
+  }
 #endif /* UNIV_DEBUG */
 
-	new (dpage) buf_page_t(*bpage);
+  new (dpage) buf_page_t(*bpage);
 
-	/* Important that we adjust the hazard pointer before
-	removing bpage from LRU list. */
-	buf_LRU_adjust_hp(buf_pool, bpage);
+  /* Important that we adjust the hazard pointer before
+  removing bpage from LRU list. */
+  buf_LRU_adjust_hp(buf_pool, bpage);
 
-	ut_d(bpage->in_LRU_list = FALSE);
-	ut_d(bpage->in_page_hash = FALSE);
+  ut_d(bpage->in_LRU_list = FALSE);
+  ut_d(bpage->in_page_hash = FALSE);
 
-	/* relocate buf_pool->LRU */
-	b = UT_LIST_GET_PREV(LRU, bpage);
-	UT_LIST_REMOVE(buf_pool->LRU, bpage);
+  /* relocate buf_pool->LRU */
+  b = UT_LIST_GET_PREV(LRU, bpage);
+  UT_LIST_REMOVE(buf_pool->LRU, bpage);
 
-	if (b != NULL) {
-		UT_LIST_INSERT_AFTER(buf_pool->LRU, b, dpage);
-	} else {
-		UT_LIST_ADD_FIRST(buf_pool->LRU, dpage);
-	}
+  if (b != NULL) {
+    UT_LIST_INSERT_AFTER(buf_pool->LRU, b, dpage);
+  } else {
+    UT_LIST_ADD_FIRST(buf_pool->LRU, dpage);
+  }
 
-	if (UNIV_UNLIKELY(buf_pool->LRU_old == bpage)) {
-		buf_pool->LRU_old = dpage;
+  if (UNIV_UNLIKELY(buf_pool->LRU_old == bpage)) {
+    buf_pool->LRU_old = dpage;
 #ifdef UNIV_LRU_DEBUG
-		/* buf_pool->LRU_old must be the first item in the LRU list
-		whose "old" flag is set. */
-		ut_a(buf_pool->LRU_old->old);
-		ut_a(!UT_LIST_GET_PREV(LRU, buf_pool->LRU_old)
-		     || !UT_LIST_GET_PREV(LRU, buf_pool->LRU_old)->old);
-		ut_a(!UT_LIST_GET_NEXT(LRU, buf_pool->LRU_old)
-		     || UT_LIST_GET_NEXT(LRU, buf_pool->LRU_old)->old);
-	} else {
-		/* Check that the "old" flag is consistent in
-		the block and its neighbours. */
-		buf_page_set_old(dpage, buf_page_is_old(dpage));
+    /* buf_pool->LRU_old must be the first item in the LRU list
+    whose "old" flag is set. */
+    ut_a(buf_pool->LRU_old->old);
+    ut_a(!UT_LIST_GET_PREV(LRU, buf_pool->LRU_old)
+         || !UT_LIST_GET_PREV(LRU, buf_pool->LRU_old)->old);
+    ut_a(!UT_LIST_GET_NEXT(LRU, buf_pool->LRU_old)
+         || UT_LIST_GET_NEXT(LRU, buf_pool->LRU_old)->old);
+  } else {
+    /* Check that the "old" flag is consistent in
+    the block and its neighbours. */
+    buf_page_set_old(dpage, buf_page_is_old(dpage));
 #endif /* UNIV_LRU_DEBUG */
-	}
+  }
 
         ut_d(CheckInLRUList::validate(buf_pool));
 
-	/* relocate buf_pool->page_hash */
-	ulint	fold = bpage->id.fold();
-	ut_ad(fold == dpage->id.fold());
-	HASH_DELETE(buf_page_t, hash, buf_pool->page_hash, fold, bpage);
-	HASH_INSERT(buf_page_t, hash, buf_pool->page_hash, fold, dpage);
+  /* relocate buf_pool->page_hash */
+  ulint	fold = bpage->id.fold();
+  ut_ad(fold == dpage->id.fold());
+  HASH_DELETE(buf_page_t, hash, buf_pool->page_hash, fold, bpage);
+  HASH_INSERT(buf_page_t, hash, buf_pool->page_hash, fold, dpage);
 }
 
 /** Hazard Pointer implementation. */
@@ -3382,11 +3485,11 @@ buf_relocate(
 void
 HazardPointer::set(buf_page_t* bpage)
 {
-	ut_ad(mutex_own(m_mutex));
-	ut_ad(!bpage || buf_pool_from_bpage(bpage) == m_buf_pool);
-	ut_ad(!bpage || buf_page_in_file(bpage));
+  ut_ad(mutex_own(m_mutex));
+  ut_ad(!bpage || buf_pool_from_bpage(bpage) == m_buf_pool);
+  ut_ad(!bpage || buf_page_in_file(bpage));
 
-	m_hp = bpage;
+  m_hp = bpage;
 }
 
 /** Checks if a bpage is the hp
@@ -3396,11 +3499,11 @@ HazardPointer::set(buf_page_t* bpage)
 bool
 HazardPointer::is_hp(const buf_page_t* bpage)
 {
-	ut_ad(mutex_own(m_mutex));
-	ut_ad(!m_hp || buf_pool_from_bpage(m_hp) == m_buf_pool);
-	ut_ad(!bpage || buf_pool_from_bpage(bpage) == m_buf_pool);
+  ut_ad(mutex_own(m_mutex));
+  ut_ad(!m_hp || buf_pool_from_bpage(m_hp) == m_buf_pool);
+  ut_ad(!bpage || buf_pool_from_bpage(bpage) == m_buf_pool);
 
-	return(bpage == m_hp);
+  return(bpage == m_hp);
 }
 
 /** Adjust the value of hp. This happens when some other thread working
@@ -3410,14 +3513,14 @@ on the same list attempts to remove the hp from the list.
 void
 FlushHp::adjust(const buf_page_t* bpage)
 {
-	ut_ad(bpage != NULL);
+  ut_ad(bpage != NULL);
 
-	/** We only support reverse traversal for now. */
-	if (is_hp(bpage)) {
-		m_hp = UT_LIST_GET_PREV(list, m_hp);
-	}
+  /** We only support reverse traversal for now. */
+  if (is_hp(bpage)) {
+    m_hp = UT_LIST_GET_PREV(list, m_hp);
+  }
 
-	ut_ad(!m_hp || m_hp->in_flush_list);
+  ut_ad(!m_hp || m_hp->in_flush_list);
 }
 
 /** Adjust the value of hp. This happens when some other thread working
@@ -3427,14 +3530,14 @@ on the same list attempts to remove the hp from the list.
 void
 LRUHp::adjust(const buf_page_t* bpage)
 {
-	ut_ad(bpage);
+  ut_ad(bpage);
 
-	/** We only support reverse traversal for now. */
-	if (is_hp(bpage)) {
-		m_hp = UT_LIST_GET_PREV(LRU, m_hp);
-	}
+  /** We only support reverse traversal for now. */
+  if (is_hp(bpage)) {
+    m_hp = UT_LIST_GET_PREV(LRU, m_hp);
+  }
 
-	ut_ad(!m_hp || m_hp->in_LRU_list);
+  ut_ad(!m_hp || m_hp->in_LRU_list);
 }
 
 /** Selects from where to start a scan. If we have scanned too deep into
@@ -3444,13 +3547,13 @@ the LRU list it resets the value to the tail of the LRU list.
 buf_page_t*
 LRUItr::start()
 {
-	ut_ad(mutex_own(m_mutex));
+  ut_ad(mutex_own(m_mutex));
 
-	if (!m_hp || m_hp->old) {
-		m_hp = UT_LIST_GET_LAST(m_buf_pool->LRU);
-	}
+  if (!m_hp || m_hp->old) {
+    m_hp = UT_LIST_GET_LAST(m_buf_pool->LRU);
+  }
 
-	return(m_hp);
+  return(m_hp);
 }
 
 /** Determine if a block is a sentinel for a buffer pool watch.
@@ -3459,27 +3562,27 @@ LRUItr::start()
 @return TRUE if a sentinel for a buffer pool watch, FALSE if not */
 ibool
 buf_pool_watch_is_sentinel(
-	const buf_pool_t*	buf_pool,
-	const buf_page_t*	bpage)
+  const buf_pool_t*	buf_pool,
+  const buf_page_t*	bpage)
 {
-	/* We must also own the appropriate hash lock. */
-	ut_ad(buf_page_hash_lock_held_s_or_x(buf_pool, bpage));
-	ut_ad(buf_page_in_file(bpage));
+  /* We must also own the appropriate hash lock. */
+  ut_ad(buf_page_hash_lock_held_s_or_x(buf_pool, bpage));
+  ut_ad(buf_page_in_file(bpage));
 
-	if (bpage < &buf_pool->watch[0]
-	    || bpage >= &buf_pool->watch[BUF_POOL_WATCH_SIZE]) {
+  if (bpage < &buf_pool->watch[0]
+      || bpage >= &buf_pool->watch[BUF_POOL_WATCH_SIZE]) {
 
-		ut_ad(buf_page_get_state(bpage) != BUF_BLOCK_ZIP_PAGE
-		      || bpage->zip.data != NULL);
+    ut_ad(buf_page_get_state(bpage) != BUF_BLOCK_ZIP_PAGE
+          || bpage->zip.data != NULL);
 
-		return(FALSE);
-	}
+    return(FALSE);
+  }
 
-	ut_ad(buf_page_get_state(bpage) == BUF_BLOCK_ZIP_PAGE);
-	ut_ad(!bpage->in_zip_hash);
-	ut_ad(bpage->in_page_hash);
-	ut_ad(bpage->zip.data == NULL);
-	return(TRUE);
+  ut_ad(buf_page_get_state(bpage) == BUF_BLOCK_ZIP_PAGE);
+  ut_ad(!bpage->in_zip_hash);
+  ut_ad(bpage->in_page_hash);
+  ut_ad(bpage->zip.data == NULL);
+  return(TRUE);
 }
 
 /** Add watch for the given page to be read in. Caller must have
@@ -3491,116 +3594,116 @@ hash_lock and reacquire it.
 static
 buf_page_t*
 buf_pool_watch_set(
-	const page_id_t		page_id,
-	rw_lock_t**		hash_lock)
+  const page_id_t		page_id,
+  rw_lock_t**		hash_lock)
 {
-	buf_page_t*	bpage;
-	ulint		i;
-	buf_pool_t*	buf_pool = buf_pool_get(page_id);
+  buf_page_t*	bpage;
+  ulint		i;
+  buf_pool_t*	buf_pool = buf_pool_get(page_id);
 
-	ut_ad(*hash_lock == buf_page_hash_lock_get(buf_pool, page_id));
+  ut_ad(*hash_lock == buf_page_hash_lock_get(buf_pool, page_id));
 
-	ut_ad(rw_lock_own(*hash_lock, RW_LOCK_X));
+  ut_ad(rw_lock_own(*hash_lock, RW_LOCK_X));
 
-	bpage = buf_page_hash_get_low(buf_pool, page_id);
+  bpage = buf_page_hash_get_low(buf_pool, page_id);
 
-	if (bpage != NULL) {
+  if (bpage != NULL) {
 page_found:
-		if (!buf_pool_watch_is_sentinel(buf_pool, bpage)) {
-			/* The page was loaded meanwhile. */
-			return(bpage);
-		}
-
-		/* Add to an existing watch. */
-		bpage->fix();
-		return(NULL);
-	}
-
-	/* From this point this function becomes fairly heavy in terms
-	of latching. We acquire the buf_pool mutex as well as all the
-	hash_locks. buf_pool mutex is needed because any changes to
-	the page_hash must be covered by it and hash_locks are needed
-	because we don't want to read any stale information in
-	buf_pool->watch[]. However, it is not in the critical code path
-	as this function will be called only by the purge thread. */
-
-	/* To obey latching order first release the hash_lock. */
-	rw_lock_x_unlock(*hash_lock);
-
-	buf_pool_mutex_enter(buf_pool);
-	hash_lock_x_all(buf_pool->page_hash);
-
-	/* If not own buf_pool_mutex, page_hash can be changed. */
-	*hash_lock = buf_page_hash_lock_get(buf_pool, page_id);
-
-	/* We have to recheck that the page
-	was not loaded or a watch set by some other
-	purge thread. This is because of the small
-	time window between when we release the
-	hash_lock to acquire buf_pool mutex above. */
-
-	bpage = buf_page_hash_get_low(buf_pool, page_id);
-	if (UNIV_LIKELY_NULL(bpage)) {
-		buf_pool_mutex_exit(buf_pool);
-		hash_unlock_x_all_but(buf_pool->page_hash, *hash_lock);
-		goto page_found;
-	}
-
-	/* The maximum number of purge threads should never exceed
-	BUF_POOL_WATCH_SIZE. So there is no way for purge thread
-	instance to hold a watch when setting another watch. */
-	for (i = 0; i < BUF_POOL_WATCH_SIZE; i++) {
-		bpage = &buf_pool->watch[i];
-
-		ut_ad(bpage->access_time == 0);
-		ut_ad(bpage->newest_modification == 0);
-		ut_ad(bpage->oldest_modification == 0);
-		ut_ad(bpage->zip.data == NULL);
-		ut_ad(!bpage->in_zip_hash);
-
-		switch (bpage->state) {
-		case BUF_BLOCK_POOL_WATCH:
-			ut_ad(!bpage->in_page_hash);
-			ut_ad(bpage->buf_fix_count == 0);
-
-			/* bpage is pointing to buf_pool->watch[],
-			which is protected by buf_pool->mutex.
-			Normally, buf_page_t objects are protected by
-			buf_block_t::mutex or buf_pool->zip_mutex or both. */
-
-			bpage->state = BUF_BLOCK_ZIP_PAGE;
-			bpage->id = page_id;
-			bpage->buf_fix_count = 1;
-
-			ut_d(bpage->in_page_hash = TRUE);
-			HASH_INSERT(buf_page_t, hash, buf_pool->page_hash,
-				    page_id.fold(), bpage);
-
-			buf_pool_mutex_exit(buf_pool);
-			/* Once the sentinel is in the page_hash we can
-			safely release all locks except just the
-			relevant hash_lock */
-			hash_unlock_x_all_but(buf_pool->page_hash,
-						*hash_lock);
-
-			return(NULL);
-		case BUF_BLOCK_ZIP_PAGE:
-			ut_ad(bpage->in_page_hash);
-			ut_ad(bpage->buf_fix_count > 0);
-			break;
-		default:
-			ut_error;
-		}
-	}
-
-	/* Allocation failed.  Either the maximum number of purge
-	threads should never exceed BUF_POOL_WATCH_SIZE, or this code
-	should be modified to return a special non-NULL value and the
-	caller should purge the record directly. */
-	ut_error;
-
-	/* Fix compiler warning */
-	return(NULL);
+    if (!buf_pool_watch_is_sentinel(buf_pool, bpage)) {
+      /* The page was loaded meanwhile. */
+      return(bpage);
+    }
+
+    /* Add to an existing watch. */
+    bpage->fix();
+    return(NULL);
+  }
+
+  /* From this point this function becomes fairly heavy in terms
+  of latching. We acquire the buf_pool mutex as well as all the
+  hash_locks. buf_pool mutex is needed because any changes to
+  the page_hash must be covered by it and hash_locks are needed
+  because we don't want to read any stale information in
+  buf_pool->watch[]. However, it is not in the critical code path
+  as this function will be called only by the purge thread. */
+
+  /* To obey latching order first release the hash_lock. */
+  rw_lock_x_unlock(*hash_lock);
+
+  buf_pool_mutex_enter(buf_pool);
+  hash_lock_x_all(buf_pool->page_hash);
+
+  /* If not own buf_pool_mutex, page_hash can be changed. */
+  *hash_lock = buf_page_hash_lock_get(buf_pool, page_id);
+
+  /* We have to recheck that the page
+  was not loaded or a watch set by some other
+  purge thread. This is because of the small
+  time window between when we release the
+  hash_lock to acquire buf_pool mutex above. */
+
+  bpage = buf_page_hash_get_low(buf_pool, page_id);
+  if (UNIV_LIKELY_NULL(bpage)) {
+    buf_pool_mutex_exit(buf_pool);
+    hash_unlock_x_all_but(buf_pool->page_hash, *hash_lock);
+    goto page_found;
+  }
+
+  /* The maximum number of purge threads should never exceed
+  BUF_POOL_WATCH_SIZE. So there is no way for purge thread
+  instance to hold a watch when setting another watch. */
+  for (i = 0; i < BUF_POOL_WATCH_SIZE; i++) {
+    bpage = &buf_pool->watch[i];
+
+    ut_ad(bpage->access_time == 0);
+    ut_ad(bpage->newest_modification == 0);
+    ut_ad(bpage->oldest_modification == 0);
+    ut_ad(bpage->zip.data == NULL);
+    ut_ad(!bpage->in_zip_hash);
+
+    switch (bpage->state) {
+    case BUF_BLOCK_POOL_WATCH:
+      ut_ad(!bpage->in_page_hash);
+      ut_ad(bpage->buf_fix_count == 0);
+
+      /* bpage is pointing to buf_pool->watch[],
+      which is protected by buf_pool->mutex.
+      Normally, buf_page_t objects are protected by
+      buf_block_t::mutex or buf_pool->zip_mutex or both. */
+
+      bpage->state = BUF_BLOCK_ZIP_PAGE;
+      bpage->id = page_id;
+      bpage->buf_fix_count = 1;
+
+      ut_d(bpage->in_page_hash = TRUE);
+      HASH_INSERT(buf_page_t, hash, buf_pool->page_hash,
+            page_id.fold(), bpage);
+
+      buf_pool_mutex_exit(buf_pool);
+      /* Once the sentinel is in the page_hash we can
+      safely release all locks except just the
+      relevant hash_lock */
+      hash_unlock_x_all_but(buf_pool->page_hash,
+            *hash_lock);
+
+      return(NULL);
+    case BUF_BLOCK_ZIP_PAGE:
+      ut_ad(bpage->in_page_hash);
+      ut_ad(bpage->buf_fix_count > 0);
+      break;
+    default:
+      ut_error;
+    }
+  }
+
+  /* Allocation failed.  Either the maximum number of purge
+  threads should never exceed BUF_POOL_WATCH_SIZE, or this code
+  should be modified to return a special non-NULL value and the
+  caller should purge the record directly. */
+  ut_error;
+
+  /* Fix compiler warning */
+  return(NULL);
 }
 
 /** Remove the sentinel block for the watch before replacing it with a
@@ -3612,22 +3715,22 @@ that the block has been replaced with the real block.
 static
 void
 buf_pool_watch_remove(
-	buf_pool_t*	buf_pool,
-	buf_page_t*	watch)
+  buf_pool_t*	buf_pool,
+  buf_page_t*	watch)
 {
 #ifdef UNIV_DEBUG
-	/* We must also own the appropriate hash_bucket mutex. */
-	rw_lock_t* hash_lock = buf_page_hash_lock_get(buf_pool, watch->id);
-	ut_ad(rw_lock_own(hash_lock, RW_LOCK_X));
+  /* We must also own the appropriate hash_bucket mutex. */
+  rw_lock_t* hash_lock = buf_page_hash_lock_get(buf_pool, watch->id);
+  ut_ad(rw_lock_own(hash_lock, RW_LOCK_X));
 #endif /* UNIV_DEBUG */
 
-	ut_ad(buf_pool_mutex_own(buf_pool));
+  ut_ad(buf_pool_mutex_own(buf_pool));
 
-	HASH_DELETE(buf_page_t, hash, buf_pool->page_hash, watch->id.fold(),
-		    watch);
-	ut_d(watch->in_page_hash = FALSE);
-	watch->buf_fix_count = 0;
-	watch->state = BUF_BLOCK_POOL_WATCH;
+  HASH_DELETE(buf_page_t, hash, buf_pool->page_hash, watch->id.fold(),
+        watch);
+  ut_d(watch->in_page_hash = FALSE);
+  watch->buf_fix_count = 0;
+  watch->state = BUF_BLOCK_POOL_WATCH;
 }
 
 /** Stop watching if the page has been read in.
@@ -3635,30 +3738,30 @@ buf_pool_watch_set(same_page_id) must have returned NULL before.
 @param[in]	page_id	page id */
 void buf_pool_watch_unset(const page_id_t page_id)
 {
-	buf_page_t*	bpage;
-	buf_pool_t*	buf_pool = buf_pool_get(page_id);
-
-	/* We only need to have buf_pool mutex in case where we end
-	up calling buf_pool_watch_remove but to obey latching order
-	we acquire it here before acquiring hash_lock. This should
-	not cause too much grief as this function is only ever
-	called from the purge thread. */
-	buf_pool_mutex_enter(buf_pool);
-
-	rw_lock_t*	hash_lock = buf_page_hash_lock_get(buf_pool, page_id);
-	rw_lock_x_lock(hash_lock);
-
-	/* The page must exist because buf_pool_watch_set()
-	increments buf_fix_count. */
-	bpage = buf_page_hash_get_low(buf_pool, page_id);
-
-	if (bpage->unfix() == 0
-	    && buf_pool_watch_is_sentinel(buf_pool, bpage)) {
-		buf_pool_watch_remove(buf_pool, bpage);
-	}
-
-	buf_pool_mutex_exit(buf_pool);
-	rw_lock_x_unlock(hash_lock);
+  buf_page_t*	bpage;
+  buf_pool_t*	buf_pool = buf_pool_get(page_id);
+
+  /* We only need to have buf_pool mutex in case where we end
+  up calling buf_pool_watch_remove but to obey latching order
+  we acquire it here before acquiring hash_lock. This should
+  not cause too much grief as this function is only ever
+  called from the purge thread. */
+  buf_pool_mutex_enter(buf_pool);
+
+  rw_lock_t*	hash_lock = buf_page_hash_lock_get(buf_pool, page_id);
+  rw_lock_x_lock(hash_lock);
+
+  /* The page must exist because buf_pool_watch_set()
+  increments buf_fix_count. */
+  bpage = buf_page_hash_get_low(buf_pool, page_id);
+
+  if (bpage->unfix() == 0
+      && buf_pool_watch_is_sentinel(buf_pool, bpage)) {
+    buf_pool_watch_remove(buf_pool, bpage);
+  }
+
+  buf_pool_mutex_exit(buf_pool);
+  rw_lock_x_unlock(hash_lock);
 }
 
 /** Check if the page has been read in.
@@ -3668,24 +3771,24 @@ has returned NULL and before invoking buf_pool_watch_unset(same_page_id).
 @return false if the given page was not read in, true if it was */
 bool buf_pool_watch_occurred(const page_id_t page_id)
 {
-	bool		ret;
-	buf_page_t*	bpage;
-	buf_pool_t*	buf_pool = buf_pool_get(page_id);
-	rw_lock_t*	hash_lock = buf_page_hash_lock_get(buf_pool, page_id);
+  bool		ret;
+  buf_page_t*	bpage;
+  buf_pool_t*	buf_pool = buf_pool_get(page_id);
+  rw_lock_t*	hash_lock = buf_page_hash_lock_get(buf_pool, page_id);
 
-	rw_lock_s_lock(hash_lock);
+  rw_lock_s_lock(hash_lock);
 
-	/* If not own buf_pool_mutex, page_hash can be changed. */
-	hash_lock = buf_page_hash_lock_s_confirm(hash_lock, buf_pool, page_id);
+  /* If not own buf_pool_mutex, page_hash can be changed. */
+  hash_lock = buf_page_hash_lock_s_confirm(hash_lock, buf_pool, page_id);
 
-	/* The page must exist because buf_pool_watch_set()
-	increments buf_fix_count. */
-	bpage = buf_page_hash_get_low(buf_pool, page_id);
+  /* The page must exist because buf_pool_watch_set()
+  increments buf_fix_count. */
+  bpage = buf_page_hash_get_low(buf_pool, page_id);
 
-	ret = !buf_pool_watch_is_sentinel(buf_pool, bpage);
-	rw_lock_s_unlock(hash_lock);
+  ret = !buf_pool_watch_is_sentinel(buf_pool, bpage);
+  rw_lock_s_unlock(hash_lock);
 
-	return(ret);
+  return(ret);
 }
 
 /********************************************************************//**
@@ -3695,17 +3798,17 @@ the buffer pool. */
 void
 buf_page_make_young(
 /*================*/
-	buf_page_t*	bpage)	/*!< in: buffer block of a file page */
+  buf_page_t*	bpage)	/*!< in: buffer block of a file page */
 {
-	buf_pool_t*	buf_pool = buf_pool_from_bpage(bpage);
+  buf_pool_t*	buf_pool = buf_pool_from_bpage(bpage);
 
-	buf_pool_mutex_enter(buf_pool);
+  buf_pool_mutex_enter(buf_pool);
 
-	ut_a(buf_page_in_file(bpage));
+  ut_a(buf_page_in_file(bpage));
 
-	buf_LRU_make_block_young(bpage);
+  buf_LRU_make_block_young(bpage);
 
-	buf_pool_mutex_exit(buf_pool);
+  buf_pool_mutex_exit(buf_pool);
 }
 
 #ifdef UNIV_DEBUG
@@ -3718,24 +3821,24 @@ reallocated.
 @return control block if found in page hash table, otherwise NULL */
 buf_page_t* buf_page_set_file_page_was_freed(const page_id_t page_id)
 {
-	buf_page_t*	bpage;
-	buf_pool_t*	buf_pool = buf_pool_get(page_id);
-	rw_lock_t*	hash_lock;
-
-	bpage = buf_page_hash_get_s_locked(buf_pool, page_id, &hash_lock);
-
-	if (bpage) {
-		BPageMutex*	block_mutex = buf_page_get_mutex(bpage);
-		ut_ad(!buf_pool_watch_is_sentinel(buf_pool, bpage));
-		mutex_enter(block_mutex);
-		rw_lock_s_unlock(hash_lock);
-		/* bpage->file_page_was_freed can already hold
-		when this code is invoked from dict_drop_index_tree() */
-		bpage->file_page_was_freed = TRUE;
-		mutex_exit(block_mutex);
-	}
-
-	return(bpage);
+  buf_page_t*	bpage;
+  buf_pool_t*	buf_pool = buf_pool_get(page_id);
+  rw_lock_t*	hash_lock;
+
+  bpage = buf_page_hash_get_s_locked(buf_pool, page_id, &hash_lock);
+
+  if (bpage) {
+    BPageMutex*	block_mutex = buf_page_get_mutex(bpage);
+    ut_ad(!buf_pool_watch_is_sentinel(buf_pool, bpage));
+    mutex_enter(block_mutex);
+    rw_lock_s_unlock(hash_lock);
+    /* bpage->file_page_was_freed can already hold
+    when this code is invoked from dict_drop_index_tree() */
+    bpage->file_page_was_freed = TRUE;
+    mutex_exit(block_mutex);
+  }
+
+  return(bpage);
 }
 
 /** Sets file_page_was_freed FALSE if the page is found in the buffer pool.
@@ -3746,21 +3849,21 @@ reallocated.
 @return control block if found in page hash table, otherwise NULL */
 buf_page_t* buf_page_reset_file_page_was_freed(const page_id_t page_id)
 {
-	buf_page_t*	bpage;
-	buf_pool_t*	buf_pool = buf_pool_get(page_id);
-	rw_lock_t*	hash_lock;
-
-	bpage = buf_page_hash_get_s_locked(buf_pool, page_id, &hash_lock);
-	if (bpage) {
-		BPageMutex*	block_mutex = buf_page_get_mutex(bpage);
-		ut_ad(!buf_pool_watch_is_sentinel(buf_pool, bpage));
-		mutex_enter(block_mutex);
-		rw_lock_s_unlock(hash_lock);
-		bpage->file_page_was_freed = FALSE;
-		mutex_exit(block_mutex);
-	}
-
-	return(bpage);
+  buf_page_t*	bpage;
+  buf_pool_t*	buf_pool = buf_pool_get(page_id);
+  rw_lock_t*	hash_lock;
+
+  bpage = buf_page_hash_get_s_locked(buf_pool, page_id, &hash_lock);
+  if (bpage) {
+    BPageMutex*	block_mutex = buf_page_get_mutex(bpage);
+    ut_ad(!buf_pool_watch_is_sentinel(buf_pool, bpage));
+    mutex_enter(block_mutex);
+    rw_lock_s_unlock(hash_lock);
+    bpage->file_page_was_freed = FALSE;
+    mutex_exit(block_mutex);
+  }
+
+  return(bpage);
 }
 #endif /* UNIV_DEBUG */
 
@@ -3769,24 +3872,24 @@ The caller should not be holding any mutexes when this function is called.
 @param[in]	page_id	page id */
 static void buf_block_try_discard_uncompressed(const page_id_t page_id)
 {
-	buf_page_t*	bpage;
-	buf_pool_t*	buf_pool = buf_pool_get(page_id);
+  buf_page_t*	bpage;
+  buf_pool_t*	buf_pool = buf_pool_get(page_id);
 
-	/* Since we need to acquire buf_pool mutex to discard
-	the uncompressed frame and because page_hash mutex resides
-	below buf_pool mutex in sync ordering therefore we must
-	first release the page_hash mutex. This means that the
-	block in question can move out of page_hash. Therefore
-	we need to check again if the block is still in page_hash. */
-	buf_pool_mutex_enter(buf_pool);
+  /* Since we need to acquire buf_pool mutex to discard
+  the uncompressed frame and because page_hash mutex resides
+  below buf_pool mutex in sync ordering therefore we must
+  first release the page_hash mutex. This means that the
+  block in question can move out of page_hash. Therefore
+  we need to check again if the block is still in page_hash. */
+  buf_pool_mutex_enter(buf_pool);
 
-	bpage = buf_page_hash_get(buf_pool, page_id);
+  bpage = buf_page_hash_get(buf_pool, page_id);
 
-	if (bpage) {
-		buf_LRU_free_page(bpage, false);
-	}
+  if (bpage) {
+    buf_LRU_free_page(bpage, false);
+  }
 
-	buf_pool_mutex_exit(buf_pool);
+  buf_pool_mutex_exit(buf_pool);
 }
 
 /** Get read access to a compressed page (usually of type
@@ -3801,125 +3904,125 @@ the same set of mutexes or latches.
 @return pointer to the block */
 buf_page_t* buf_page_get_zip(const page_id_t page_id, ulint zip_size)
 {
-	buf_page_t*	bpage;
-	BPageMutex*	block_mutex;
-	rw_lock_t*	hash_lock;
-	ibool		discard_attempted = FALSE;
-	ibool		must_read;
-	buf_pool_t*	buf_pool = buf_pool_get(page_id);
-
-	ut_ad(zip_size);
-	ut_ad(ut_is_2pow(zip_size));
-	buf_pool->stat.n_page_gets++;
-
-	for (;;) {
+  buf_page_t*	bpage;
+  BPageMutex*	block_mutex;
+  rw_lock_t*	hash_lock;
+  ibool		discard_attempted = FALSE;
+  ibool		must_read;
+  buf_pool_t*	buf_pool = buf_pool_get(page_id);
+
+  ut_ad(zip_size);
+  ut_ad(ut_is_2pow(zip_size));
+  buf_pool->stat.n_page_gets++;
+
+  for (;;) {
 lookup:
 
-		/* The following call will also grab the page_hash
-		mutex if the page is found. */
-		bpage = buf_page_hash_get_s_locked(buf_pool, page_id,
-						   &hash_lock);
-		if (bpage) {
-			ut_ad(!buf_pool_watch_is_sentinel(buf_pool, bpage));
-			break;
-		}
+    /* The following call will also grab the page_hash
+    mutex if the page is found. */
+    bpage = buf_page_hash_get_s_locked(buf_pool, page_id,
+               &hash_lock);
+    if (bpage) {
+      ut_ad(!buf_pool_watch_is_sentinel(buf_pool, bpage));
+      break;
+    }
 
-		/* Page not in buf_pool: needs to be read from file */
+    /* Page not in buf_pool: needs to be read from file */
 
-		ut_ad(!hash_lock);
-		dberr_t err = buf_read_page(page_id, zip_size);
+    ut_ad(!hash_lock);
+    dberr_t err = buf_read_page(page_id, zip_size);
 
-		if (err != DB_SUCCESS) {
-			ib::error() << "Reading compressed page " << page_id
-				<< " failed with error: " << ut_strerr(err);
+    if (err != DB_SUCCESS) {
+      ib::error() << "Reading compressed page " << page_id
+        << " failed with error: " << ut_strerr(err);
 
-			goto err_exit;
-		}
+      goto err_exit;
+    }
 
 #if defined UNIV_DEBUG || defined UNIV_BUF_DEBUG
-		ut_a(++buf_dbg_counter % 5771 || buf_validate());
+    ut_a(++buf_dbg_counter % 5771 || buf_validate());
 #endif /* UNIV_DEBUG || UNIV_BUF_DEBUG */
-	}
+  }
 
-	ut_ad(buf_page_hash_lock_held_s(buf_pool, bpage));
+  ut_ad(buf_page_hash_lock_held_s(buf_pool, bpage));
 
-	if (!bpage->zip.data) {
-		/* There is no compressed page. */
+  if (!bpage->zip.data) {
+    /* There is no compressed page. */
 err_exit:
-		rw_lock_s_unlock(hash_lock);
-		return(NULL);
-	}
-
-	ut_ad(!buf_pool_watch_is_sentinel(buf_pool, bpage));
-
-	switch (buf_page_get_state(bpage)) {
-	case BUF_BLOCK_ZIP_PAGE:
-	case BUF_BLOCK_ZIP_DIRTY:
-		bpage->fix();
-		block_mutex = &buf_pool->zip_mutex;
-		goto got_block;
-	case BUF_BLOCK_FILE_PAGE:
-		/* Discard the uncompressed page frame if possible. */
-		if (!discard_attempted) {
-			rw_lock_s_unlock(hash_lock);
-			buf_block_try_discard_uncompressed(page_id);
-			discard_attempted = TRUE;
-			goto lookup;
-		}
-
-		buf_block_buf_fix_inc((buf_block_t*) bpage,
-				      __FILE__, __LINE__);
-
-		block_mutex = &((buf_block_t*) bpage)->mutex;
-		goto got_block;
-	default:
-		break;
-	}
-
-	ut_error;
-	goto err_exit;
+    rw_lock_s_unlock(hash_lock);
+    return(NULL);
+  }
+
+  ut_ad(!buf_pool_watch_is_sentinel(buf_pool, bpage));
+
+  switch (buf_page_get_state(bpage)) {
+  case BUF_BLOCK_ZIP_PAGE:
+  case BUF_BLOCK_ZIP_DIRTY:
+    bpage->fix();
+    block_mutex = &buf_pool->zip_mutex;
+    goto got_block;
+  case BUF_BLOCK_FILE_PAGE:
+    /* Discard the uncompressed page frame if possible. */
+    if (!discard_attempted) {
+      rw_lock_s_unlock(hash_lock);
+      buf_block_try_discard_uncompressed(page_id);
+      discard_attempted = TRUE;
+      goto lookup;
+    }
+
+    buf_block_buf_fix_inc((buf_block_t*) bpage,
+              __FILE__, __LINE__);
+
+    block_mutex = &((buf_block_t*) bpage)->mutex;
+    goto got_block;
+  default:
+    break;
+  }
+
+  ut_error;
+  goto err_exit;
 
 got_block:
-	mutex_enter(block_mutex);
-	must_read = buf_page_get_io_fix(bpage) == BUF_IO_READ;
+  mutex_enter(block_mutex);
+  must_read = buf_page_get_io_fix(bpage) == BUF_IO_READ;
 
-	rw_lock_s_unlock(hash_lock);
+  rw_lock_s_unlock(hash_lock);
 
-	ut_ad(!bpage->file_page_was_freed);
+  ut_ad(!bpage->file_page_was_freed);
 
-	buf_page_set_accessed(bpage);
+  buf_page_set_accessed(bpage);
 
-	mutex_exit(block_mutex);
+  mutex_exit(block_mutex);
 
-	buf_page_make_young_if_needed(buf_pool, bpage);
+  buf_page_make_young_if_needed(buf_pool, bpage);
 
 #if defined UNIV_DEBUG || defined UNIV_BUF_DEBUG
-	ut_a(++buf_dbg_counter % 5771 || buf_validate());
-	ut_a(bpage->buf_fix_count > 0);
-	ut_a(buf_page_in_file(bpage));
+  ut_a(++buf_dbg_counter % 5771 || buf_validate());
+  ut_a(bpage->buf_fix_count > 0);
+  ut_a(buf_page_in_file(bpage));
 #endif /* UNIV_DEBUG || UNIV_BUF_DEBUG */
 
-	if (must_read) {
-		/* Let us wait until the read operation
-		completes */
+  if (must_read) {
+    /* Let us wait until the read operation
+    completes */
 
-		for (;;) {
-			enum buf_io_fix	io_fix;
+    for (;;) {
+      enum buf_io_fix	io_fix;
 
-			mutex_enter(block_mutex);
-			io_fix = buf_page_get_io_fix(bpage);
-			mutex_exit(block_mutex);
+      mutex_enter(block_mutex);
+      io_fix = buf_page_get_io_fix(bpage);
+      mutex_exit(block_mutex);
 
-			if (io_fix == BUF_IO_READ) {
+      if (io_fix == BUF_IO_READ) {
 
-				os_thread_sleep(WAIT_FOR_READ);
-			} else {
-				break;
-			}
-		}
-	}
+        os_thread_sleep(WAIT_FOR_READ);
+      } else {
+        break;
+      }
+    }
+  }
 
-	return(bpage);
+  return(bpage);
 }
 
 /********************************************************************//**
@@ -3928,19 +4031,19 @@ UNIV_INLINE
 void
 buf_block_init_low(
 /*===============*/
-	buf_block_t*	block)	/*!< in: block to init */
+  buf_block_t*	block)	/*!< in: block to init */
 {
-	block->skip_flush_check = false;
+  block->skip_flush_check = false;
 #ifdef BTR_CUR_HASH_ADAPT
-	/* No adaptive hash index entries may point to a previously
-	unused (and now freshly allocated) block. */
-	assert_block_ahi_empty_on_init(block);
-	block->index		= NULL;
-
-	block->n_hash_helps	= 0;
-	block->n_fields		= 1;
-	block->n_bytes		= 0;
-	block->left_side	= TRUE;
+  /* No adaptive hash index entries may point to a previously
+  unused (and now freshly allocated) block. */
+  assert_block_ahi_empty_on_init(block);
+  block->index		= NULL;
+
+  block->n_hash_helps	= 0;
+  block->n_fields		= 1;
+  block->n_bytes		= 0;
+  block->left_side	= TRUE;
 #endif /* BTR_CUR_HASH_ADAPT */
 }
 
@@ -3950,96 +4053,96 @@ Decompress a block.
 ibool
 buf_zip_decompress(
 /*===============*/
-	buf_block_t*	block,	/*!< in/out: block */
-	ibool		check)	/*!< in: TRUE=verify the page checksum */
+  buf_block_t*	block,	/*!< in/out: block */
+  ibool		check)	/*!< in: TRUE=verify the page checksum */
 {
-	const byte*	frame = block->page.zip.data;
-	ulint		size = page_zip_get_size(&block->page.zip);
-	/* The tablespace will not be found if this function is called
-	during IMPORT. */
-	fil_space_t* space = fil_space_acquire_for_io(block->page.id.space());
-	const unsigned key_version = mach_read_from_4(
-		frame + FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION);
-	fil_space_crypt_t* crypt_data = space ? space->crypt_data : NULL;
-	const bool encrypted = crypt_data
-		&& crypt_data->type != CRYPT_SCHEME_UNENCRYPTED
-		&& (!crypt_data->is_default_encryption()
-		    || srv_encrypt_tables);
-
-	ut_ad(block->zip_size());
-	ut_a(block->page.id.space() != 0);
-
-	if (UNIV_UNLIKELY(check && !page_zip_verify_checksum(frame, size))) {
-
-		ib::error() << "Compressed page checksum mismatch for "
-			<< (space ? space->chain.start->name : "")
-			<< block->page.id << ": stored: "
-			<< mach_read_from_4(frame + FIL_PAGE_SPACE_OR_CHKSUM)
-			<< ", crc32: "
-			<< page_zip_calc_checksum(
-				frame, size, SRV_CHECKSUM_ALGORITHM_CRC32)
-			<< " innodb: "
-			<< page_zip_calc_checksum(
-				frame, size, SRV_CHECKSUM_ALGORITHM_INNODB)
-			<< ", none: "
-			<< page_zip_calc_checksum(
-				frame, size, SRV_CHECKSUM_ALGORITHM_NONE);
-		goto err_exit;
-	}
-
-	switch (fil_page_get_type(frame)) {
-	case FIL_PAGE_INDEX:
-	case FIL_PAGE_RTREE:
-		if (page_zip_decompress(&block->page.zip,
-					block->frame, TRUE)) {
-			if (space) {
-				space->release_for_io();
-			}
-			return(TRUE);
-		}
-
-		ib::error() << "Unable to decompress "
-			<< (space ? space->chain.start->name : "")
-			<< block->page.id;
-		goto err_exit;
-	case FIL_PAGE_TYPE_ALLOCATED:
-	case FIL_PAGE_INODE:
-	case FIL_PAGE_IBUF_BITMAP:
-	case FIL_PAGE_TYPE_FSP_HDR:
-	case FIL_PAGE_TYPE_XDES:
-	case FIL_PAGE_TYPE_ZBLOB:
-	case FIL_PAGE_TYPE_ZBLOB2:
-		/* Copy to uncompressed storage. */
-		memcpy(block->frame, frame, block->zip_size());
-		if (space) {
-			space->release_for_io();
-		}
-
-		return(TRUE);
-	}
-
-	ib::error() << "Unknown compressed page type "
-		<< fil_page_get_type(frame)
-		<< " in " << (space ? space->chain.start->name : "")
-		<< block->page.id;
+  const byte*	frame = block->page.zip.data;
+  ulint		size = page_zip_get_size(&block->page.zip);
+  /* The tablespace will not be found if this function is called
+  during IMPORT. */
+  fil_space_t* space = fil_space_acquire_for_io(block->page.id.space());
+  const unsigned key_version = mach_read_from_4(
+    frame + FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION);
+  fil_space_crypt_t* crypt_data = space ? space->crypt_data : NULL;
+  const bool encrypted = crypt_data
+    && crypt_data->type != CRYPT_SCHEME_UNENCRYPTED
+    && (!crypt_data->is_default_encryption()
+        || srv_encrypt_tables);
+
+  ut_ad(block->zip_size());
+  ut_a(block->page.id.space() != 0);
+
+  if (UNIV_UNLIKELY(check && !page_zip_verify_checksum(frame, size))) {
+
+    ib::error() << "Compressed page checksum mismatch for "
+      << (space ? space->chain.start->name : "")
+      << block->page.id << ": stored: "
+      << mach_read_from_4(frame + FIL_PAGE_SPACE_OR_CHKSUM)
+      << ", crc32: "
+      << page_zip_calc_checksum(
+        frame, size, SRV_CHECKSUM_ALGORITHM_CRC32)
+      << " innodb: "
+      << page_zip_calc_checksum(
+        frame, size, SRV_CHECKSUM_ALGORITHM_INNODB)
+      << ", none: "
+      << page_zip_calc_checksum(
+        frame, size, SRV_CHECKSUM_ALGORITHM_NONE);
+    goto err_exit;
+  }
+
+  switch (fil_page_get_type(frame)) {
+  case FIL_PAGE_INDEX:
+  case FIL_PAGE_RTREE:
+    if (page_zip_decompress(&block->page.zip,
+          block->frame, TRUE)) {
+      if (space) {
+        space->release_for_io();
+      }
+      return(TRUE);
+    }
+
+    ib::error() << "Unable to decompress "
+      << (space ? space->chain.start->name : "")
+      << block->page.id;
+    goto err_exit;
+  case FIL_PAGE_TYPE_ALLOCATED:
+  case FIL_PAGE_INODE:
+  case FIL_PAGE_IBUF_BITMAP:
+  case FIL_PAGE_TYPE_FSP_HDR:
+  case FIL_PAGE_TYPE_XDES:
+  case FIL_PAGE_TYPE_ZBLOB:
+  case FIL_PAGE_TYPE_ZBLOB2:
+    /* Copy to uncompressed storage. */
+    memcpy(block->frame, frame, block->zip_size());
+    if (space) {
+      space->release_for_io();
+    }
+
+    return(TRUE);
+  }
+
+  ib::error() << "Unknown compressed page type "
+    << fil_page_get_type(frame)
+    << " in " << (space ? space->chain.start->name : "")
+    << block->page.id;
 
 err_exit:
-	if (encrypted) {
-		ib::info() << "Row compressed page could be encrypted"
-			" with key_version " << key_version;
-	}
-
-	if (space) {
-		if (encrypted) {
-			dict_set_encrypted_by_space(space);
-		} else {
-			dict_set_corrupted_by_space(space);
-		}
-
-		space->release_for_io();
-	}
-
-	return(FALSE);
+  if (encrypted) {
+    ib::info() << "Row compressed page could be encrypted"
+      " with key_version " << key_version;
+  }
+
+  if (space) {
+    if (encrypted) {
+      dict_set_encrypted_by_space(space);
+    } else {
+      dict_set_corrupted_by_space(space);
+    }
+
+    space->release_for_io();
+  }
+
+  return(FALSE);
 }
 
 #ifdef BTR_CUR_HASH_ADAPT
@@ -4050,40 +4153,40 @@ This function does not return if the block is not identified.
 buf_block_t*
 buf_block_from_ahi(const byte* ptr)
 {
-	buf_pool_chunk_map_t::iterator it;
+  buf_pool_chunk_map_t::iterator it;
 
-	buf_pool_chunk_map_t*	chunk_map = buf_chunk_map_ref;
-	ut_ad(buf_chunk_map_ref == buf_chunk_map_reg);
-	ut_ad(!buf_pool_resizing);
+  buf_pool_chunk_map_t*	chunk_map = buf_chunk_map_ref;
+  ut_ad(buf_chunk_map_ref == buf_chunk_map_reg);
+  ut_ad(!buf_pool_resizing);
 
-	buf_chunk_t*	chunk;
-	it = chunk_map->upper_bound(ptr);
+  buf_chunk_t*	chunk;
+  it = chunk_map->upper_bound(ptr);
 
-	ut_a(it != chunk_map->begin());
+  ut_a(it != chunk_map->begin());
 
-	if (it == chunk_map->end()) {
-		chunk = chunk_map->rbegin()->second;
-	} else {
-		chunk = (--it)->second;
-	}
+  if (it == chunk_map->end()) {
+    chunk = chunk_map->rbegin()->second;
+  } else {
+    chunk = (--it)->second;
+  }
 
-	ulint		offs = ulint(ptr - chunk->blocks->frame);
+  ulint		offs = ulint(ptr - chunk->blocks->frame);
 
-	offs >>= srv_page_size_shift;
+  offs >>= srv_page_size_shift;
 
-	ut_a(offs < chunk->size);
+  ut_a(offs < chunk->size);
 
-	buf_block_t*	block = &chunk->blocks[offs];
+  buf_block_t*	block = &chunk->blocks[offs];
 
-	/* The function buf_chunk_init() invokes buf_block_init() so that
-	block[n].frame == block->frame + n * srv_page_size.  Check it. */
-	ut_ad(block->frame == page_align(ptr));
-	/* Read the state of the block without holding a mutex.
-	A state transition from BUF_BLOCK_FILE_PAGE to
-	BUF_BLOCK_REMOVE_HASH is possible during this execution. */
-	ut_d(const buf_page_state state = buf_block_get_state(block));
-	ut_ad(state == BUF_BLOCK_FILE_PAGE || state == BUF_BLOCK_REMOVE_HASH);
-	return(block);
+  /* The function buf_chunk_init() invokes buf_block_init() so that
+  block[n].frame == block->frame + n * srv_page_size.  Check it. */
+  ut_ad(block->frame == page_align(ptr));
+  /* Read the state of the block without holding a mutex.
+  A state transition from BUF_BLOCK_FILE_PAGE to
+  BUF_BLOCK_REMOVE_HASH is possible during this execution. */
+  ut_d(const buf_page_state state = buf_block_get_state(block));
+  ut_ad(state == BUF_BLOCK_FILE_PAGE || state == BUF_BLOCK_REMOVE_HASH);
+  return(block);
 }
 #endif /* BTR_CUR_HASH_ADAPT */
 
@@ -4096,26 +4199,26 @@ static
 ibool
 buf_pointer_is_block_field_instance(
 /*================================*/
-	buf_pool_t*	buf_pool,	/*!< in: buffer pool instance */
-	const void*	ptr)		/*!< in: pointer not dereferenced */
+  buf_pool_t*	buf_pool,	/*!< in: buffer pool instance */
+  const void*	ptr)		/*!< in: pointer not dereferenced */
 {
-	const buf_chunk_t*		chunk	= buf_pool->chunks;
-	const buf_chunk_t* const	echunk	= chunk + ut_min(
-		buf_pool->n_chunks, buf_pool->n_chunks_new);
+  const buf_chunk_t*		chunk	= buf_pool->chunks;
+  const buf_chunk_t* const	echunk	= chunk + ut_min(
+    buf_pool->n_chunks, buf_pool->n_chunks_new);
 
-	/* TODO: protect buf_pool->chunks with a mutex (the older pointer will
-	currently remain while during buf_pool_resize()) */
-	while (chunk < echunk) {
-		if (ptr >= (void*) chunk->blocks
-		    && ptr < (void*) (chunk->blocks + chunk->size)) {
+  /* TODO: protect buf_pool->chunks with a mutex (the older pointer will
+  currently remain while during buf_pool_resize()) */
+  while (chunk < echunk) {
+    if (ptr >= (void*) chunk->blocks
+        && ptr < (void*) (chunk->blocks + chunk->size)) {
 
-			return(TRUE);
-		}
+      return(TRUE);
+    }
 
-		chunk++;
-	}
+    chunk++;
+  }
 
-	return(FALSE);
+  return(FALSE);
 }
 
 /********************************************************************//**
@@ -4125,21 +4228,21 @@ the buf_block_t itself or a member of it
 ibool
 buf_pointer_is_block_field(
 /*=======================*/
-	const void*	ptr)	/*!< in: pointer not dereferenced */
+  const void*	ptr)	/*!< in: pointer not dereferenced */
 {
-	ulint	i;
+  ulint	i;
 
-	for (i = 0; i < srv_buf_pool_instances; i++) {
-		ibool	found;
+  for (i = 0; i < srv_buf_pool_instances; i++) {
+    ibool	found;
 
-		found = buf_pointer_is_block_field_instance(
-			buf_pool_from_array(i), ptr);
-		if (found) {
-			return(TRUE);
-		}
-	}
+    found = buf_pointer_is_block_field_instance(
+      buf_pool_from_array(i), ptr);
+    if (found) {
+      return(TRUE);
+    }
+  }
 
-	return(FALSE);
+  return(FALSE);
 }
 
 /********************************************************************//**
@@ -4149,16 +4252,16 @@ static
 ibool
 buf_block_is_uncompressed(
 /*======================*/
-	buf_pool_t*		buf_pool,	/*!< in: buffer pool instance */
-	const buf_block_t*	block)		/*!< in: pointer to block,
-						not dereferenced */
+  buf_pool_t*		buf_pool,	/*!< in: buffer pool instance */
+  const buf_block_t*	block)		/*!< in: pointer to block,
+            not dereferenced */
 {
-	if ((((ulint) block) % sizeof *block) != 0) {
-		/* The pointer should be aligned. */
-		return(FALSE);
-	}
+  if ((((ulint) block) % sizeof *block) != 0) {
+    /* The pointer should be aligned. */
+    return(FALSE);
+  }
 
-	return(buf_pointer_is_block_field_instance(buf_pool, (void*) block));
+  return(buf_pointer_is_block_field_instance(buf_pool, (void*) block));
 }
 
 #if defined UNIV_DEBUG || defined UNIV_IBUF_DEBUG
@@ -4170,8 +4273,8 @@ bool
 buf_debug_execute_is_force_flush()
 /*==============================*/
 {
-	DBUG_EXECUTE_IF("ib_buf_force_flush", return(true); );
-	return(false);
+  DBUG_EXECUTE_IF("ib_buf_force_flush", return(true); );
+  return(false);
 }
 #endif /* UNIV_DEBUG || UNIV_IBUF_DEBUG */
 
@@ -4180,40 +4283,40 @@ buf_debug_execute_is_force_flush()
 static
 void
 buf_wait_for_read(
-	buf_block_t*	block)
+  buf_block_t*	block)
 {
-	/* Note:
+  /* Note:
 
-	We are using the block->lock to check for IO state (and a dirty read).
-	We set the IO_READ state under the protection of the hash_lock
-	(and block->mutex). This is safe because another thread can only
-	access the block (and check for IO state) after the block has been
-	added to the page hashtable. */
+  We are using the block->lock to check for IO state (and a dirty read).
+  We set the IO_READ state under the protection of the hash_lock
+  (and block->mutex). This is safe because another thread can only
+  access the block (and check for IO state) after the block has been
+  added to the page hashtable. */
 
-	if (buf_block_get_io_fix(block) == BUF_IO_READ) {
+  if (buf_block_get_io_fix(block) == BUF_IO_READ) {
 
-		/* Wait until the read operation completes */
+    /* Wait until the read operation completes */
 
-		BPageMutex*	mutex = buf_page_get_mutex(&block->page);
+    BPageMutex*	mutex = buf_page_get_mutex(&block->page);
 
-		for (;;) {
-			buf_io_fix	io_fix;
+    for (;;) {
+      buf_io_fix	io_fix;
 
-			mutex_enter(mutex);
+      mutex_enter(mutex);
 
-			io_fix = buf_block_get_io_fix(block);
+      io_fix = buf_block_get_io_fix(block);
 
-			mutex_exit(mutex);
+      mutex_exit(mutex);
 
-			if (io_fix == BUF_IO_READ) {
-				/* Wait by temporaly s-latch */
-				rw_lock_s_lock(&block->lock);
-				rw_lock_s_unlock(&block->lock);
-			} else {
-				break;
-			}
-		}
-	}
+      if (io_fix == BUF_IO_READ) {
+        /* Wait by temporaly s-latch */
+        rw_lock_s_lock(&block->lock);
+        rw_lock_s_unlock(&block->lock);
+      } else {
+        break;
+      }
+    }
+  }
 }
 
 /** This is the general function used to get access to a database page.
@@ -4234,700 +4337,700 @@ reading the page from file.
 @return pointer to the block or NULL */
 buf_block_t*
 buf_page_get_gen(
-	const page_id_t		page_id,
-	ulint			zip_size,
-	ulint			rw_latch,
-	buf_block_t*		guess,
-	ulint			mode,
-	const char*		file,
-	unsigned		line,
-	mtr_t*			mtr,
-	dberr_t*		err,
-	bool			allow_ibuf_merge)
+  const page_id_t		page_id,
+  ulint			zip_size,
+  ulint			rw_latch,
+  buf_block_t*		guess,
+  ulint			mode,
+  const char*		file,
+  unsigned		line,
+  mtr_t*			mtr,
+  dberr_t*		err,
+  bool			allow_ibuf_merge)
 {
-	buf_block_t*	block;
-	unsigned	access_time;
-	rw_lock_t*	hash_lock;
-	buf_block_t*	fix_block;
-	ulint		retries = 0;
-	buf_pool_t*	buf_pool = buf_pool_get(page_id);
-
-	ut_ad((mtr == NULL) == (mode == BUF_EVICT_IF_IN_POOL));
-	ut_ad(!mtr || mtr->is_active());
-	ut_ad((rw_latch == RW_S_LATCH)
-	      || (rw_latch == RW_X_LATCH)
-	      || (rw_latch == RW_SX_LATCH)
-	      || (rw_latch == RW_NO_LATCH));
-	ut_ad(!allow_ibuf_merge
-	      || mode == BUF_GET
-	      || mode == BUF_GET_IF_IN_POOL
-	      || mode == BUF_GET_IF_IN_POOL_OR_WATCH);
-
-	if (err) {
-		*err = DB_SUCCESS;
-	}
+  buf_block_t*	block;
+  unsigned	access_time;
+  rw_lock_t*	hash_lock;
+  buf_block_t*	fix_block;
+  ulint		retries = 0;
+  buf_pool_t*	buf_pool = buf_pool_get(page_id);
+
+  ut_ad((mtr == NULL) == (mode == BUF_EVICT_IF_IN_POOL));
+  ut_ad(!mtr || mtr->is_active());
+  ut_ad((rw_latch == RW_S_LATCH)
+        || (rw_latch == RW_X_LATCH)
+        || (rw_latch == RW_SX_LATCH)
+        || (rw_latch == RW_NO_LATCH));
+  ut_ad(!allow_ibuf_merge
+        || mode == BUF_GET
+        || mode == BUF_GET_IF_IN_POOL
+        || mode == BUF_GET_IF_IN_POOL_OR_WATCH);
+
+  if (err) {
+    *err = DB_SUCCESS;
+  }
 
 #ifdef UNIV_DEBUG
-	switch (mode) {
-	case BUF_EVICT_IF_IN_POOL:
-		/* After DISCARD TABLESPACE, the tablespace would not exist,
-		but in IMPORT TABLESPACE, PageConverter::operator() must
-		replace any old pages, which were not evicted during DISCARD.
-		Skip the assertion on space_page_size. */
-		break;
-	case BUF_PEEK_IF_IN_POOL:
-	case BUF_GET_IF_IN_POOL:
-		/* The caller may pass a dummy page size,
-		because it does not really matter. */
-		break;
-	default:
-		ut_error;
-	case BUF_GET_NO_LATCH:
-		ut_ad(rw_latch == RW_NO_LATCH);
-		/* fall through */
-	case BUF_GET:
-	case BUF_GET_IF_IN_POOL_OR_WATCH:
-	case BUF_GET_POSSIBLY_FREED:
-		fil_space_t* s = fil_space_acquire_for_io(page_id.space());
-		ut_ad(s);
-		ut_ad(s->zip_size() == zip_size);
-		s->release_for_io();
-	}
+  switch (mode) {
+  case BUF_EVICT_IF_IN_POOL:
+    /* After DISCARD TABLESPACE, the tablespace would not exist,
+    but in IMPORT TABLESPACE, PageConverter::operator() must
+    replace any old pages, which were not evicted during DISCARD.
+    Skip the assertion on space_page_size. */
+    break;
+  case BUF_PEEK_IF_IN_POOL:
+  case BUF_GET_IF_IN_POOL:
+    /* The caller may pass a dummy page size,
+    because it does not really matter. */
+    break;
+  default:
+    ut_error;
+  case BUF_GET_NO_LATCH:
+    ut_ad(rw_latch == RW_NO_LATCH);
+    /* fall through */
+  case BUF_GET:
+  case BUF_GET_IF_IN_POOL_OR_WATCH:
+  case BUF_GET_POSSIBLY_FREED:
+    fil_space_t* s = fil_space_acquire_for_io(page_id.space());
+    ut_ad(s);
+    ut_ad(s->zip_size() == zip_size);
+    s->release_for_io();
+  }
 #endif /* UNIV_DEBUG */
 
-	ut_ad(!mtr || !ibuf_inside(mtr)
-	      || ibuf_page_low(page_id, zip_size, FALSE, file, line, NULL));
+  ut_ad(!mtr || !ibuf_inside(mtr)
+        || ibuf_page_low(page_id, zip_size, FALSE, file, line, NULL));
 
-	buf_pool->stat.n_page_gets++;
-	hash_lock = buf_page_hash_lock_get(buf_pool, page_id);
+  buf_pool->stat.n_page_gets++;
+  hash_lock = buf_page_hash_lock_get(buf_pool, page_id);
 loop:
-	block = guess;
-
-	rw_lock_s_lock(hash_lock);
-
-	/* If not own buf_pool_mutex, page_hash can be changed. */
-	hash_lock = buf_page_hash_lock_s_confirm(hash_lock, buf_pool, page_id);
-
-	if (block != NULL) {
-
-		/* If the guess is a compressed page descriptor that
-		has been allocated by buf_page_alloc_descriptor(),
-		it may have been freed by buf_relocate(). */
-
-		if (!buf_block_is_uncompressed(buf_pool, block)
-		    || page_id != block->page.id
-		    || buf_block_get_state(block) != BUF_BLOCK_FILE_PAGE) {
-
-			/* Our guess was bogus or things have changed
-			since. */
-			block = guess = NULL;
-		} else {
-			ut_ad(!block->page.in_zip_hash);
-		}
-	}
-
-	if (block == NULL) {
-		block = (buf_block_t*) buf_page_hash_get_low(buf_pool, page_id);
-	}
-
-	if (!block || buf_pool_watch_is_sentinel(buf_pool, &block->page)) {
-		rw_lock_s_unlock(hash_lock);
-		block = NULL;
-	}
-
-	if (block == NULL) {
-
-		/* Page not in buf_pool: needs to be read from file */
-
-		if (mode == BUF_GET_IF_IN_POOL_OR_WATCH) {
-			rw_lock_x_lock(hash_lock);
-
-			/* If not own buf_pool_mutex,
-			page_hash can be changed. */
-			hash_lock = buf_page_hash_lock_x_confirm(
-				hash_lock, buf_pool, page_id);
-
-			block = (buf_block_t*) buf_pool_watch_set(
-				page_id, &hash_lock);
-
-			if (block) {
-				/* We can release hash_lock after we
-				increment the fix count to make
-				sure that no state change takes place. */
-				fix_block = block;
-
-				if (fsp_is_system_temporary(page_id.space())) {
-					/* For temporary tablespace,
-					the mutex is being used for
-					synchronization between user
-					thread and flush thread,
-					instead of block->lock. See
-					buf_flush_page() for the flush
-					thread counterpart. */
-
-					BPageMutex*	fix_mutex
-						= buf_page_get_mutex(
-							&fix_block->page);
-					mutex_enter(fix_mutex);
-					fix_block->fix();
-					mutex_exit(fix_mutex);
-				} else {
-					fix_block->fix();
-				}
-
-				/* Now safe to release page_hash mutex */
-				rw_lock_x_unlock(hash_lock);
-				goto got_block;
-			}
-
-			rw_lock_x_unlock(hash_lock);
-		}
-
-		switch (mode) {
-		case BUF_GET_IF_IN_POOL:
-		case BUF_GET_IF_IN_POOL_OR_WATCH:
-		case BUF_PEEK_IF_IN_POOL:
-		case BUF_EVICT_IF_IN_POOL:
-			ut_ad(!rw_lock_own_flagged(
-				      hash_lock,
-				      RW_LOCK_FLAG_X | RW_LOCK_FLAG_S));
-			return(NULL);
-		}
-
-		/* The call path is buf_read_page() ->
-		buf_read_page_low() (fil_io()) ->
-		buf_page_io_complete() ->
-		buf_decrypt_after_read(). Here fil_space_t* is used
-		and we decrypt -> buf_page_check_corrupt() where page
-		checksums are compared. Decryption, decompression as
-		well as error handling takes place at a lower level.
-		Here we only need to know whether the page really is
-		corrupted, or if an encrypted page with a valid
-		checksum cannot be decypted. */
-
-		dberr_t local_err = buf_read_page(page_id, zip_size);
-
-		if (local_err == DB_SUCCESS) {
-			buf_read_ahead_random(page_id, zip_size,
-					      ibuf_inside(mtr));
-
-			retries = 0;
-		} else if (mode == BUF_GET_POSSIBLY_FREED) {
-			if (err) {
-				*err = local_err;
-			}
-			return NULL;
-		} else if (retries < BUF_PAGE_READ_MAX_RETRIES) {
-			++retries;
-
-			DBUG_EXECUTE_IF(
-				"innodb_page_corruption_retries",
-				retries = BUF_PAGE_READ_MAX_RETRIES;
-			);
-		} else {
-			if (err) {
-				*err = local_err;
-			}
-
-			/* Pages whose encryption key is unavailable or used
-			key, encryption algorithm or encryption method is
-			incorrect are marked as encrypted in
-			buf_page_check_corrupt(). Unencrypted page could be
-			corrupted in a way where the key_id field is
-			nonzero. There is no checksum on field
-			FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION. */
-			if (local_err == DB_DECRYPTION_FAILED) {
-				return (NULL);
-			}
-
-			if (local_err == DB_PAGE_CORRUPTED
-			    && srv_force_recovery) {
-				return NULL;
-			}
-
-			/* Try to set table as corrupted instead of
-			asserting. */
-			if (page_id.space() == TRX_SYS_SPACE) {
-			} else if (page_id.space() == SRV_TMP_SPACE_ID) {
-			} else if (fil_space_t* space
-				   = fil_space_acquire_for_io(
-					   page_id.space())) {
-				bool set = dict_set_corrupted_by_space(space);
-				space->release_for_io();
-				if (set) {
-					return NULL;
-				}
-			}
-
-			ib::fatal() << "Unable to read page " << page_id
-				<< " into the buffer pool after "
-				<< BUF_PAGE_READ_MAX_RETRIES
-				<< ". The most probable cause"
-				" of this error may be that the"
-				" table has been corrupted."
-				" See https://mariadb.com/kb/en/library/innodb-recovery-modes/";
-		}
+  block = guess;
+
+  rw_lock_s_lock(hash_lock);
+
+  /* If not own buf_pool_mutex, page_hash can be changed. */
+  hash_lock = buf_page_hash_lock_s_confirm(hash_lock, buf_pool, page_id);
+
+  if (block != NULL) {
+
+    /* If the guess is a compressed page descriptor that
+    has been allocated by buf_page_alloc_descriptor(),
+    it may have been freed by buf_relocate(). */
+
+    if (!buf_block_is_uncompressed(buf_pool, block)
+        || page_id != block->page.id
+        || buf_block_get_state(block) != BUF_BLOCK_FILE_PAGE) {
+
+      /* Our guess was bogus or things have changed
+      since. */
+      block = guess = NULL;
+    } else {
+      ut_ad(!block->page.in_zip_hash);
+    }
+  }
+
+  if (block == NULL) {
+    block = (buf_block_t*) buf_page_hash_get_low(buf_pool, page_id);
+  }
+
+  if (!block || buf_pool_watch_is_sentinel(buf_pool, &block->page)) {
+    rw_lock_s_unlock(hash_lock);
+    block = NULL;
+  }
+
+  if (block == NULL) {
+
+    /* Page not in buf_pool: needs to be read from file */
+
+    if (mode == BUF_GET_IF_IN_POOL_OR_WATCH) {
+      rw_lock_x_lock(hash_lock);
+
+      /* If not own buf_pool_mutex,
+      page_hash can be changed. */
+      hash_lock = buf_page_hash_lock_x_confirm(
+        hash_lock, buf_pool, page_id);
+
+      block = (buf_block_t*) buf_pool_watch_set(
+        page_id, &hash_lock);
+
+      if (block) {
+        /* We can release hash_lock after we
+        increment the fix count to make
+        sure that no state change takes place. */
+        fix_block = block;
+
+        if (fsp_is_system_temporary(page_id.space())) {
+          /* For temporary tablespace,
+          the mutex is being used for
+          synchronization between user
+          thread and flush thread,
+          instead of block->lock. See
+          buf_flush_page() for the flush
+          thread counterpart. */
+
+          BPageMutex*	fix_mutex
+            = buf_page_get_mutex(
+              &fix_block->page);
+          mutex_enter(fix_mutex);
+          fix_block->fix();
+          mutex_exit(fix_mutex);
+        } else {
+          fix_block->fix();
+        }
+
+        /* Now safe to release page_hash mutex */
+        rw_lock_x_unlock(hash_lock);
+        goto got_block;
+      }
+
+      rw_lock_x_unlock(hash_lock);
+    }
+
+    switch (mode) {
+    case BUF_GET_IF_IN_POOL:
+    case BUF_GET_IF_IN_POOL_OR_WATCH:
+    case BUF_PEEK_IF_IN_POOL:
+    case BUF_EVICT_IF_IN_POOL:
+      ut_ad(!rw_lock_own_flagged(
+              hash_lock,
+              RW_LOCK_FLAG_X | RW_LOCK_FLAG_S));
+      return(NULL);
+    }
+
+    /* The call path is buf_read_page() ->
+    buf_read_page_low() (fil_io()) ->
+    buf_page_io_complete() ->
+    buf_decrypt_after_read(). Here fil_space_t* is used
+    and we decrypt -> buf_page_check_corrupt() where page
+    checksums are compared. Decryption, decompression as
+    well as error handling takes place at a lower level.
+    Here we only need to know whether the page really is
+    corrupted, or if an encrypted page with a valid
+    checksum cannot be decypted. */
+
+    dberr_t local_err = buf_read_page(page_id, zip_size);
+
+    if (local_err == DB_SUCCESS) {
+      buf_read_ahead_random(page_id, zip_size,
+                ibuf_inside(mtr));
+
+      retries = 0;
+    } else if (mode == BUF_GET_POSSIBLY_FREED) {
+      if (err) {
+        *err = local_err;
+      }
+      return NULL;
+    } else if (retries < BUF_PAGE_READ_MAX_RETRIES) {
+      ++retries;
+
+      DBUG_EXECUTE_IF(
+        "innodb_page_corruption_retries",
+        retries = BUF_PAGE_READ_MAX_RETRIES;
+      );
+    } else {
+      if (err) {
+        *err = local_err;
+      }
+
+      /* Pages whose encryption key is unavailable or used
+      key, encryption algorithm or encryption method is
+      incorrect are marked as encrypted in
+      buf_page_check_corrupt(). Unencrypted page could be
+      corrupted in a way where the key_id field is
+      nonzero. There is no checksum on field
+      FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION. */
+      if (local_err == DB_DECRYPTION_FAILED) {
+        return (NULL);
+      }
+
+      if (local_err == DB_PAGE_CORRUPTED
+          && srv_force_recovery) {
+        return NULL;
+      }
+
+      /* Try to set table as corrupted instead of
+      asserting. */
+      if (page_id.space() == TRX_SYS_SPACE) {
+      } else if (page_id.space() == SRV_TMP_SPACE_ID) {
+      } else if (fil_space_t* space
+           = fil_space_acquire_for_io(
+             page_id.space())) {
+        bool set = dict_set_corrupted_by_space(space);
+        space->release_for_io();
+        if (set) {
+          return NULL;
+        }
+      }
+
+      ib::fatal() << "Unable to read page " << page_id
+        << " into the buffer pool after "
+        << BUF_PAGE_READ_MAX_RETRIES
+        << ". The most probable cause"
+        " of this error may be that the"
+        " table has been corrupted."
+        " See https://mariadb.com/kb/en/library/innodb-recovery-modes/";
+    }
 
 #if defined UNIV_DEBUG || defined UNIV_BUF_DEBUG
-		ut_a(++buf_dbg_counter % 5771 || buf_validate());
+    ut_a(++buf_dbg_counter % 5771 || buf_validate());
 #endif /* UNIV_DEBUG || UNIV_BUF_DEBUG */
-		goto loop;
-	} else {
-		fix_block = block;
-	}
-
-	if (fsp_is_system_temporary(page_id.space())) {
-		/* For temporary tablespace, the mutex is being used
-		for synchorization between user thread and flush thread,
-		instead of block->lock. See buf_flush_page() for the flush
-		thread counterpart. */
-		BPageMutex*	fix_mutex = buf_page_get_mutex(
-						&fix_block->page);
-		mutex_enter(fix_mutex);
-		fix_block->fix();
-		mutex_exit(fix_mutex);
-	} else {
-		fix_block->fix();
-	}
-
-	/* Now safe to release page_hash mutex */
-	rw_lock_s_unlock(hash_lock);
+    goto loop;
+  } else {
+    fix_block = block;
+  }
+
+  if (fsp_is_system_temporary(page_id.space())) {
+    /* For temporary tablespace, the mutex is being used
+    for synchorization between user thread and flush thread,
+    instead of block->lock. See buf_flush_page() for the flush
+    thread counterpart. */
+    BPageMutex*	fix_mutex = buf_page_get_mutex(
+            &fix_block->page);
+    mutex_enter(fix_mutex);
+    fix_block->fix();
+    mutex_exit(fix_mutex);
+  } else {
+    fix_block->fix();
+  }
+
+  /* Now safe to release page_hash mutex */
+  rw_lock_s_unlock(hash_lock);
 
 got_block:
-	switch (mode) {
-	default:
-		ut_ad(block->zip_size() == zip_size);
-		break;
-	case BUF_GET_IF_IN_POOL:
-	case BUF_PEEK_IF_IN_POOL:
-	case BUF_EVICT_IF_IN_POOL:
-		buf_page_t*	fix_page = &fix_block->page;
-		BPageMutex*	fix_mutex = buf_page_get_mutex(fix_page);
-		mutex_enter(fix_mutex);
-		const bool	must_read
-			= (buf_page_get_io_fix(fix_page) == BUF_IO_READ);
-		mutex_exit(fix_mutex);
-
-		if (must_read) {
-			/* The page is being read to buffer pool,
-			but we cannot wait around for the read to
-			complete. */
-			fix_block->unfix();
-
-			return(NULL);
-		}
-	}
-
-	switch (UNIV_EXPECT(buf_block_get_state(fix_block),
-			    BUF_BLOCK_FILE_PAGE)) {
-	case BUF_BLOCK_FILE_PAGE:
-		if (fsp_is_system_temporary(page_id.space())
-		    && buf_block_get_io_fix(block) != BUF_IO_NONE) {
-			/* This suggests that the page is being flushed.
-			Avoid returning reference to this page.
-			Instead wait for the flush action to complete. */
-			fix_block->unfix();
-			os_thread_sleep(WAIT_FOR_WRITE);
-			goto loop;
-		}
-
-		if (UNIV_UNLIKELY(mode == BUF_EVICT_IF_IN_POOL)) {
-evict_from_pool:
-			ut_ad(!fix_block->page.oldest_modification);
-			buf_pool_mutex_enter(buf_pool);
-			fix_block->unfix();
+  switch (mode) {
+  default:
+    ut_ad(block->zip_size() == zip_size);
+    break;
+  case BUF_GET_IF_IN_POOL:
+  case BUF_PEEK_IF_IN_POOL:
+  case BUF_EVICT_IF_IN_POOL:
+    buf_page_t*	fix_page = &fix_block->page;
+    BPageMutex*	fix_mutex = buf_page_get_mutex(fix_page);
+    mutex_enter(fix_mutex);
+    const bool	must_read
+      = (buf_page_get_io_fix(fix_page) == BUF_IO_READ);
+    mutex_exit(fix_mutex);
+
+    if (must_read) {
+      /* The page is being read to buffer pool,
+      but we cannot wait around for the read to
+      complete. */
+      fix_block->unfix();
+
+      return(NULL);
+    }
+  }
+
+  switch (UNIV_EXPECT(buf_block_get_state(fix_block),
+          BUF_BLOCK_FILE_PAGE)) {
+  case BUF_BLOCK_FILE_PAGE:
+    if (fsp_is_system_temporary(page_id.space())
+        && buf_block_get_io_fix(block) != BUF_IO_NONE) {
+      /* This suggests that the page is being flushed.
+      Avoid returning reference to this page.
+      Instead wait for the flush action to complete. */
+      fix_block->unfix();
+      os_thread_sleep(WAIT_FOR_WRITE);
+      goto loop;
+    }
 
-			if (!buf_LRU_free_page(&fix_block->page, true)) {
-				ut_ad(0);
-			}
+    if (UNIV_UNLIKELY(mode == BUF_EVICT_IF_IN_POOL)) {
+evict_from_pool:
+      ut_ad(!fix_block->page.oldest_modification);
+      buf_pool_mutex_enter(buf_pool);
+      fix_block->unfix();
 
-			buf_pool_mutex_exit(buf_pool);
-			return(NULL);
-		}
-		break;
-	default:
-		ut_error;
-		break;
+      if (!buf_LRU_free_page(&fix_block->page, true)) {
+        ut_ad(0);
+      }
 
-	case BUF_BLOCK_ZIP_PAGE:
-	case BUF_BLOCK_ZIP_DIRTY:
-		if (UNIV_UNLIKELY(mode == BUF_EVICT_IF_IN_POOL)) {
-			goto evict_from_pool;
-		}
+      buf_pool_mutex_exit(buf_pool);
+      return(NULL);
+    }
+    break;
+  default:
+    ut_error;
+    break;
+
+  case BUF_BLOCK_ZIP_PAGE:
+  case BUF_BLOCK_ZIP_DIRTY:
+    if (UNIV_UNLIKELY(mode == BUF_EVICT_IF_IN_POOL)) {
+      goto evict_from_pool;
+    }
 
-		if (mode == BUF_PEEK_IF_IN_POOL) {
-			/* This mode is only used for dropping an
-			adaptive hash index.  There cannot be an
-			adaptive hash index for a compressed-only
-			page, so do not bother decompressing the page. */
-			fix_block->unfix();
+    if (mode == BUF_PEEK_IF_IN_POOL) {
+      /* This mode is only used for dropping an
+      adaptive hash index.  There cannot be an
+      adaptive hash index for a compressed-only
+      page, so do not bother decompressing the page. */
+      fix_block->unfix();
 
-			return(NULL);
-		}
+      return(NULL);
+    }
 
-		buf_page_t* bpage = &block->page;
+    buf_page_t* bpage = &block->page;
 
-		/* Note: We have already buffer fixed this block. */
-		if (bpage->buf_fix_count > 1
-		    || buf_page_get_io_fix(bpage) != BUF_IO_NONE) {
+    /* Note: We have already buffer fixed this block. */
+    if (bpage->buf_fix_count > 1
+        || buf_page_get_io_fix(bpage) != BUF_IO_NONE) {
 
-			/* This condition often occurs when the buffer
-			is not buffer-fixed, but I/O-fixed by
-			buf_page_init_for_read(). */
-			fix_block->unfix();
+      /* This condition often occurs when the buffer
+      is not buffer-fixed, but I/O-fixed by
+      buf_page_init_for_read(). */
+      fix_block->unfix();
 
-			/* The block is buffer-fixed or I/O-fixed.
-			Try again later. */
-			os_thread_sleep(WAIT_FOR_READ);
+      /* The block is buffer-fixed or I/O-fixed.
+      Try again later. */
+      os_thread_sleep(WAIT_FOR_READ);
 
-			goto loop;
-		}
+      goto loop;
+    }
 
-		/* Buffer-fix the block so that it cannot be evicted
-		or relocated while we are attempting to allocate an
-		uncompressed page. */
+    /* Buffer-fix the block so that it cannot be evicted
+    or relocated while we are attempting to allocate an
+    uncompressed page. */
 
-		block = buf_LRU_get_free_block(buf_pool);
+    block = buf_LRU_get_free_block(buf_pool);
 
-		buf_pool_mutex_enter(buf_pool);
+    buf_pool_mutex_enter(buf_pool);
 
-		/* If not own buf_pool_mutex, page_hash can be changed. */
-		hash_lock = buf_page_hash_lock_get(buf_pool, page_id);
+    /* If not own buf_pool_mutex, page_hash can be changed. */
+    hash_lock = buf_page_hash_lock_get(buf_pool, page_id);
 
-		rw_lock_x_lock(hash_lock);
+    rw_lock_x_lock(hash_lock);
 
-		/* Buffer-fixing prevents the page_hash from changing. */
-		ut_ad(bpage == buf_page_hash_get_low(buf_pool, page_id));
+    /* Buffer-fixing prevents the page_hash from changing. */
+    ut_ad(bpage == buf_page_hash_get_low(buf_pool, page_id));
 
-		fix_block->unfix();
+    fix_block->unfix();
 
-		buf_page_mutex_enter(block);
-		mutex_enter(&buf_pool->zip_mutex);
+    buf_page_mutex_enter(block);
+    mutex_enter(&buf_pool->zip_mutex);
 
-		fix_block = block;
+    fix_block = block;
 
-		if (bpage->buf_fix_count > 0
-		    || buf_page_get_io_fix(bpage) != BUF_IO_NONE) {
+    if (bpage->buf_fix_count > 0
+        || buf_page_get_io_fix(bpage) != BUF_IO_NONE) {
 
-			mutex_exit(&buf_pool->zip_mutex);
-			/* The block was buffer-fixed or I/O-fixed while
-			buf_pool->mutex was not held by this thread.
-			Free the block that was allocated and retry.
-			This should be extremely unlikely, for example,
-			if buf_page_get_zip() was invoked. */
+      mutex_exit(&buf_pool->zip_mutex);
+      /* The block was buffer-fixed or I/O-fixed while
+      buf_pool->mutex was not held by this thread.
+      Free the block that was allocated and retry.
+      This should be extremely unlikely, for example,
+      if buf_page_get_zip() was invoked. */
 
-			buf_LRU_block_free_non_file_page(block);
-			buf_pool_mutex_exit(buf_pool);
-			rw_lock_x_unlock(hash_lock);
-			buf_page_mutex_exit(block);
+      buf_LRU_block_free_non_file_page(block);
+      buf_pool_mutex_exit(buf_pool);
+      rw_lock_x_unlock(hash_lock);
+      buf_page_mutex_exit(block);
 
-			/* Try again */
-			goto loop;
-		}
+      /* Try again */
+      goto loop;
+    }
 
-		/* Move the compressed page from bpage to block,
-		and uncompress it. */
+    /* Move the compressed page from bpage to block,
+    and uncompress it. */
 
-		/* Note: this is the uncompressed block and it is not
-		accessible by other threads yet because it is not in
-		any list or hash table */
-		buf_relocate(bpage, &block->page);
+    /* Note: this is the uncompressed block and it is not
+    accessible by other threads yet because it is not in
+    any list or hash table */
+    buf_relocate(bpage, &block->page);
 
-		buf_block_init_low(block);
+    buf_block_init_low(block);
 
-		/* Set after buf_relocate(). */
-		block->page.buf_fix_count = 1;
+    /* Set after buf_relocate(). */
+    block->page.buf_fix_count = 1;
 
-		block->lock_hash_val = lock_rec_hash(page_id.space(),
-						     page_id.page_no());
+    block->lock_hash_val = lock_rec_hash(page_id.space(),
+                 page_id.page_no());
 
-		UNIV_MEM_DESC(&block->page.zip.data,
-			      page_zip_get_size(&block->page.zip));
+    UNIV_MEM_DESC(&block->page.zip.data,
+            page_zip_get_size(&block->page.zip));
 
-		if (buf_page_get_state(&block->page) == BUF_BLOCK_ZIP_PAGE) {
+    if (buf_page_get_state(&block->page) == BUF_BLOCK_ZIP_PAGE) {
 #if defined UNIV_DEBUG || defined UNIV_BUF_DEBUG
-			UT_LIST_REMOVE(buf_pool->zip_clean, &block->page);
+      UT_LIST_REMOVE(buf_pool->zip_clean, &block->page);
 #endif /* UNIV_DEBUG || UNIV_BUF_DEBUG */
-			ut_ad(!block->page.in_flush_list);
-		} else {
-			/* Relocate buf_pool->flush_list. */
-			buf_flush_relocate_on_flush_list(bpage, &block->page);
-		}
+      ut_ad(!block->page.in_flush_list);
+    } else {
+      /* Relocate buf_pool->flush_list. */
+      buf_flush_relocate_on_flush_list(bpage, &block->page);
+    }
 
-		/* Buffer-fix, I/O-fix, and X-latch the block
-		for the duration of the decompression.
-		Also add the block to the unzip_LRU list. */
-		block->page.state = BUF_BLOCK_FILE_PAGE;
+    /* Buffer-fix, I/O-fix, and X-latch the block
+    for the duration of the decompression.
+    Also add the block to the unzip_LRU list. */
+    block->page.state = BUF_BLOCK_FILE_PAGE;
 
-		/* Insert at the front of unzip_LRU list */
-		buf_unzip_LRU_add_block(block, FALSE);
+    /* Insert at the front of unzip_LRU list */
+    buf_unzip_LRU_add_block(block, FALSE);
 
-		buf_block_set_io_fix(block, BUF_IO_READ);
-		rw_lock_x_lock_inline(&block->lock, 0, file, line);
+    buf_block_set_io_fix(block, BUF_IO_READ);
+    rw_lock_x_lock_inline(&block->lock, 0, file, line);
 
-		UNIV_MEM_INVALID(bpage, sizeof *bpage);
+    UNIV_MEM_INVALID(bpage, sizeof *bpage);
 
-		rw_lock_x_unlock(hash_lock);
-		buf_pool->n_pend_unzip++;
-		mutex_exit(&buf_pool->zip_mutex);
-		buf_pool_mutex_exit(buf_pool);
+    rw_lock_x_unlock(hash_lock);
+    buf_pool->n_pend_unzip++;
+    mutex_exit(&buf_pool->zip_mutex);
+    buf_pool_mutex_exit(buf_pool);
 
-		access_time = buf_page_is_accessed(&block->page);
+    access_time = buf_page_is_accessed(&block->page);
 
-		buf_page_mutex_exit(block);
+    buf_page_mutex_exit(block);
 
-		if (!access_time && !recv_no_ibuf_operations
-		    && ibuf_page_exists(block->page)) {
-			block->page.ibuf_exist = true;
-		}
+    if (!access_time && !recv_no_ibuf_operations
+        && ibuf_page_exists(block->page)) {
+      block->page.ibuf_exist = true;
+    }
 
-		buf_page_free_descriptor(bpage);
+    buf_page_free_descriptor(bpage);
 
-		/* Decompress the page while not holding
-		buf_pool->mutex or block->mutex. */
+    /* Decompress the page while not holding
+    buf_pool->mutex or block->mutex. */
 
-		if (!buf_zip_decompress(block, TRUE)) {
-			buf_pool_mutex_enter(buf_pool);
-			buf_page_mutex_enter(fix_block);
-			buf_block_set_io_fix(fix_block, BUF_IO_NONE);
-			buf_page_mutex_exit(fix_block);
+    if (!buf_zip_decompress(block, TRUE)) {
+      buf_pool_mutex_enter(buf_pool);
+      buf_page_mutex_enter(fix_block);
+      buf_block_set_io_fix(fix_block, BUF_IO_NONE);
+      buf_page_mutex_exit(fix_block);
 
-			--buf_pool->n_pend_unzip;
-			fix_block->unfix();
-			buf_pool_mutex_exit(buf_pool);
-			rw_lock_x_unlock(&fix_block->lock);
+      --buf_pool->n_pend_unzip;
+      fix_block->unfix();
+      buf_pool_mutex_exit(buf_pool);
+      rw_lock_x_unlock(&fix_block->lock);
 
-			if (err) {
-				*err = DB_PAGE_CORRUPTED;
-			}
-			return NULL;
-		}
+      if (err) {
+        *err = DB_PAGE_CORRUPTED;
+      }
+      return NULL;
+    }
 
-		buf_pool_mutex_enter(buf_pool);
+    buf_pool_mutex_enter(buf_pool);
 
-		buf_page_mutex_enter(fix_block);
+    buf_page_mutex_enter(fix_block);
 
-		buf_block_set_io_fix(fix_block, BUF_IO_NONE);
+    buf_block_set_io_fix(fix_block, BUF_IO_NONE);
 
-		buf_page_mutex_exit(fix_block);
+    buf_page_mutex_exit(fix_block);
 
-		--buf_pool->n_pend_unzip;
+    --buf_pool->n_pend_unzip;
 
-		buf_pool_mutex_exit(buf_pool);
+    buf_pool_mutex_exit(buf_pool);
 
-		rw_lock_x_unlock(&block->lock);
+    rw_lock_x_unlock(&block->lock);
 
-		break;
-	}
+    break;
+  }
 
-	ut_ad(block == fix_block);
-	ut_ad(fix_block->page.buf_fix_count > 0);
+  ut_ad(block == fix_block);
+  ut_ad(fix_block->page.buf_fix_count > 0);
 
-	ut_ad(!rw_lock_own_flagged(hash_lock,
-				   RW_LOCK_FLAG_X | RW_LOCK_FLAG_S));
+  ut_ad(!rw_lock_own_flagged(hash_lock,
+           RW_LOCK_FLAG_X | RW_LOCK_FLAG_S));
 
-	ut_ad(buf_block_get_state(fix_block) == BUF_BLOCK_FILE_PAGE);
+  ut_ad(buf_block_get_state(fix_block) == BUF_BLOCK_FILE_PAGE);
 
 #if defined UNIV_DEBUG || defined UNIV_IBUF_DEBUG
 
-	if ((mode == BUF_GET_IF_IN_POOL || mode == BUF_GET_IF_IN_POOL_OR_WATCH)
-	    && (ibuf_debug || buf_debug_execute_is_force_flush())) {
+  if ((mode == BUF_GET_IF_IN_POOL || mode == BUF_GET_IF_IN_POOL_OR_WATCH)
+      && (ibuf_debug || buf_debug_execute_is_force_flush())) {
 
-		/* Try to evict the block from the buffer pool, to use the
-		insert buffer (change buffer) as much as possible. */
+    /* Try to evict the block from the buffer pool, to use the
+    insert buffer (change buffer) as much as possible. */
 
-		buf_pool_mutex_enter(buf_pool);
+    buf_pool_mutex_enter(buf_pool);
 
-		fix_block->unfix();
+    fix_block->unfix();
 
-		/* Now we are only holding the buf_pool->mutex,
-		not block->mutex or hash_lock. Blocks cannot be
-		relocated or enter or exit the buf_pool while we
-		are holding the buf_pool->mutex. */
+    /* Now we are only holding the buf_pool->mutex,
+    not block->mutex or hash_lock. Blocks cannot be
+    relocated or enter or exit the buf_pool while we
+    are holding the buf_pool->mutex. */
 
-		if (buf_LRU_free_page(&fix_block->page, true)) {
+    if (buf_LRU_free_page(&fix_block->page, true)) {
 
-			buf_pool_mutex_exit(buf_pool);
+      buf_pool_mutex_exit(buf_pool);
 
-			/* If not own buf_pool_mutex,
-			page_hash can be changed. */
-			hash_lock = buf_page_hash_lock_get(buf_pool, page_id);
+      /* If not own buf_pool_mutex,
+      page_hash can be changed. */
+      hash_lock = buf_page_hash_lock_get(buf_pool, page_id);
 
-			rw_lock_x_lock(hash_lock);
+      rw_lock_x_lock(hash_lock);
 
-			/* If not own buf_pool_mutex,
-			page_hash can be changed. */
-			hash_lock = buf_page_hash_lock_x_confirm(
-				hash_lock, buf_pool, page_id);
+      /* If not own buf_pool_mutex,
+      page_hash can be changed. */
+      hash_lock = buf_page_hash_lock_x_confirm(
+        hash_lock, buf_pool, page_id);
 
-			if (mode == BUF_GET_IF_IN_POOL_OR_WATCH) {
-				/* Set the watch, as it would have
-				been set if the page were not in the
-				buffer pool in the first place. */
-				block = (buf_block_t*) buf_pool_watch_set(
-					page_id, &hash_lock);
-			} else {
-				block = (buf_block_t*) buf_page_hash_get_low(
-					buf_pool, page_id);
-			}
+      if (mode == BUF_GET_IF_IN_POOL_OR_WATCH) {
+        /* Set the watch, as it would have
+        been set if the page were not in the
+        buffer pool in the first place. */
+        block = (buf_block_t*) buf_pool_watch_set(
+          page_id, &hash_lock);
+      } else {
+        block = (buf_block_t*) buf_page_hash_get_low(
+          buf_pool, page_id);
+      }
 
-			rw_lock_x_unlock(hash_lock);
+      rw_lock_x_unlock(hash_lock);
 
-			if (block != NULL) {
-				/* Either the page has been read in or
-				a watch was set on that in the window
-				where we released the buf_pool::mutex
-				and before we acquire the hash_lock
-				above. Try again. */
-				guess = block;
+      if (block != NULL) {
+        /* Either the page has been read in or
+        a watch was set on that in the window
+        where we released the buf_pool::mutex
+        and before we acquire the hash_lock
+        above. Try again. */
+        guess = block;
 
-				goto loop;
-			}
+        goto loop;
+      }
 
-			return(NULL);
-		}
+      return(NULL);
+    }
 
-		buf_page_mutex_enter(fix_block);
+    buf_page_mutex_enter(fix_block);
 
-		if (buf_flush_page_try(buf_pool, fix_block)) {
-			guess = fix_block;
+    if (buf_flush_page_try(buf_pool, fix_block)) {
+      guess = fix_block;
 
-			goto loop;
-		}
+      goto loop;
+    }
 
-		buf_page_mutex_exit(fix_block);
+    buf_page_mutex_exit(fix_block);
 
-		fix_block->fix();
+    fix_block->fix();
 
-		/* Failed to evict the page; change it directly */
+    /* Failed to evict the page; change it directly */
 
-		buf_pool_mutex_exit(buf_pool);
-	}
+    buf_pool_mutex_exit(buf_pool);
+  }
 #endif /* UNIV_DEBUG || UNIV_IBUF_DEBUG */
 
-	ut_ad(fix_block->page.buf_fix_count > 0);
+  ut_ad(fix_block->page.buf_fix_count > 0);
 
 #ifdef UNIV_DEBUG
-	/* We have already buffer fixed the page, and we are committed to
-	returning this page to the caller. Register for debugging.
-	Avoid debug latching if page/block belongs to system temporary
-	tablespace (Not much needed for table with single threaded access.). */
-	if (!fsp_is_system_temporary(page_id.space())) {
-		ibool   ret;
-		ret = rw_lock_s_lock_nowait(
-			fix_block->debug_latch, file, line);
-		ut_a(ret);
-	}
+  /* We have already buffer fixed the page, and we are committed to
+  returning this page to the caller. Register for debugging.
+  Avoid debug latching if page/block belongs to system temporary
+  tablespace (Not much needed for table with single threaded access.). */
+  if (!fsp_is_system_temporary(page_id.space())) {
+    ibool   ret;
+    ret = rw_lock_s_lock_nowait(
+      fix_block->debug_latch, file, line);
+    ut_a(ret);
+  }
 #endif /* UNIV_DEBUG */
 
-	/* While tablespace is reinited the indexes are already freed but the
-	blocks related to it still resides in buffer pool. Trying to remove
-	such blocks from buffer pool would invoke removal of AHI entries
-	associated with these blocks. Logic to remove AHI entry will try to
-	load the block but block is already in free state. Handle the said case
-	with mode = BUF_PEEK_IF_IN_POOL that is invoked from
-	"btr_search_drop_page_hash_when_freed". */
-	ut_ad(mode == BUF_GET_POSSIBLY_FREED
-	      || mode == BUF_PEEK_IF_IN_POOL
-	      || !fix_block->page.file_page_was_freed);
+  /* While tablespace is reinited the indexes are already freed but the
+  blocks related to it still resides in buffer pool. Trying to remove
+  such blocks from buffer pool would invoke removal of AHI entries
+  associated with these blocks. Logic to remove AHI entry will try to
+  load the block but block is already in free state. Handle the said case
+  with mode = BUF_PEEK_IF_IN_POOL that is invoked from
+  "btr_search_drop_page_hash_when_freed". */
+  ut_ad(mode == BUF_GET_POSSIBLY_FREED
+        || mode == BUF_PEEK_IF_IN_POOL
+        || !fix_block->page.file_page_was_freed);
 
-	/* Check if this is the first access to the page */
-	access_time = buf_page_is_accessed(&fix_block->page);
+  /* Check if this is the first access to the page */
+  access_time = buf_page_is_accessed(&fix_block->page);
 
-	/* This is a heuristic and we don't care about ordering issues. */
-	if (access_time == 0) {
-		buf_page_mutex_enter(fix_block);
+  /* This is a heuristic and we don't care about ordering issues. */
+  if (access_time == 0) {
+    buf_page_mutex_enter(fix_block);
 
-		buf_page_set_accessed(&fix_block->page);
+    buf_page_set_accessed(&fix_block->page);
 
-		buf_page_mutex_exit(fix_block);
-	}
+    buf_page_mutex_exit(fix_block);
+  }
 
-	if (mode != BUF_PEEK_IF_IN_POOL) {
-		buf_page_make_young_if_needed(buf_pool, &fix_block->page);
-	}
+  if (mode != BUF_PEEK_IF_IN_POOL) {
+    buf_page_make_young_if_needed(buf_pool, &fix_block->page);
+  }
 
 #if defined UNIV_DEBUG || defined UNIV_BUF_DEBUG
-	ut_a(++buf_dbg_counter % 5771 || buf_validate());
-	ut_a(buf_block_get_state(fix_block) == BUF_BLOCK_FILE_PAGE);
+  ut_a(++buf_dbg_counter % 5771 || buf_validate());
+  ut_a(buf_block_get_state(fix_block) == BUF_BLOCK_FILE_PAGE);
 #endif /* UNIV_DEBUG || UNIV_BUF_DEBUG */
 
-	/* We have to wait here because the IO_READ state was set
-	under the protection of the hash_lock and not the block->mutex
-	and block->lock. */
-	buf_wait_for_read(fix_block);
+  /* We have to wait here because the IO_READ state was set
+  under the protection of the hash_lock and not the block->mutex
+  and block->lock. */
+  buf_wait_for_read(fix_block);
 
-	if (fix_block->page.id != page_id) {
-		fix_block->unfix();
+  if (fix_block->page.id != page_id) {
+    fix_block->unfix();
 
 #ifdef UNIV_DEBUG
-		if (!fsp_is_system_temporary(page_id.space())) {
-			rw_lock_s_unlock(fix_block->debug_latch);
-		}
+    if (!fsp_is_system_temporary(page_id.space())) {
+      rw_lock_s_unlock(fix_block->debug_latch);
+    }
 #endif /* UNIV_DEBUG */
 
-		if (err) {
-			*err = DB_PAGE_CORRUPTED;
-		}
-
-		return NULL;
-	}
-
-	if (allow_ibuf_merge
-	    && mach_read_from_2(fix_block->frame + FIL_PAGE_TYPE)
-	    == FIL_PAGE_INDEX
-	    && page_is_leaf(fix_block->frame)) {
-		rw_lock_x_lock_inline(&fix_block->lock, 0, file, line);
-
-		if (fix_block->page.ibuf_exist) {
-			fix_block->page.ibuf_exist = false;
-			ibuf_merge_or_delete_for_page(fix_block, page_id,
-						      zip_size, true);
-		}
-
-		if (rw_latch == RW_X_LATCH) {
-			mtr->memo_push(fix_block, MTR_MEMO_PAGE_X_FIX);
-		} else {
-			rw_lock_x_unlock(&fix_block->lock);
-			goto get_latch;
-		}
-	} else {
+    if (err) {
+      *err = DB_PAGE_CORRUPTED;
+    }
+
+    return NULL;
+  }
+
+  if (allow_ibuf_merge
+      && mach_read_from_2(fix_block->frame + FIL_PAGE_TYPE)
+      == FIL_PAGE_INDEX
+      && page_is_leaf(fix_block->frame)) {
+    rw_lock_x_lock_inline(&fix_block->lock, 0, file, line);
+
+    if (fix_block->page.ibuf_exist) {
+      fix_block->page.ibuf_exist = false;
+      ibuf_merge_or_delete_for_page(fix_block, page_id,
+                  zip_size, true);
+    }
+
+    if (rw_latch == RW_X_LATCH) {
+      mtr->memo_push(fix_block, MTR_MEMO_PAGE_X_FIX);
+    } else {
+      rw_lock_x_unlock(&fix_block->lock);
+      goto get_latch;
+    }
+  } else {
 get_latch:
-		mtr_memo_type_t fix_type;
-
-		switch (rw_latch) {
-		case RW_NO_LATCH:
-			fix_type = MTR_MEMO_BUF_FIX;
-			break;
-		case RW_S_LATCH:
-			rw_lock_s_lock_inline(&fix_block->lock, 0, file, line);
-			fix_type = MTR_MEMO_PAGE_S_FIX;
-			break;
-		case RW_SX_LATCH:
-			rw_lock_sx_lock_inline(&fix_block->lock, 0, file, line);
-			fix_type = MTR_MEMO_PAGE_SX_FIX;
-			break;
-		default:
-			ut_ad(rw_latch == RW_X_LATCH);
-			rw_lock_x_lock_inline(&fix_block->lock, 0, file, line);
-			fix_type = MTR_MEMO_PAGE_X_FIX;
-			break;
-		}
-
-		mtr->memo_push(block, fix_type);
-	}
-
-	if (mode != BUF_PEEK_IF_IN_POOL && !access_time) {
-		/* In the case of a first access, try to apply linear
-		read-ahead */
-
-		buf_read_ahead_linear(page_id, zip_size, ibuf_inside(mtr));
-	}
-
-	ut_ad(!rw_lock_own_flagged(hash_lock,
-				   RW_LOCK_FLAG_X | RW_LOCK_FLAG_S));
-
-	return(fix_block);
+    mtr_memo_type_t fix_type;
+
+    switch (rw_latch) {
+    case RW_NO_LATCH:
+      fix_type = MTR_MEMO_BUF_FIX;
+      break;
+    case RW_S_LATCH:
+      rw_lock_s_lock_inline(&fix_block->lock, 0, file, line);
+      fix_type = MTR_MEMO_PAGE_S_FIX;
+      break;
+    case RW_SX_LATCH:
+      rw_lock_sx_lock_inline(&fix_block->lock, 0, file, line);
+      fix_type = MTR_MEMO_PAGE_SX_FIX;
+      break;
+    default:
+      ut_ad(rw_latch == RW_X_LATCH);
+      rw_lock_x_lock_inline(&fix_block->lock, 0, file, line);
+      fix_type = MTR_MEMO_PAGE_X_FIX;
+      break;
+    }
+
+    mtr->memo_push(block, fix_type);
+  }
+
+  if (mode != BUF_PEEK_IF_IN_POOL && !access_time) {
+    /* In the case of a first access, try to apply linear
+    read-ahead */
+
+    buf_read_ahead_linear(page_id, zip_size, ibuf_inside(mtr));
+  }
+
+  ut_ad(!rw_lock_own_flagged(hash_lock,
+           RW_LOCK_FLAG_X | RW_LOCK_FLAG_S));
+
+  return(fix_block);
 }
 
 /********************************************************************//**
@@ -4937,103 +5040,103 @@ page.
 ibool
 buf_page_optimistic_get(
 /*====================*/
-	ulint		rw_latch,/*!< in: RW_S_LATCH, RW_X_LATCH */
-	buf_block_t*	block,	/*!< in: guessed buffer block */
-	ib_uint64_t	modify_clock,/*!< in: modify clock value */
-	const char*	file,	/*!< in: file name */
-	unsigned	line,	/*!< in: line where called */
-	mtr_t*		mtr)	/*!< in: mini-transaction */
+  ulint		rw_latch,/*!< in: RW_S_LATCH, RW_X_LATCH */
+  buf_block_t*	block,	/*!< in: guessed buffer block */
+  ib_uint64_t	modify_clock,/*!< in: modify clock value */
+  const char*	file,	/*!< in: file name */
+  unsigned	line,	/*!< in: line where called */
+  mtr_t*		mtr)	/*!< in: mini-transaction */
 {
-	unsigned	access_time;
-	ibool		success;
+  unsigned	access_time;
+  ibool		success;
 
-	ut_ad(block);
-	ut_ad(mtr);
-	ut_ad(mtr->is_active());
-	ut_ad((rw_latch == RW_S_LATCH) || (rw_latch == RW_X_LATCH));
+  ut_ad(block);
+  ut_ad(mtr);
+  ut_ad(mtr->is_active());
+  ut_ad((rw_latch == RW_S_LATCH) || (rw_latch == RW_X_LATCH));
 
-	buf_page_mutex_enter(block);
+  buf_page_mutex_enter(block);
 
-	if (UNIV_UNLIKELY(buf_block_get_state(block) != BUF_BLOCK_FILE_PAGE)) {
+  if (UNIV_UNLIKELY(buf_block_get_state(block) != BUF_BLOCK_FILE_PAGE)) {
 
-		buf_page_mutex_exit(block);
+    buf_page_mutex_exit(block);
 
-		return(FALSE);
-	}
+    return(FALSE);
+  }
 
-	buf_block_buf_fix_inc(block, file, line);
+  buf_block_buf_fix_inc(block, file, line);
 
-	access_time = buf_page_is_accessed(&block->page);
+  access_time = buf_page_is_accessed(&block->page);
 
-	buf_page_set_accessed(&block->page);
+  buf_page_set_accessed(&block->page);
 
-	buf_page_mutex_exit(block);
+  buf_page_mutex_exit(block);
 
-	buf_pool_t* buf_pool = buf_pool_from_block(block);
-	buf_page_make_young_if_needed(buf_pool, &block->page);
+  buf_pool_t* buf_pool = buf_pool_from_block(block);
+  buf_page_make_young_if_needed(buf_pool, &block->page);
 
-	ut_ad(!ibuf_inside(mtr)
-	      || ibuf_page(block->page.id, block->zip_size(), NULL));
+  ut_ad(!ibuf_inside(mtr)
+        || ibuf_page(block->page.id, block->zip_size(), NULL));
 
-	mtr_memo_type_t	fix_type;
+  mtr_memo_type_t	fix_type;
 
-	switch (rw_latch) {
-	case RW_S_LATCH:
-		success = rw_lock_s_lock_nowait(&block->lock, file, line);
+  switch (rw_latch) {
+  case RW_S_LATCH:
+    success = rw_lock_s_lock_nowait(&block->lock, file, line);
 
-		fix_type = MTR_MEMO_PAGE_S_FIX;
-		break;
-	case RW_X_LATCH:
-		success = rw_lock_x_lock_func_nowait_inline(
-			&block->lock, file, line);
+    fix_type = MTR_MEMO_PAGE_S_FIX;
+    break;
+  case RW_X_LATCH:
+    success = rw_lock_x_lock_func_nowait_inline(
+      &block->lock, file, line);
 
-		fix_type = MTR_MEMO_PAGE_X_FIX;
-		break;
-	default:
-		ut_error; /* RW_SX_LATCH is not implemented yet */
-	}
+    fix_type = MTR_MEMO_PAGE_X_FIX;
+    break;
+  default:
+    ut_error; /* RW_SX_LATCH is not implemented yet */
+  }
 
-	if (!success) {
-		buf_block_buf_fix_dec(block);
-		return(FALSE);
-	}
+  if (!success) {
+    buf_block_buf_fix_dec(block);
+    return(FALSE);
+  }
 
-	if (modify_clock != block->modify_clock) {
+  if (modify_clock != block->modify_clock) {
 
-		buf_block_dbg_add_level(block, SYNC_NO_ORDER_CHECK);
+    buf_block_dbg_add_level(block, SYNC_NO_ORDER_CHECK);
 
-		if (rw_latch == RW_S_LATCH) {
-			rw_lock_s_unlock(&block->lock);
-		} else {
-			rw_lock_x_unlock(&block->lock);
-		}
+    if (rw_latch == RW_S_LATCH) {
+      rw_lock_s_unlock(&block->lock);
+    } else {
+      rw_lock_x_unlock(&block->lock);
+    }
 
-		buf_block_buf_fix_dec(block);
-		return(FALSE);
-	}
+    buf_block_buf_fix_dec(block);
+    return(FALSE);
+  }
 
-	mtr_memo_push(mtr, block, fix_type);
+  mtr_memo_push(mtr, block, fix_type);
 
 #if defined UNIV_DEBUG || defined UNIV_BUF_DEBUG
-	ut_a(++buf_dbg_counter % 5771 || buf_validate());
-	ut_a(block->page.buf_fix_count > 0);
-	ut_a(buf_block_get_state(block) == BUF_BLOCK_FILE_PAGE);
+  ut_a(++buf_dbg_counter % 5771 || buf_validate());
+  ut_a(block->page.buf_fix_count > 0);
+  ut_a(buf_block_get_state(block) == BUF_BLOCK_FILE_PAGE);
 #endif /* UNIV_DEBUG || UNIV_BUF_DEBUG */
 
-	ut_d(buf_page_mutex_enter(block));
-	ut_ad(!block->page.file_page_was_freed);
-	ut_d(buf_page_mutex_exit(block));
+  ut_d(buf_page_mutex_enter(block));
+  ut_ad(!block->page.file_page_was_freed);
+  ut_d(buf_page_mutex_exit(block));
 
-	if (!access_time) {
-		/* In the case of a first access, try to apply linear
-		read-ahead */
-		buf_read_ahead_linear(block->page.id, block->zip_size(),
-				      ibuf_inside(mtr));
-	}
+  if (!access_time) {
+    /* In the case of a first access, try to apply linear
+    read-ahead */
+    buf_read_ahead_linear(block->page.id, block->zip_size(),
+              ibuf_inside(mtr));
+  }
 
-	buf_pool->stat.n_page_gets++;
+  buf_pool->stat.n_page_gets++;
 
-	return(TRUE);
+  return(TRUE);
 }
 
 /** Given a tablespace id and page number tries to get that page. If the
@@ -5046,76 +5149,76 @@ Suitable for using when holding the lock_sys_t::mutex.
 @return pointer to a page or NULL */
 buf_block_t*
 buf_page_try_get_func(
-	const page_id_t		page_id,
-	const char*		file,
-	unsigned		line,
-	mtr_t*			mtr)
+  const page_id_t		page_id,
+  const char*		file,
+  unsigned		line,
+  mtr_t*			mtr)
 {
-	buf_block_t*	block;
-	ibool		success;
-	buf_pool_t*	buf_pool = buf_pool_get(page_id);
-	rw_lock_t*	hash_lock;
+  buf_block_t*	block;
+  ibool		success;
+  buf_pool_t*	buf_pool = buf_pool_get(page_id);
+  rw_lock_t*	hash_lock;
 
-	ut_ad(mtr);
-	ut_ad(mtr->is_active());
+  ut_ad(mtr);
+  ut_ad(mtr->is_active());
 
-	block = buf_block_hash_get_s_locked(buf_pool, page_id, &hash_lock);
+  block = buf_block_hash_get_s_locked(buf_pool, page_id, &hash_lock);
 
-	if (!block || buf_block_get_state(block) != BUF_BLOCK_FILE_PAGE) {
-		if (block) {
-			rw_lock_s_unlock(hash_lock);
-		}
-		return(NULL);
-	}
+  if (!block || buf_block_get_state(block) != BUF_BLOCK_FILE_PAGE) {
+    if (block) {
+      rw_lock_s_unlock(hash_lock);
+    }
+    return(NULL);
+  }
 
-	ut_ad(!buf_pool_watch_is_sentinel(buf_pool, &block->page));
+  ut_ad(!buf_pool_watch_is_sentinel(buf_pool, &block->page));
 
-	buf_page_mutex_enter(block);
-	rw_lock_s_unlock(hash_lock);
+  buf_page_mutex_enter(block);
+  rw_lock_s_unlock(hash_lock);
 
 #if defined UNIV_DEBUG || defined UNIV_BUF_DEBUG
-	ut_a(buf_block_get_state(block) == BUF_BLOCK_FILE_PAGE);
-	ut_a(page_id == block->page.id);
+  ut_a(buf_block_get_state(block) == BUF_BLOCK_FILE_PAGE);
+  ut_a(page_id == block->page.id);
 #endif /* UNIV_DEBUG || UNIV_BUF_DEBUG */
 
-	buf_block_buf_fix_inc(block, file, line);
-	buf_page_mutex_exit(block);
+  buf_block_buf_fix_inc(block, file, line);
+  buf_page_mutex_exit(block);
 
-	mtr_memo_type_t	fix_type = MTR_MEMO_PAGE_S_FIX;
-	success = rw_lock_s_lock_nowait(&block->lock, file, line);
+  mtr_memo_type_t	fix_type = MTR_MEMO_PAGE_S_FIX;
+  success = rw_lock_s_lock_nowait(&block->lock, file, line);
 
-	if (!success) {
-		/* Let us try to get an X-latch. If the current thread
-		is holding an X-latch on the page, we cannot get an
-		S-latch. */
+  if (!success) {
+    /* Let us try to get an X-latch. If the current thread
+    is holding an X-latch on the page, we cannot get an
+    S-latch. */
 
-		fix_type = MTR_MEMO_PAGE_X_FIX;
-		success = rw_lock_x_lock_func_nowait_inline(&block->lock,
-							    file, line);
-	}
+    fix_type = MTR_MEMO_PAGE_X_FIX;
+    success = rw_lock_x_lock_func_nowait_inline(&block->lock,
+                  file, line);
+  }
 
-	if (!success) {
-		buf_block_buf_fix_dec(block);
-		return(NULL);
-	}
+  if (!success) {
+    buf_block_buf_fix_dec(block);
+    return(NULL);
+  }
 
-	mtr_memo_push(mtr, block, fix_type);
+  mtr_memo_push(mtr, block, fix_type);
 
 #if defined UNIV_DEBUG || defined UNIV_BUF_DEBUG
-	ut_a(++buf_dbg_counter % 5771 || buf_validate());
-	ut_a(block->page.buf_fix_count > 0);
-	ut_a(buf_block_get_state(block) == BUF_BLOCK_FILE_PAGE);
+  ut_a(++buf_dbg_counter % 5771 || buf_validate());
+  ut_a(block->page.buf_fix_count > 0);
+  ut_a(buf_block_get_state(block) == BUF_BLOCK_FILE_PAGE);
 #endif /* UNIV_DEBUG || UNIV_BUF_DEBUG */
 
-	ut_d(buf_page_mutex_enter(block));
-	ut_d(ut_a(!block->page.file_page_was_freed));
-	ut_d(buf_page_mutex_exit(block));
+  ut_d(buf_page_mutex_enter(block));
+  ut_d(ut_a(!block->page.file_page_was_freed));
+  ut_d(buf_page_mutex_exit(block));
 
-	buf_block_dbg_add_level(block, SYNC_NO_ORDER_CHECK);
+  buf_block_dbg_add_level(block, SYNC_NO_ORDER_CHECK);
 
-	buf_pool->stat.n_page_gets++;
+  buf_pool->stat.n_page_gets++;
 
-	return(block);
+  return(block);
 }
 
 /********************************************************************//**
@@ -5124,24 +5227,24 @@ UNIV_INLINE
 void
 buf_page_init_low(
 /*==============*/
-	buf_page_t*	bpage)	/*!< in: block to init */
+  buf_page_t*	bpage)	/*!< in: block to init */
 {
-	bpage->flush_type = BUF_FLUSH_LRU;
-	bpage->io_fix = BUF_IO_NONE;
-	bpage->buf_fix_count = 0;
-	bpage->old = 0;
-	bpage->freed_page_clock = 0;
-	bpage->access_time = 0;
-	bpage->newest_modification = 0;
-	bpage->oldest_modification = 0;
-	bpage->write_size = 0;
-	bpage->real_size = 0;
-	bpage->slot = NULL;
-	bpage->ibuf_exist = false;
-
-	HASH_INVALIDATE(bpage, hash);
-
-	ut_d(bpage->file_page_was_freed = FALSE);
+  bpage->flush_type = BUF_FLUSH_LRU;
+  bpage->io_fix = BUF_IO_NONE;
+  bpage->buf_fix_count = 0;
+  bpage->old = 0;
+  bpage->freed_page_clock = 0;
+  bpage->access_time = 0;
+  bpage->newest_modification = 0;
+  bpage->oldest_modification = 0;
+  bpage->write_size = 0;
+  bpage->real_size = 0;
+  bpage->slot = NULL;
+  bpage->ibuf_exist = false;
+
+  HASH_INVALIDATE(bpage, hash);
+
+  ut_d(bpage->file_page_was_freed = FALSE);
 }
 
 /** Inits a page to the buffer buf_pool.
@@ -5152,81 +5255,81 @@ buf_page_init_low(
 static
 void
 buf_page_init(
-	buf_pool_t*		buf_pool,
-	const page_id_t		page_id,
-	ulint			zip_size,
-	buf_block_t*		block)
+  buf_pool_t*		buf_pool,
+  const page_id_t		page_id,
+  ulint			zip_size,
+  buf_block_t*		block)
 {
-	buf_page_t*	hash_page;
+  buf_page_t*	hash_page;
 
-	ut_ad(buf_pool == buf_pool_get(page_id));
-	ut_ad(buf_pool_mutex_own(buf_pool));
+  ut_ad(buf_pool == buf_pool_get(page_id));
+  ut_ad(buf_pool_mutex_own(buf_pool));
 
-	ut_ad(buf_page_mutex_own(block));
-	ut_a(buf_block_get_state(block) != BUF_BLOCK_FILE_PAGE);
+  ut_ad(buf_page_mutex_own(block));
+  ut_a(buf_block_get_state(block) != BUF_BLOCK_FILE_PAGE);
 
-	ut_ad(rw_lock_own(buf_page_hash_lock_get(buf_pool, page_id),
-			  RW_LOCK_X));
+  ut_ad(rw_lock_own(buf_page_hash_lock_get(buf_pool, page_id),
+        RW_LOCK_X));
 
-	/* Set the state of the block */
-	buf_block_set_file_page(block, page_id);
+  /* Set the state of the block */
+  buf_block_set_file_page(block, page_id);
 
 #ifdef UNIV_DEBUG_VALGRIND
-	if (is_system_tablespace(page_id.space())) {
-		/* Silence valid Valgrind warnings about uninitialized
-		data being written to data files.  There are some unused
-		bytes on some pages that InnoDB does not initialize. */
-		UNIV_MEM_VALID(block->frame, srv_page_size);
-	}
+  if (is_system_tablespace(page_id.space())) {
+    /* Silence valid Valgrind warnings about uninitialized
+    data being written to data files.  There are some unused
+    bytes on some pages that InnoDB does not initialize. */
+    UNIV_MEM_VALID(block->frame, srv_page_size);
+  }
 #endif /* UNIV_DEBUG_VALGRIND */
 
-	buf_block_init_low(block);
+  buf_block_init_low(block);
 
-	block->lock_hash_val = lock_rec_hash(page_id.space(),
-					     page_id.page_no());
+  block->lock_hash_val = lock_rec_hash(page_id.space(),
+               page_id.page_no());
 
-	buf_page_init_low(&block->page);
+  buf_page_init_low(&block->page);
 
-	/* Insert into the hash table of file pages */
+  /* Insert into the hash table of file pages */
 
-	hash_page = buf_page_hash_get_low(buf_pool, page_id);
+  hash_page = buf_page_hash_get_low(buf_pool, page_id);
 
-	if (hash_page == NULL) {
-		/* Block not found in hash table */
-	} else if (buf_pool_watch_is_sentinel(buf_pool, hash_page)) {
-		/* Preserve the reference count. */
-		ib_uint32_t	buf_fix_count = hash_page->buf_fix_count;
+  if (hash_page == NULL) {
+    /* Block not found in hash table */
+  } else if (buf_pool_watch_is_sentinel(buf_pool, hash_page)) {
+    /* Preserve the reference count. */
+    ib_uint32_t	buf_fix_count = hash_page->buf_fix_count;
 
-		ut_a(buf_fix_count > 0);
+    ut_a(buf_fix_count > 0);
 
-		block->page.buf_fix_count += buf_fix_count;
+    block->page.buf_fix_count += buf_fix_count;
 
-		buf_pool_watch_remove(buf_pool, hash_page);
-	} else {
+    buf_pool_watch_remove(buf_pool, hash_page);
+  } else {
 
-		ib::error() << "Page " << page_id
-			<< " already found in the hash table: "
-			<< hash_page << ", " << block;
+    ib::error() << "Page " << page_id
+      << " already found in the hash table: "
+      << hash_page << ", " << block;
 
-		ut_d(buf_page_mutex_exit(block));
-		ut_d(buf_pool_mutex_exit(buf_pool));
-		ut_d(buf_print());
-		ut_d(buf_LRU_print());
-		ut_d(buf_validate());
-		ut_d(buf_LRU_validate());
-		ut_error;
-	}
+    ut_d(buf_page_mutex_exit(block));
+    ut_d(buf_pool_mutex_exit(buf_pool));
+    ut_d(buf_print());
+    ut_d(buf_LRU_print());
+    ut_d(buf_validate());
+    ut_d(buf_LRU_validate());
+    ut_error;
+  }
 
-	ut_ad(!block->page.in_zip_hash);
-	ut_ad(!block->page.in_page_hash);
-	ut_d(block->page.in_page_hash = TRUE);
+  ut_ad(!block->page.in_zip_hash);
+  ut_ad(!block->page.in_page_hash);
+  ut_d(block->page.in_page_hash = TRUE);
 
-	block->page.id = page_id;
+  block->page.id = page_id;
 
-	HASH_INSERT(buf_page_t, hash, buf_pool->page_hash,
-		    page_id.fold(), &block->page);
+  HASH_INSERT(buf_page_t, hash, buf_pool->page_hash,
+        page_id.fold(), &block->page);
 
-	page_zip_set_size(&block->page.zip, zip_size);
+  page_zip_set_size(&block->page.zip, zip_size);
 }
 
 /** Initialize a page for read to the buffer buf_pool. If the page is
@@ -5242,236 +5345,236 @@ and the lock released later.
 @param[in]	page_id			page id
 @param[in]	zip_size		ROW_FORMAT=COMPRESSED page size, or 0
 @param[in]	unzip			whether the uncompressed page is
-					requested (for ROW_FORMAT=COMPRESSED)
+          requested (for ROW_FORMAT=COMPRESSED)
 @return pointer to the block
 @retval	NULL	in case of an error */
 buf_page_t*
 buf_page_init_for_read(
-	dberr_t*		err,
-	ulint			mode,
-	const page_id_t		page_id,
-	ulint			zip_size,
-	bool			unzip)
+  dberr_t*		err,
+  ulint			mode,
+  const page_id_t		page_id,
+  ulint			zip_size,
+  bool			unzip)
 {
-	buf_block_t*	block;
-	buf_page_t*	bpage	= NULL;
-	buf_page_t*	watch_page;
-	rw_lock_t*	hash_lock;
-	mtr_t		mtr;
-	bool		lru	= false;
-	void*		data;
-	buf_pool_t*	buf_pool = buf_pool_get(page_id);
-
-	ut_ad(buf_pool);
-
-	*err = DB_SUCCESS;
-
-	if (mode == BUF_READ_IBUF_PAGES_ONLY) {
-		/* It is a read-ahead within an ibuf routine */
-
-		ut_ad(!ibuf_bitmap_page(page_id, zip_size));
-
-		ibuf_mtr_start(&mtr);
-
-		if (!recv_no_ibuf_operations
-		    && !ibuf_page(page_id, zip_size, &mtr)) {
-
-			ibuf_mtr_commit(&mtr);
-
-			return(NULL);
-		}
-	} else {
-		ut_ad(mode == BUF_READ_ANY_PAGE);
-	}
-
-	if (zip_size && !unzip && !recv_recovery_is_on()) {
-		block = NULL;
-	} else {
-		block = buf_LRU_get_free_block(buf_pool);
-		ut_ad(block);
-		ut_ad(buf_pool_from_block(block) == buf_pool);
-	}
-
-	buf_pool_mutex_enter(buf_pool);
-
-	hash_lock = buf_page_hash_lock_get(buf_pool, page_id);
-	rw_lock_x_lock(hash_lock);
-
-	watch_page = buf_page_hash_get_low(buf_pool, page_id);
-	if (watch_page && !buf_pool_watch_is_sentinel(buf_pool, watch_page)) {
-		/* The page is already in the buffer pool. */
-		watch_page = NULL;
-		rw_lock_x_unlock(hash_lock);
-		if (block) {
-			buf_page_mutex_enter(block);
-			buf_LRU_block_free_non_file_page(block);
-			buf_page_mutex_exit(block);
-		}
-
-		bpage = NULL;
-		goto func_exit;
-	}
-
-	if (block) {
-		bpage = &block->page;
-
-		buf_page_mutex_enter(block);
-
-		ut_ad(buf_pool_from_bpage(bpage) == buf_pool);
-
-		buf_page_init(buf_pool, page_id, zip_size, block);
-
-		/* Note: We are using the hash_lock for protection. This is
-		safe because no other thread can lookup the block from the
-		page hashtable yet. */
-
-		buf_page_set_io_fix(bpage, BUF_IO_READ);
-
-		rw_lock_x_unlock(hash_lock);
-
-		/* The block must be put to the LRU list, to the old blocks */
-		buf_LRU_add_block(bpage, TRUE/* to old blocks */);
+  buf_block_t*	block;
+  buf_page_t*	bpage	= NULL;
+  buf_page_t*	watch_page;
+  rw_lock_t*	hash_lock;
+  mtr_t		mtr;
+  bool		lru	= false;
+  void*		data;
+  buf_pool_t*	buf_pool = buf_pool_get(page_id);
 
-		/* We set a pass-type x-lock on the frame because then
-		the same thread which called for the read operation
-		(and is running now at this point of code) can wait
-		for the read to complete by waiting for the x-lock on
-		the frame; if the x-lock were recursive, the same
-		thread would illegally get the x-lock before the page
-		read is completed.  The x-lock is cleared by the
-		io-handler thread. */
+  ut_ad(buf_pool);
 
-		rw_lock_x_lock_gen(&block->lock, BUF_IO_READ);
+  *err = DB_SUCCESS;
 
-		if (zip_size) {
-			/* buf_pool->mutex may be released and
-			reacquired by buf_buddy_alloc().  Thus, we
-			must release block->mutex in order not to
-			break the latching order in the reacquisition
-			of buf_pool->mutex.  We also must defer this
-			operation until after the block descriptor has
-			been added to buf_pool->LRU and
-			buf_pool->page_hash. */
-			buf_page_mutex_exit(block);
-			data = buf_buddy_alloc(buf_pool, zip_size, &lru);
-			buf_page_mutex_enter(block);
-			block->page.zip.data = (page_zip_t*) data;
+  if (mode == BUF_READ_IBUF_PAGES_ONLY) {
+    /* It is a read-ahead within an ibuf routine */
 
-			/* To maintain the invariant
-			block->in_unzip_LRU_list
-			== buf_page_belongs_to_unzip_LRU(&block->page)
-			we have to add this block to unzip_LRU
-			after block->page.zip.data is set. */
-			ut_ad(buf_page_belongs_to_unzip_LRU(&block->page));
-			buf_unzip_LRU_add_block(block, TRUE);
-		}
+    ut_ad(!ibuf_bitmap_page(page_id, zip_size));
 
-		buf_page_mutex_exit(block);
-	} else {
-		rw_lock_x_unlock(hash_lock);
+    ibuf_mtr_start(&mtr);
 
-		/* The compressed page must be allocated before the
-		control block (bpage), in order to avoid the
-		invocation of buf_buddy_relocate_block() on
-		uninitialized data. */
-		data = buf_buddy_alloc(buf_pool, zip_size, &lru);
+    if (!recv_no_ibuf_operations
+        && !ibuf_page(page_id, zip_size, &mtr)) {
 
-		rw_lock_x_lock(hash_lock);
+      ibuf_mtr_commit(&mtr);
 
-		/* If buf_buddy_alloc() allocated storage from the LRU list,
-		it released and reacquired buf_pool->mutex.  Thus, we must
-		check the page_hash again, as it may have been modified. */
-		if (UNIV_UNLIKELY(lru)) {
+      return(NULL);
+    }
+  } else {
+    ut_ad(mode == BUF_READ_ANY_PAGE);
+  }
+
+  if (zip_size && !unzip && !recv_recovery_is_on()) {
+    block = NULL;
+  } else {
+    block = buf_LRU_get_free_block(buf_pool);
+    ut_ad(block);
+    ut_ad(buf_pool_from_block(block) == buf_pool);
+  }
+
+  buf_pool_mutex_enter(buf_pool);
+
+  hash_lock = buf_page_hash_lock_get(buf_pool, page_id);
+  rw_lock_x_lock(hash_lock);
+
+  watch_page = buf_page_hash_get_low(buf_pool, page_id);
+  if (watch_page && !buf_pool_watch_is_sentinel(buf_pool, watch_page)) {
+    /* The page is already in the buffer pool. */
+    watch_page = NULL;
+    rw_lock_x_unlock(hash_lock);
+    if (block) {
+      buf_page_mutex_enter(block);
+      buf_LRU_block_free_non_file_page(block);
+      buf_page_mutex_exit(block);
+    }
 
-			watch_page = buf_page_hash_get_low(buf_pool, page_id);
+    bpage = NULL;
+    goto func_exit;
+  }
+
+  if (block) {
+    bpage = &block->page;
+
+    buf_page_mutex_enter(block);
+
+    ut_ad(buf_pool_from_bpage(bpage) == buf_pool);
+
+    buf_page_init(buf_pool, page_id, zip_size, block);
+
+    /* Note: We are using the hash_lock for protection. This is
+    safe because no other thread can lookup the block from the
+    page hashtable yet. */
+
+    buf_page_set_io_fix(bpage, BUF_IO_READ);
+
+    rw_lock_x_unlock(hash_lock);
+
+    /* The block must be put to the LRU list, to the old blocks */
+    buf_LRU_add_block(bpage, TRUE/* to old blocks */);
+
+    /* We set a pass-type x-lock on the frame because then
+    the same thread which called for the read operation
+    (and is running now at this point of code) can wait
+    for the read to complete by waiting for the x-lock on
+    the frame; if the x-lock were recursive, the same
+    thread would illegally get the x-lock before the page
+    read is completed.  The x-lock is cleared by the
+    io-handler thread. */
+
+    rw_lock_x_lock_gen(&block->lock, BUF_IO_READ);
+
+    if (zip_size) {
+      /* buf_pool->mutex may be released and
+      reacquired by buf_buddy_alloc().  Thus, we
+      must release block->mutex in order not to
+      break the latching order in the reacquisition
+      of buf_pool->mutex.  We also must defer this
+      operation until after the block descriptor has
+      been added to buf_pool->LRU and
+      buf_pool->page_hash. */
+      buf_page_mutex_exit(block);
+      data = buf_buddy_alloc(buf_pool, zip_size, &lru);
+      buf_page_mutex_enter(block);
+      block->page.zip.data = (page_zip_t*) data;
+
+      /* To maintain the invariant
+      block->in_unzip_LRU_list
+      == buf_page_belongs_to_unzip_LRU(&block->page)
+      we have to add this block to unzip_LRU
+      after block->page.zip.data is set. */
+      ut_ad(buf_page_belongs_to_unzip_LRU(&block->page));
+      buf_unzip_LRU_add_block(block, TRUE);
+    }
 
-			if (UNIV_UNLIKELY(watch_page
-			    && !buf_pool_watch_is_sentinel(buf_pool,
-							   watch_page))) {
+    buf_page_mutex_exit(block);
+  } else {
+    rw_lock_x_unlock(hash_lock);
 
-				/* The block was added by some other thread. */
-				rw_lock_x_unlock(hash_lock);
-				watch_page = NULL;
-				buf_buddy_free(buf_pool, data, zip_size);
+    /* The compressed page must be allocated before the
+    control block (bpage), in order to avoid the
+    invocation of buf_buddy_relocate_block() on
+    uninitialized data. */
+    data = buf_buddy_alloc(buf_pool, zip_size, &lru);
 
-				bpage = NULL;
-				goto func_exit;
-			}
-		}
+    rw_lock_x_lock(hash_lock);
 
-		bpage = buf_page_alloc_descriptor();
+    /* If buf_buddy_alloc() allocated storage from the LRU list,
+    it released and reacquired buf_pool->mutex.  Thus, we must
+    check the page_hash again, as it may have been modified. */
+    if (UNIV_UNLIKELY(lru)) {
 
-		/* Initialize the buf_pool pointer. */
-		bpage->buf_pool_index = buf_pool_index(buf_pool);
+      watch_page = buf_page_hash_get_low(buf_pool, page_id);
 
-		page_zip_des_init(&bpage->zip);
-		page_zip_set_size(&bpage->zip, zip_size);
-		bpage->zip.data = (page_zip_t*) data;
+      if (UNIV_UNLIKELY(watch_page
+          && !buf_pool_watch_is_sentinel(buf_pool,
+                 watch_page))) {
 
-		mutex_enter(&buf_pool->zip_mutex);
-		UNIV_MEM_DESC(bpage->zip.data, zip_size);
+        /* The block was added by some other thread. */
+        rw_lock_x_unlock(hash_lock);
+        watch_page = NULL;
+        buf_buddy_free(buf_pool, data, zip_size);
 
-		buf_page_init_low(bpage);
+        bpage = NULL;
+        goto func_exit;
+      }
+    }
+
+    bpage = buf_page_alloc_descriptor();
+
+    /* Initialize the buf_pool pointer. */
+    bpage->buf_pool_index = buf_pool_index(buf_pool);
 
-		bpage->state = BUF_BLOCK_ZIP_PAGE;
-		bpage->id = page_id;
-		bpage->flush_observer = NULL;
-		bpage->init_on_flush = false;
+    page_zip_des_init(&bpage->zip);
+    page_zip_set_size(&bpage->zip, zip_size);
+    bpage->zip.data = (page_zip_t*) data;
 
-		ut_d(bpage->in_page_hash = FALSE);
-		ut_d(bpage->in_zip_hash = FALSE);
-		ut_d(bpage->in_flush_list = FALSE);
-		ut_d(bpage->in_free_list = FALSE);
-		ut_d(bpage->in_LRU_list = FALSE);
+    mutex_enter(&buf_pool->zip_mutex);
+    UNIV_MEM_DESC(bpage->zip.data, zip_size);
 
-		ut_d(bpage->in_page_hash = TRUE);
+    buf_page_init_low(bpage);
 
-		if (watch_page != NULL) {
+    bpage->state = BUF_BLOCK_ZIP_PAGE;
+    bpage->id = page_id;
+    bpage->flush_observer = NULL;
+    bpage->init_on_flush = false;
 
-			/* Preserve the reference count. */
-			ib_uint32_t	buf_fix_count;
+    ut_d(bpage->in_page_hash = FALSE);
+    ut_d(bpage->in_zip_hash = FALSE);
+    ut_d(bpage->in_flush_list = FALSE);
+    ut_d(bpage->in_free_list = FALSE);
+    ut_d(bpage->in_LRU_list = FALSE);
 
-			buf_fix_count = watch_page->buf_fix_count;
-
-			ut_a(buf_fix_count > 0);
+    ut_d(bpage->in_page_hash = TRUE);
 
-			bpage->buf_fix_count += buf_fix_count;
+    if (watch_page != NULL) {
 
-			ut_ad(buf_pool_watch_is_sentinel(buf_pool, watch_page));
-			buf_pool_watch_remove(buf_pool, watch_page);
-		}
+      /* Preserve the reference count. */
+      ib_uint32_t	buf_fix_count;
 
-		HASH_INSERT(buf_page_t, hash, buf_pool->page_hash,
-			    bpage->id.fold(), bpage);
+      buf_fix_count = watch_page->buf_fix_count;
 
-		rw_lock_x_unlock(hash_lock);
+      ut_a(buf_fix_count > 0);
 
-		/* The block must be put to the LRU list, to the old blocks.
-		The zip size is already set into the page zip */
-		buf_LRU_add_block(bpage, TRUE/* to old blocks */);
+      bpage->buf_fix_count += buf_fix_count;
+
+      ut_ad(buf_pool_watch_is_sentinel(buf_pool, watch_page));
+      buf_pool_watch_remove(buf_pool, watch_page);
+    }
+
+    HASH_INSERT(buf_page_t, hash, buf_pool->page_hash,
+          bpage->id.fold(), bpage);
+
+    rw_lock_x_unlock(hash_lock);
+
+    /* The block must be put to the LRU list, to the old blocks.
+    The zip size is already set into the page zip */
+    buf_LRU_add_block(bpage, TRUE/* to old blocks */);
 #if defined UNIV_DEBUG || defined UNIV_BUF_DEBUG
-		buf_LRU_insert_zip_clean(bpage);
+    buf_LRU_insert_zip_clean(bpage);
 #endif /* UNIV_DEBUG || UNIV_BUF_DEBUG */
 
-		buf_page_set_io_fix(bpage, BUF_IO_READ);
+    buf_page_set_io_fix(bpage, BUF_IO_READ);
 
-		mutex_exit(&buf_pool->zip_mutex);
-	}
+    mutex_exit(&buf_pool->zip_mutex);
+  }
 
-	buf_pool->n_pend_reads++;
+  buf_pool->n_pend_reads++;
 func_exit:
-	buf_pool_mutex_exit(buf_pool);
+  buf_pool_mutex_exit(buf_pool);
 
-	if (mode == BUF_READ_IBUF_PAGES_ONLY) {
+  if (mode == BUF_READ_IBUF_PAGES_ONLY) {
 
-		ibuf_mtr_commit(&mtr);
-	}
+    ibuf_mtr_commit(&mtr);
+  }
 
-	ut_ad(!rw_lock_own_flagged(hash_lock,
-				   RW_LOCK_FLAG_X | RW_LOCK_FLAG_S));
-	ut_ad(!bpage || buf_page_in_file(bpage));
+  ut_ad(!rw_lock_own_flagged(hash_lock,
+           RW_LOCK_FLAG_X | RW_LOCK_FLAG_S));
+  ut_ad(!bpage || buf_page_in_file(bpage));
 
-	return(bpage);
+  return(bpage);
 }
 
 /** Initialize a page in the buffer pool. The page is usually not read
@@ -5484,136 +5587,136 @@ FILE_PAGE (the other is buf_page_get_gen).
 @return pointer to the block, page bufferfixed */
 buf_block_t*
 buf_page_create(
-	const page_id_t		page_id,
-	ulint			zip_size,
-	mtr_t*			mtr)
+  const page_id_t		page_id,
+  ulint			zip_size,
+  mtr_t*			mtr)
 {
-	buf_frame_t*	frame;
-	buf_block_t*	block;
-	buf_block_t*	free_block	= NULL;
-	buf_pool_t*	buf_pool = buf_pool_get(page_id);
-	rw_lock_t*	hash_lock;
+  buf_frame_t*	frame;
+  buf_block_t*	block;
+  buf_block_t*	free_block	= NULL;
+  buf_pool_t*	buf_pool = buf_pool_get(page_id);
+  rw_lock_t*	hash_lock;
 
-	ut_ad(mtr->is_active());
-	ut_ad(page_id.space() != 0 || !zip_size);
+  ut_ad(mtr->is_active());
+  ut_ad(page_id.space() != 0 || !zip_size);
 
-	free_block = buf_LRU_get_free_block(buf_pool);
+  free_block = buf_LRU_get_free_block(buf_pool);
 
-	buf_pool_mutex_enter(buf_pool);
+  buf_pool_mutex_enter(buf_pool);
 
-	hash_lock = buf_page_hash_lock_get(buf_pool, page_id);
-	rw_lock_x_lock(hash_lock);
+  hash_lock = buf_page_hash_lock_get(buf_pool, page_id);
+  rw_lock_x_lock(hash_lock);
 
-	block = (buf_block_t*) buf_page_hash_get_low(buf_pool, page_id);
+  block = (buf_block_t*) buf_page_hash_get_low(buf_pool, page_id);
 
-	if (block
-	    && buf_page_in_file(&block->page)
-	    && !buf_pool_watch_is_sentinel(buf_pool, &block->page)) {
-		ut_d(block->page.file_page_was_freed = FALSE);
+  if (block
+      && buf_page_in_file(&block->page)
+      && !buf_pool_watch_is_sentinel(buf_pool, &block->page)) {
+    ut_d(block->page.file_page_was_freed = FALSE);
 
-		/* Page can be found in buf_pool */
-		buf_pool_mutex_exit(buf_pool);
-		rw_lock_x_unlock(hash_lock);
+    /* Page can be found in buf_pool */
+    buf_pool_mutex_exit(buf_pool);
+    rw_lock_x_unlock(hash_lock);
 
-		buf_block_free(free_block);
+    buf_block_free(free_block);
 
-		if (!recv_recovery_is_on()) {
-			return buf_page_get_with_no_latch(page_id, zip_size,
-							  mtr);
-		}
+    if (!recv_recovery_is_on()) {
+      return buf_page_get_with_no_latch(page_id, zip_size,
+                mtr);
+    }
 
-		mutex_exit(&recv_sys.mutex);
-		block = buf_page_get_with_no_latch(page_id, zip_size, mtr);
-		mutex_enter(&recv_sys.mutex);
-		return block;
-	}
+    mutex_exit(&recv_sys.mutex);
+    block = buf_page_get_with_no_latch(page_id, zip_size, mtr);
+    mutex_enter(&recv_sys.mutex);
+    return block;
+  }
 
-	/* If we get here, the page was not in buf_pool: init it there */
+  /* If we get here, the page was not in buf_pool: init it there */
 
-	DBUG_PRINT("ib_buf", ("create page %u:%u",
-			      page_id.space(), page_id.page_no()));
+  DBUG_PRINT("ib_buf", ("create page %u:%u",
+            page_id.space(), page_id.page_no()));
 
-	block = free_block;
+  block = free_block;
 
-	buf_page_mutex_enter(block);
+  buf_page_mutex_enter(block);
 
-	buf_page_init(buf_pool, page_id, zip_size, block);
+  buf_page_init(buf_pool, page_id, zip_size, block);
 
-	rw_lock_x_unlock(hash_lock);
+  rw_lock_x_unlock(hash_lock);
 
-	/* The block must be put to the LRU list */
-	buf_LRU_add_block(&block->page, FALSE);
+  /* The block must be put to the LRU list */
+  buf_LRU_add_block(&block->page, FALSE);
 
-	buf_block_buf_fix_inc(block, __FILE__, __LINE__);
-	buf_pool->stat.n_pages_created++;
+  buf_block_buf_fix_inc(block, __FILE__, __LINE__);
+  buf_pool->stat.n_pages_created++;
 
-	if (zip_size) {
-		void*	data;
-		bool	lru;
+  if (zip_size) {
+    void*	data;
+    bool	lru;
 
-		/* Prevent race conditions during buf_buddy_alloc(),
-		which may release and reacquire buf_pool->mutex,
-		by IO-fixing and X-latching the block. */
+    /* Prevent race conditions during buf_buddy_alloc(),
+    which may release and reacquire buf_pool->mutex,
+    by IO-fixing and X-latching the block. */
 
-		buf_page_set_io_fix(&block->page, BUF_IO_READ);
-		rw_lock_x_lock(&block->lock);
+    buf_page_set_io_fix(&block->page, BUF_IO_READ);
+    rw_lock_x_lock(&block->lock);
 
-		buf_page_mutex_exit(block);
-		/* buf_pool->mutex may be released and reacquired by
-		buf_buddy_alloc().  Thus, we must release block->mutex
-		in order not to break the latching order in
-		the reacquisition of buf_pool->mutex.  We also must
-		defer this operation until after the block descriptor
-		has been added to buf_pool->LRU and buf_pool->page_hash. */
-		data = buf_buddy_alloc(buf_pool, zip_size, &lru);
-		buf_page_mutex_enter(block);
-		block->page.zip.data = (page_zip_t*) data;
+    buf_page_mutex_exit(block);
+    /* buf_pool->mutex may be released and reacquired by
+    buf_buddy_alloc().  Thus, we must release block->mutex
+    in order not to break the latching order in
+    the reacquisition of buf_pool->mutex.  We also must
+    defer this operation until after the block descriptor
+    has been added to buf_pool->LRU and buf_pool->page_hash. */
+    data = buf_buddy_alloc(buf_pool, zip_size, &lru);
+    buf_page_mutex_enter(block);
+    block->page.zip.data = (page_zip_t*) data;
 
-		/* To maintain the invariant
-		block->in_unzip_LRU_list
-		== buf_page_belongs_to_unzip_LRU(&block->page)
-		we have to add this block to unzip_LRU after
-		block->page.zip.data is set. */
-		ut_ad(buf_page_belongs_to_unzip_LRU(&block->page));
-		buf_unzip_LRU_add_block(block, FALSE);
+    /* To maintain the invariant
+    block->in_unzip_LRU_list
+    == buf_page_belongs_to_unzip_LRU(&block->page)
+    we have to add this block to unzip_LRU after
+    block->page.zip.data is set. */
+    ut_ad(buf_page_belongs_to_unzip_LRU(&block->page));
+    buf_unzip_LRU_add_block(block, FALSE);
 
-		buf_page_set_io_fix(&block->page, BUF_IO_NONE);
-		rw_lock_x_unlock(&block->lock);
-	}
+    buf_page_set_io_fix(&block->page, BUF_IO_NONE);
+    rw_lock_x_unlock(&block->lock);
+  }
 
-	buf_pool_mutex_exit(buf_pool);
+  buf_pool_mutex_exit(buf_pool);
 
-	mtr_memo_push(mtr, block, MTR_MEMO_BUF_FIX);
+  mtr_memo_push(mtr, block, MTR_MEMO_BUF_FIX);
 
-	buf_page_set_accessed(&block->page);
+  buf_page_set_accessed(&block->page);
 
-	buf_page_mutex_exit(block);
+  buf_page_mutex_exit(block);
 
-	/* Delete possible entries for the page from the insert buffer:
-	such can exist if the page belonged to an index which was dropped */
-	if (!recv_recovery_is_on()) {
-		ibuf_merge_or_delete_for_page(NULL, page_id, zip_size, true);
-	}
+  /* Delete possible entries for the page from the insert buffer:
+  such can exist if the page belonged to an index which was dropped */
+  if (!recv_recovery_is_on()) {
+    ibuf_merge_or_delete_for_page(NULL, page_id, zip_size, true);
+  }
 
-	frame = block->frame;
+  frame = block->frame;
 
-	memset(frame + FIL_PAGE_PREV, 0xff, 4);
-	memset(frame + FIL_PAGE_NEXT, 0xff, 4);
-	mach_write_to_2(frame + FIL_PAGE_TYPE, FIL_PAGE_TYPE_ALLOCATED);
+  memset(frame + FIL_PAGE_PREV, 0xff, 4);
+  memset(frame + FIL_PAGE_NEXT, 0xff, 4);
+  mach_write_to_2(frame + FIL_PAGE_TYPE, FIL_PAGE_TYPE_ALLOCATED);
 
-	/* FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION is only used on the
-	following pages:
-	(1) The first page of the InnoDB system tablespace (page 0:0)
-	(2) FIL_RTREE_SPLIT_SEQ_NUM on R-tree pages
-	(3) key_version on encrypted pages (not page 0:0) */
+  /* FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION is only used on the
+  following pages:
+  (1) The first page of the InnoDB system tablespace (page 0:0)
+  (2) FIL_RTREE_SPLIT_SEQ_NUM on R-tree pages
+  (3) key_version on encrypted pages (not page 0:0) */
 
-	memset(frame + FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION, 0, 8);
-	memset(frame + FIL_PAGE_LSN, 0, 8);
+  memset(frame + FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION, 0, 8);
+  memset(frame + FIL_PAGE_LSN, 0, 8);
 
 #if defined UNIV_DEBUG || defined UNIV_BUF_DEBUG
-	ut_a(++buf_dbg_counter % 5771 || buf_validate());
+  ut_a(++buf_dbg_counter % 5771 || buf_validate());
 #endif /* UNIV_DEBUG || UNIV_BUF_DEBUG */
-	return(block);
+  return(block);
 }
 
 /********************************************************************//**
@@ -5624,104 +5727,104 @@ static
 void
 buf_page_monitor(
 /*=============*/
-	const buf_page_t*	bpage,	/*!< in: pointer to the block */
-	enum buf_io_fix		io_type)/*!< in: io_fix types */
+  const buf_page_t*	bpage,	/*!< in: pointer to the block */
+  enum buf_io_fix		io_type)/*!< in: io_fix types */
 {
-	const byte*	frame;
-	monitor_id_t	counter;
-
-	/* If the counter module is not turned on, just return */
-	if (!MONITOR_IS_ON(MONITOR_MODULE_BUF_PAGE)) {
-		return;
-	}
-
-	ut_a(io_type == BUF_IO_READ || io_type == BUF_IO_WRITE);
-
-	frame = bpage->zip.data
-		? bpage->zip.data
-		: ((buf_block_t*) bpage)->frame;
-
-	switch (fil_page_get_type(frame)) {
-		ulint	level;
-	case FIL_PAGE_TYPE_INSTANT:
-	case FIL_PAGE_INDEX:
-	case FIL_PAGE_RTREE:
-		level = btr_page_get_level(frame);
-
-		/* Check if it is an index page for insert buffer */
-		if (fil_page_get_type(frame) == FIL_PAGE_INDEX
-		    && btr_page_get_index_id(frame)
-		    == (index_id_t)(DICT_IBUF_ID_MIN + IBUF_SPACE_ID)) {
-			if (level == 0) {
-				counter = MONITOR_RW_COUNTER(
-					io_type, MONITOR_INDEX_IBUF_LEAF_PAGE);
-			} else {
-				counter = MONITOR_RW_COUNTER(
-					io_type,
-					MONITOR_INDEX_IBUF_NON_LEAF_PAGE);
-			}
-		} else {
-			if (level == 0) {
-				counter = MONITOR_RW_COUNTER(
-					io_type, MONITOR_INDEX_LEAF_PAGE);
-			} else {
-				counter = MONITOR_RW_COUNTER(
-					io_type, MONITOR_INDEX_NON_LEAF_PAGE);
-			}
-		}
-		break;
-
-	case FIL_PAGE_UNDO_LOG:
-		counter = MONITOR_RW_COUNTER(io_type, MONITOR_UNDO_LOG_PAGE);
-		break;
-
-	case FIL_PAGE_INODE:
-		counter = MONITOR_RW_COUNTER(io_type, MONITOR_INODE_PAGE);
-		break;
-
-	case FIL_PAGE_IBUF_FREE_LIST:
-		counter = MONITOR_RW_COUNTER(io_type,
-					     MONITOR_IBUF_FREELIST_PAGE);
-		break;
-
-	case FIL_PAGE_IBUF_BITMAP:
-		counter = MONITOR_RW_COUNTER(io_type,
-					     MONITOR_IBUF_BITMAP_PAGE);
-		break;
-
-	case FIL_PAGE_TYPE_SYS:
-		counter = MONITOR_RW_COUNTER(io_type, MONITOR_SYSTEM_PAGE);
-		break;
-
-	case FIL_PAGE_TYPE_TRX_SYS:
-		counter = MONITOR_RW_COUNTER(io_type, MONITOR_TRX_SYSTEM_PAGE);
-		break;
-
-	case FIL_PAGE_TYPE_FSP_HDR:
-		counter = MONITOR_RW_COUNTER(io_type, MONITOR_FSP_HDR_PAGE);
-		break;
-
-	case FIL_PAGE_TYPE_XDES:
-		counter = MONITOR_RW_COUNTER(io_type, MONITOR_XDES_PAGE);
-		break;
-
-	case FIL_PAGE_TYPE_BLOB:
-		counter = MONITOR_RW_COUNTER(io_type, MONITOR_BLOB_PAGE);
-		break;
-
-	case FIL_PAGE_TYPE_ZBLOB:
-		counter = MONITOR_RW_COUNTER(io_type, MONITOR_ZBLOB_PAGE);
-		break;
-
-	case FIL_PAGE_TYPE_ZBLOB2:
-		counter = MONITOR_RW_COUNTER(io_type, MONITOR_ZBLOB2_PAGE);
-		break;
-
-	default:
-		counter = MONITOR_RW_COUNTER(io_type, MONITOR_OTHER_PAGE);
-	}
-
-	MONITOR_INC_NOCHECK(counter);
+  const byte*	frame;
+  monitor_id_t	counter;
+
+  /* If the counter module is not turned on, just return */
+  if (!MONITOR_IS_ON(MONITOR_MODULE_BUF_PAGE)) {
+    return;
+  }
+
+  ut_a(io_type == BUF_IO_READ || io_type == BUF_IO_WRITE);
+
+  frame = bpage->zip.data
+    ? bpage->zip.data
+    : ((buf_block_t*) bpage)->frame;
+
+  switch (fil_page_get_type(frame)) {
+    ulint	level;
+  case FIL_PAGE_TYPE_INSTANT:
+  case FIL_PAGE_INDEX:
+  case FIL_PAGE_RTREE:
+    level = btr_page_get_level(frame);
+
+    /* Check if it is an index page for insert buffer */
+    if (fil_page_get_type(frame) == FIL_PAGE_INDEX
+        && btr_page_get_index_id(frame)
+        == (index_id_t)(DICT_IBUF_ID_MIN + IBUF_SPACE_ID)) {
+      if (level == 0) {
+        counter = MONITOR_RW_COUNTER(
+          io_type, MONITOR_INDEX_IBUF_LEAF_PAGE);
+      } else {
+        counter = MONITOR_RW_COUNTER(
+          io_type,
+          MONITOR_INDEX_IBUF_NON_LEAF_PAGE);
+      }
+    } else {
+      if (level == 0) {
+        counter = MONITOR_RW_COUNTER(
+          io_type, MONITOR_INDEX_LEAF_PAGE);
+      } else {
+        counter = MONITOR_RW_COUNTER(
+          io_type, MONITOR_INDEX_NON_LEAF_PAGE);
+      }
+    }
+    break;
+
+  case FIL_PAGE_UNDO_LOG:
+    counter = MONITOR_RW_COUNTER(io_type, MONITOR_UNDO_LOG_PAGE);
+    break;
+
+  case FIL_PAGE_INODE:
+    counter = MONITOR_RW_COUNTER(io_type, MONITOR_INODE_PAGE);
+    break;
+
+  case FIL_PAGE_IBUF_FREE_LIST:
+    counter = MONITOR_RW_COUNTER(io_type,
+               MONITOR_IBUF_FREELIST_PAGE);
+    break;
+
+  case FIL_PAGE_IBUF_BITMAP:
+    counter = MONITOR_RW_COUNTER(io_type,
+               MONITOR_IBUF_BITMAP_PAGE);
+    break;
+
+  case FIL_PAGE_TYPE_SYS:
+    counter = MONITOR_RW_COUNTER(io_type, MONITOR_SYSTEM_PAGE);
+    break;
+
+  case FIL_PAGE_TYPE_TRX_SYS:
+    counter = MONITOR_RW_COUNTER(io_type, MONITOR_TRX_SYSTEM_PAGE);
+    break;
+
+  case FIL_PAGE_TYPE_FSP_HDR:
+    counter = MONITOR_RW_COUNTER(io_type, MONITOR_FSP_HDR_PAGE);
+    break;
+
+  case FIL_PAGE_TYPE_XDES:
+    counter = MONITOR_RW_COUNTER(io_type, MONITOR_XDES_PAGE);
+    break;
+
+  case FIL_PAGE_TYPE_BLOB:
+    counter = MONITOR_RW_COUNTER(io_type, MONITOR_BLOB_PAGE);
+    break;
+
+  case FIL_PAGE_TYPE_ZBLOB:
+    counter = MONITOR_RW_COUNTER(io_type, MONITOR_ZBLOB_PAGE);
+    break;
+
+  case FIL_PAGE_TYPE_ZBLOB2:
+    counter = MONITOR_RW_COUNTER(io_type, MONITOR_ZBLOB2_PAGE);
+    break;
+
+  default:
+    counter = MONITOR_RW_COUNTER(io_type, MONITOR_OTHER_PAGE);
+  }
+
+  MONITOR_INC_NOCHECK(counter);
 }
 
 /** Mark a table corrupted.
@@ -5730,15 +5833,15 @@ buf_page_monitor(
 ATTRIBUTE_COLD
 static void buf_mark_space_corrupt(buf_page_t* bpage, const fil_space_t& space)
 {
-	/* If block is not encrypted find the table with specified
-	space id, and mark it corrupted. Encrypted tables
-	are marked unusable later e.g. in ::open(). */
-	if (!space.crypt_data
-	    || space.crypt_data->type == CRYPT_SCHEME_UNENCRYPTED) {
-		dict_set_corrupted_by_space(&space);
-	} else {
-		dict_set_encrypted_by_space(&space);
-	}
+  /* If block is not encrypted find the table with specified
+  space id, and mark it corrupted. Encrypted tables
+  are marked unusable later e.g. in ::open(). */
+  if (!space.crypt_data
+      || space.crypt_data->type == CRYPT_SCHEME_UNENCRYPTED) {
+    dict_set_corrupted_by_space(&space);
+  } else {
+    dict_set_encrypted_by_space(&space);
+  }
 }
 
 /** Mark a table corrupted.
@@ -5749,43 +5852,43 @@ static
 void
 buf_corrupt_page_release(buf_page_t* bpage, const fil_space_t* space)
 {
-	buf_pool_t*	buf_pool = buf_pool_from_bpage(bpage);
-	const ibool	uncompressed = (buf_page_get_state(bpage)
-					== BUF_BLOCK_FILE_PAGE);
-	page_id_t	old_page_id = bpage->id;
+  buf_pool_t*	buf_pool = buf_pool_from_bpage(bpage);
+  const ibool	uncompressed = (buf_page_get_state(bpage)
+          == BUF_BLOCK_FILE_PAGE);
+  page_id_t	old_page_id = bpage->id;
 
-	/* First unfix and release lock on the bpage */
-	buf_pool_mutex_enter(buf_pool);
-	mutex_enter(buf_page_get_mutex(bpage));
-	ut_ad(buf_page_get_io_fix(bpage) == BUF_IO_READ);
-	ut_ad(bpage->id.space() == space->id);
+  /* First unfix and release lock on the bpage */
+  buf_pool_mutex_enter(buf_pool);
+  mutex_enter(buf_page_get_mutex(bpage));
+  ut_ad(buf_page_get_io_fix(bpage) == BUF_IO_READ);
+  ut_ad(bpage->id.space() == space->id);
 
-	/* buf_fix_count can be greater than zero. Because other thread
-	can wait in buf_page_wait_read() for the page to be read. */
+  /* buf_fix_count can be greater than zero. Because other thread
+  can wait in buf_page_wait_read() for the page to be read. */
 
-	bpage->id.set_corrupt_id();
-	/* Set BUF_IO_NONE before we remove the block from LRU list */
-	buf_page_set_io_fix(bpage, BUF_IO_NONE);
+  bpage->id.set_corrupt_id();
+  /* Set BUF_IO_NONE before we remove the block from LRU list */
+  buf_page_set_io_fix(bpage, BUF_IO_NONE);
 
-	if (uncompressed) {
-		rw_lock_x_unlock_gen(
-			&((buf_block_t*) bpage)->lock,
-			BUF_IO_READ);
-	}
+  if (uncompressed) {
+    rw_lock_x_unlock_gen(
+      &((buf_block_t*) bpage)->lock,
+      BUF_IO_READ);
+  }
 
-	mutex_exit(buf_page_get_mutex(bpage));
+  mutex_exit(buf_page_get_mutex(bpage));
 
-	if (!srv_force_recovery) {
-		buf_mark_space_corrupt(bpage, *space);
-	}
+  if (!srv_force_recovery) {
+    buf_mark_space_corrupt(bpage, *space);
+  }
 
-	/* After this point bpage can't be referenced. */
-	buf_LRU_free_one_page(bpage, old_page_id);
+  /* After this point bpage can't be referenced. */
+  buf_LRU_free_one_page(bpage, old_page_id);
 
-	ut_ad(buf_pool->n_pend_reads > 0);
-	buf_pool->n_pend_reads--;
+  ut_ad(buf_pool->n_pend_reads > 0);
+  buf_pool->n_pend_reads--;
 
-	buf_pool_mutex_exit(buf_pool);
+  buf_pool_mutex_exit(buf_pool);
 }
 
 /** Check if the encrypted page is corrupted for the full crc32 format.
@@ -5794,21 +5897,21 @@ buf_corrupt_page_release(buf_page_t* bpage, const fil_space_t* space)
 @param[in]	is_compressed	compressed page
 @return true if page is corrupted or false if it isn't */
 static bool buf_page_full_crc32_is_corrupted(
-	ulint		space_id,
-	const byte*	dst_frame,
-	bool		is_compressed)
+  ulint		space_id,
+  const byte*	dst_frame,
+  bool		is_compressed)
 {
-	if (!is_compressed
-	    && memcmp(dst_frame + FIL_PAGE_LSN + 4,
-		      dst_frame + srv_page_size - FIL_PAGE_FCRC32_END_LSN, 4)) {
-		return true;
-	}
+  if (!is_compressed
+      && memcmp(dst_frame + FIL_PAGE_LSN + 4,
+          dst_frame + srv_page_size - FIL_PAGE_FCRC32_END_LSN, 4)) {
+    return true;
+  }
 
-	if (space_id != mach_read_from_4(dst_frame + FIL_PAGE_SPACE_ID)) {
-		return true;
-	}
+  if (space_id != mach_read_from_4(dst_frame + FIL_PAGE_SPACE_ID)) {
+    return true;
+  }
 
-	return false;
+  return false;
 }
 
 /** Check if page is maybe compressed, encrypted or both when we encounter
@@ -5824,63 +5927,63 @@ after decryption normal page checksum does not match.
 @retval	DB_TABLESPACE_DELETED	if accessed tablespace is not found */
 static dberr_t buf_page_check_corrupt(buf_page_t* bpage, fil_space_t* space)
 {
-	ut_ad(space->pending_io());
-
-	byte* dst_frame = (bpage->zip.data) ? bpage->zip.data :
-		((buf_block_t*) bpage)->frame;
-	dberr_t err = DB_SUCCESS;
-	uint key_version = buf_page_get_key_version(dst_frame, space->flags);
-
-	/* In buf_decrypt_after_read we have either decrypted the page if
-	page post encryption checksum matches and used key_id is found
-	from the encryption plugin. If checksum did not match page was
-	not decrypted and it could be either encrypted and corrupted
-	or corrupted or good page. If we decrypted, there page could
-	still be corrupted if used key does not match. */
-	const bool seems_encrypted = !space->full_crc32() && key_version
-		&& space->crypt_data
-		&& space->crypt_data->type != CRYPT_SCHEME_UNENCRYPTED;
-	ut_ad(space->purpose != FIL_TYPE_TEMPORARY || space->full_crc32());
-
-	/* If traditional checksums match, we assume that page is
-	not anymore encrypted. */
-	if (space->full_crc32()
-	    && !buf_page_is_zeroes(dst_frame, space->physical_size())
-	    && (key_version || space->is_compressed()
-		|| space->purpose == FIL_TYPE_TEMPORARY)) {
-		if (buf_page_full_crc32_is_corrupted(
-			    space->id, dst_frame, space->is_compressed())) {
-			err = DB_PAGE_CORRUPTED;
-		}
-	} else if (buf_page_is_corrupted(true, dst_frame, space->flags)) {
-		err = DB_PAGE_CORRUPTED;
-	}
-
-	if (seems_encrypted && err == DB_PAGE_CORRUPTED
-	    && bpage->id.page_no() != 0) {
-		err = DB_DECRYPTION_FAILED;
-
-		ib::error()
-			<< "The page " << bpage->id << " in file '"
-			<< space->chain.start->name
-			<< "' cannot be decrypted.";
-
-		ib::info()
-			<< "However key management plugin or used key_version "
-			<< key_version
-			<< " is not found or"
-			" used encryption algorithm or method does not match.";
-
-		if (bpage->id.space() != TRX_SYS_SPACE) {
-			ib::info()
-				<< "Marking tablespace as missing."
-				" You may drop this table or"
-				" install correct key management plugin"
-				" and key file.";
-		}
-	}
-
-	return (err);
+  ut_ad(space->pending_io());
+
+  byte* dst_frame = (bpage->zip.data) ? bpage->zip.data :
+    ((buf_block_t*) bpage)->frame;
+  dberr_t err = DB_SUCCESS;
+  uint key_version = buf_page_get_key_version(dst_frame, space->flags);
+
+  /* In buf_decrypt_after_read we have either decrypted the page if
+  page post encryption checksum matches and used key_id is found
+  from the encryption plugin. If checksum did not match page was
+  not decrypted and it could be either encrypted and corrupted
+  or corrupted or good page. If we decrypted, there page could
+  still be corrupted if used key does not match. */
+  const bool seems_encrypted = !space->full_crc32() && key_version
+    && space->crypt_data
+    && space->crypt_data->type != CRYPT_SCHEME_UNENCRYPTED;
+  ut_ad(space->purpose != FIL_TYPE_TEMPORARY || space->full_crc32());
+
+  /* If traditional checksums match, we assume that page is
+  not anymore encrypted. */
+  if (space->full_crc32()
+      && !buf_page_is_zeroes(dst_frame, space->physical_size())
+      && (key_version || space->is_compressed()
+    || space->purpose == FIL_TYPE_TEMPORARY)) {
+    if (buf_page_full_crc32_is_corrupted(
+          space->id, dst_frame, space->is_compressed())) {
+      err = DB_PAGE_CORRUPTED;
+    }
+  } else if (buf_page_is_corrupted(true, dst_frame, space->flags)) {
+    err = DB_PAGE_CORRUPTED;
+  }
+
+  if (seems_encrypted && err == DB_PAGE_CORRUPTED
+      && bpage->id.page_no() != 0) {
+    err = DB_DECRYPTION_FAILED;
+
+    ib::error()
+      << "The page " << bpage->id << " in file '"
+      << space->chain.start->name
+      << "' cannot be decrypted.";
+
+    ib::info()
+      << "However key management plugin or used key_version "
+      << key_version
+      << " is not found or"
+      " used encryption algorithm or method does not match.";
+
+    if (bpage->id.space() != TRX_SYS_SPACE) {
+      ib::info()
+        << "Marking tablespace as missing."
+        " You may drop this table or"
+        " install correct key management plugin"
+        " and key file.";
+    }
+  }
+
+  return (err);
 }
 
 /** Complete a read or write request of a file page to or from the buffer pool.
@@ -5892,274 +5995,274 @@ static dberr_t buf_page_check_corrupt(buf_page_t* bpage, fil_space_t* space)
 @retval	DB_TABLESPACE_DELETED	if the tablespace does not exist
 @retval	DB_PAGE_CORRUPTED	if the checksum fails on a page read
 @retval	DB_DECRYPTION_FAILED	if page post encryption checksum matches but
-				after decryption normal page checksum does
-				not match */
+        after decryption normal page checksum does
+        not match */
 UNIV_INTERN
 dberr_t
 buf_page_io_complete(buf_page_t* bpage, bool dblwr, bool evict)
 {
-	enum buf_io_fix	io_type;
-	buf_pool_t*	buf_pool = buf_pool_from_bpage(bpage);
-	const bool	uncompressed = (buf_page_get_state(bpage)
-					== BUF_BLOCK_FILE_PAGE);
-	ut_a(buf_page_in_file(bpage));
-
-	/* We do not need protect io_fix here by mutex to read
-	it because this is the only function where we can change the value
-	from BUF_IO_READ or BUF_IO_WRITE to some other value, and our code
-	ensures that this is the only thread that handles the i/o for this
-	block. */
-
-	io_type = buf_page_get_io_fix(bpage);
-	ut_ad(io_type == BUF_IO_READ || io_type == BUF_IO_WRITE);
-	ut_ad(!!bpage->zip.ssize == (bpage->zip.data != NULL));
-	ut_ad(uncompressed || bpage->zip.data);
-
-	if (io_type == BUF_IO_READ) {
-		ulint	read_page_no = 0;
-		ulint	read_space_id = 0;
-		byte*	frame = bpage->zip.data
-			? bpage->zip.data
-			: reinterpret_cast<buf_block_t*>(bpage)->frame;
-		ut_ad(frame);
-		fil_space_t* space = fil_space_acquire_for_io(
-			bpage->id.space());
-		if (!space) {
-			return DB_TABLESPACE_DELETED;
-		}
-
-		dberr_t	err;
-
-		if (!buf_page_decrypt_after_read(bpage, space)) {
-			err = DB_DECRYPTION_FAILED;
-			goto database_corrupted;
-		}
-
-		if (bpage->zip.data && uncompressed) {
-			buf_pool->n_pend_unzip++;
-			ibool ok = buf_zip_decompress((buf_block_t*) bpage,
-						      FALSE);
-			buf_pool->n_pend_unzip--;
-
-			if (!ok) {
-				ib::info() << "Page "
-					   << bpage->id
-					   << " zip_decompress failure.";
-
-				err = DB_PAGE_CORRUPTED;
-				goto database_corrupted;
-			}
-		}
-
-		/* If this page is not uninitialized and not in the
-		doublewrite buffer, then the page number and space id
-		should be the same as in block. */
-		read_page_no = mach_read_from_4(frame + FIL_PAGE_OFFSET);
-		read_space_id = mach_read_from_4(
-			frame + FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID);
-
-		if (bpage->id.space() == TRX_SYS_SPACE
-		    && buf_dblwr_page_inside(bpage->id.page_no())) {
-
-			ib::error() << "Reading page " << bpage->id
-				<< ", which is in the doublewrite buffer!";
-
-		} else if (read_space_id == 0 && read_page_no == 0) {
-			/* This is likely an uninitialized page. */
-		} else if (((!space->full_crc32()
-			     || bpage->id.space() != TRX_SYS_SPACE)
-			    && bpage->id.space() != read_space_id)
-			   || bpage->id.page_no() != read_page_no) {
-			/* We do not compare space_id to read_space_id
-			in the system tablespace unless space->full_crc32(),
-			because the field was written as garbage before
-			MySQL 4.1.1, which introduced support for
-			innodb_file_per_table. */
-
-			if (space->full_crc32()
-			    && *reinterpret_cast<uint32_t*>
-			    (&frame[FIL_PAGE_FCRC32_KEY_VERSION])
-			    && space->crypt_data
-			    && space->crypt_data->type
-			    != CRYPT_SCHEME_UNENCRYPTED) {
-				ib::error() << "Cannot decrypt " << bpage->id;
-				err = DB_DECRYPTION_FAILED;
-				goto release_page;
-			}
-
-			ib::error() << "Space id and page no stored in "
-				"the page, read in are "
-				<< page_id_t(read_space_id, read_page_no)
-				<< ", should be " << bpage->id;
-		}
-
-		err = buf_page_check_corrupt(bpage, space);
+  enum buf_io_fix	io_type;
+  buf_pool_t*	buf_pool = buf_pool_from_bpage(bpage);
+  const bool	uncompressed = (buf_page_get_state(bpage)
+          == BUF_BLOCK_FILE_PAGE);
+  ut_a(buf_page_in_file(bpage));
+
+  /* We do not need protect io_fix here by mutex to read
+  it because this is the only function where we can change the value
+  from BUF_IO_READ or BUF_IO_WRITE to some other value, and our code
+  ensures that this is the only thread that handles the i/o for this
+  block. */
+
+  io_type = buf_page_get_io_fix(bpage);
+  ut_ad(io_type == BUF_IO_READ || io_type == BUF_IO_WRITE);
+  ut_ad(!!bpage->zip.ssize == (bpage->zip.data != NULL));
+  ut_ad(uncompressed || bpage->zip.data);
+
+  if (io_type == BUF_IO_READ) {
+    ulint	read_page_no = 0;
+    ulint	read_space_id = 0;
+    byte*	frame = bpage->zip.data
+      ? bpage->zip.data
+      : reinterpret_cast<buf_block_t*>(bpage)->frame;
+    ut_ad(frame);
+    fil_space_t* space = fil_space_acquire_for_io(
+      bpage->id.space());
+    if (!space) {
+      return DB_TABLESPACE_DELETED;
+    }
+
+    dberr_t	err;
+
+    if (!buf_page_decrypt_after_read(bpage, space)) {
+      err = DB_DECRYPTION_FAILED;
+      goto database_corrupted;
+    }
+
+    if (bpage->zip.data && uncompressed) {
+      buf_pool->n_pend_unzip++;
+      ibool ok = buf_zip_decompress((buf_block_t*) bpage,
+                  FALSE);
+      buf_pool->n_pend_unzip--;
+
+      if (!ok) {
+        ib::info() << "Page "
+             << bpage->id
+             << " zip_decompress failure.";
+
+        err = DB_PAGE_CORRUPTED;
+        goto database_corrupted;
+      }
+    }
+
+    /* If this page is not uninitialized and not in the
+    doublewrite buffer, then the page number and space id
+    should be the same as in block. */
+    read_page_no = mach_read_from_4(frame + FIL_PAGE_OFFSET);
+    read_space_id = mach_read_from_4(
+      frame + FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID);
+
+    if (bpage->id.space() == TRX_SYS_SPACE
+        && buf_dblwr_page_inside(bpage->id.page_no())) {
+
+      ib::error() << "Reading page " << bpage->id
+        << ", which is in the doublewrite buffer!";
+
+    } else if (read_space_id == 0 && read_page_no == 0) {
+      /* This is likely an uninitialized page. */
+    } else if (((!space->full_crc32()
+           || bpage->id.space() != TRX_SYS_SPACE)
+          && bpage->id.space() != read_space_id)
+         || bpage->id.page_no() != read_page_no) {
+      /* We do not compare space_id to read_space_id
+      in the system tablespace unless space->full_crc32(),
+      because the field was written as garbage before
+      MySQL 4.1.1, which introduced support for
+      innodb_file_per_table. */
+
+      if (space->full_crc32()
+          && *reinterpret_cast<uint32_t*>
+          (&frame[FIL_PAGE_FCRC32_KEY_VERSION])
+          && space->crypt_data
+          && space->crypt_data->type
+          != CRYPT_SCHEME_UNENCRYPTED) {
+        ib::error() << "Cannot decrypt " << bpage->id;
+        err = DB_DECRYPTION_FAILED;
+        goto release_page;
+      }
+
+      ib::error() << "Space id and page no stored in "
+        "the page, read in are "
+        << page_id_t(read_space_id, read_page_no)
+        << ", should be " << bpage->id;
+    }
+
+    err = buf_page_check_corrupt(bpage, space);
 
 database_corrupted:
 
-		if (err != DB_SUCCESS) {
-			/* Not a real corruption if it was triggered by
-			error injection */
-			DBUG_EXECUTE_IF(
-				"buf_page_import_corrupt_failure",
-				if (!is_predefined_tablespace(
-					    bpage->id.space())) {
-					buf_corrupt_page_release(bpage, space);
-					ib::info() << "Simulated IMPORT "
-						"corruption";
-					space->release_for_io();
-					return(err);
-				}
-				err = DB_SUCCESS;
-				goto page_not_corrupt;
-			);
-
-			if (err == DB_PAGE_CORRUPTED) {
-				ib::error()
-					<< "Database page corruption on disk"
-					" or a failed file read of tablespace "
-					<< space->name << " page " << bpage->id
-					<< ". You may have to recover from "
-					<< "a backup.";
-
-				buf_page_print(frame, bpage->zip_size());
-
-				ib::info()
-					<< "It is also possible that your"
-					" operating system has corrupted"
-					" its own file cache and rebooting"
-					" your computer removes the error."
-					" If the corrupt page is an index page."
-					" You can also try to fix the"
-					" corruption by dumping, dropping,"
-					" and reimporting the corrupt table."
-					" You can use CHECK TABLE to scan"
-					" your table for corruption. "
-					<< FORCE_RECOVERY_MSG;
-			}
-
-			if (!srv_force_recovery) {
-
-				/* If page space id is larger than TRX_SYS_SPACE
-				(0), we will attempt to mark the corresponding
-				table as corrupted instead of crashing server */
-				if (bpage->id.space() == TRX_SYS_SPACE) {
-					ib::fatal() << "Aborting because of"
-						" a corrupt database page.";
-				}
-
-				buf_corrupt_page_release(bpage, space);
-				space->release_for_io();
-				return(err);
-			}
-		}
-
-		DBUG_EXECUTE_IF("buf_page_import_corrupt_failure",
-				page_not_corrupt: bpage = bpage; );
-
-		if (err == DB_PAGE_CORRUPTED
-		    || err == DB_DECRYPTION_FAILED) {
+    if (err != DB_SUCCESS) {
+      /* Not a real corruption if it was triggered by
+      error injection */
+      DBUG_EXECUTE_IF(
+        "buf_page_import_corrupt_failure",
+        if (!is_predefined_tablespace(
+              bpage->id.space())) {
+          buf_corrupt_page_release(bpage, space);
+          ib::info() << "Simulated IMPORT "
+            "corruption";
+          space->release_for_io();
+          return(err);
+        }
+        err = DB_SUCCESS;
+        goto page_not_corrupt;
+      );
+
+      if (err == DB_PAGE_CORRUPTED) {
+        ib::error()
+          << "Database page corruption on disk"
+          " or a failed file read of tablespace "
+          << space->name << " page " << bpage->id
+          << ". You may have to recover from "
+          << "a backup.";
+
+        buf_page_print(frame, bpage->zip_size());
+
+        ib::info()
+          << "It is also possible that your"
+          " operating system has corrupted"
+          " its own file cache and rebooting"
+          " your computer removes the error."
+          " If the corrupt page is an index page."
+          " You can also try to fix the"
+          " corruption by dumping, dropping,"
+          " and reimporting the corrupt table."
+          " You can use CHECK TABLE to scan"
+          " your table for corruption. "
+          << FORCE_RECOVERY_MSG;
+      }
+
+      if (!srv_force_recovery) {
+
+        /* If page space id is larger than TRX_SYS_SPACE
+        (0), we will attempt to mark the corresponding
+        table as corrupted instead of crashing server */
+        if (bpage->id.space() == TRX_SYS_SPACE) {
+          ib::fatal() << "Aborting because of"
+            " a corrupt database page.";
+        }
+
+        buf_corrupt_page_release(bpage, space);
+        space->release_for_io();
+        return(err);
+      }
+    }
+
+    DBUG_EXECUTE_IF("buf_page_import_corrupt_failure",
+        page_not_corrupt: bpage = bpage; );
+
+    if (err == DB_PAGE_CORRUPTED
+        || err == DB_DECRYPTION_FAILED) {
 release_page:
-			const page_id_t corrupt_page_id = bpage->id;
-
-			buf_corrupt_page_release(bpage, space);
-
-			if (recv_recovery_is_on()) {
-				recv_recover_corrupt_page(corrupt_page_id);
-			}
-
-			space->release_for_io();
-			return err;
-		}
-
-		if (recv_recovery_is_on()) {
-			recv_recover_page(bpage);
-		}
-
-		if (uncompressed
-		    && !recv_no_ibuf_operations
-		    && (bpage->id.space() == 0
-			|| !is_predefined_tablespace(bpage->id.space()))
-		    && fil_page_get_type(frame) == FIL_PAGE_INDEX
-		    && page_is_leaf(frame)
-		    && ibuf_page_exists(*bpage)) {
-			bpage->ibuf_exist = true;
-		}
-
-		space->release_for_io();
-	} else {
-		/* io_type == BUF_IO_WRITE */
-		if (bpage->slot) {
-			/* Mark slot free */
-			bpage->slot->release();
-			bpage->slot = NULL;
-		}
-	}
-
-	BPageMutex* block_mutex = buf_page_get_mutex(bpage);
-	buf_pool_mutex_enter(buf_pool);
-	mutex_enter(block_mutex);
-
-	/* Because this thread which does the unlocking is not the same that
-	did the locking, we use a pass value != 0 in unlock, which simply
-	removes the newest lock debug record, without checking the thread
-	id. */
-
-	buf_page_set_io_fix(bpage, BUF_IO_NONE);
-	buf_page_monitor(bpage, io_type);
-
-	if (io_type == BUF_IO_READ) {
-		/* NOTE that the call to ibuf may have moved the ownership of
-		the x-latch to this OS thread: do not let this confuse you in
-		debugging! */
-
-		ut_ad(buf_pool->n_pend_reads > 0);
-		buf_pool->n_pend_reads--;
-		buf_pool->stat.n_pages_read++;
-
-		if (uncompressed) {
-			rw_lock_x_unlock_gen(&((buf_block_t*) bpage)->lock,
-					     BUF_IO_READ);
-		}
-
-		mutex_exit(block_mutex);
-	} else {
-		/* Write means a flush operation: call the completion
-		routine in the flush system */
-
-		buf_flush_write_complete(bpage, dblwr);
-
-		if (uncompressed) {
-			rw_lock_sx_unlock_gen(&((buf_block_t*) bpage)->lock,
-					      BUF_IO_WRITE);
-		}
-
-		buf_pool->stat.n_pages_written++;
-
-		/* We decide whether or not to evict the page from the
-		LRU list based on the flush_type.
-		* BUF_FLUSH_LIST: don't evict
-		* BUF_FLUSH_LRU: always evict
-		* BUF_FLUSH_SINGLE_PAGE: eviction preference is passed
-		by the caller explicitly. */
-		if (buf_page_get_flush_type(bpage) == BUF_FLUSH_LRU) {
-			evict = true;
-		}
-
-		mutex_exit(block_mutex);
-
-		if (evict) {
-			buf_LRU_free_page(bpage, true);
-		}
-	}
-
-	DBUG_PRINT("ib_buf", ("%s page %u:%u",
-			      io_type == BUF_IO_READ ? "read" : "wrote",
-			      bpage->id.space(), bpage->id.page_no()));
-
-	buf_pool_mutex_exit(buf_pool);
-
-	return DB_SUCCESS;
+      const page_id_t corrupt_page_id = bpage->id;
+
+      buf_corrupt_page_release(bpage, space);
+
+      if (recv_recovery_is_on()) {
+        recv_recover_corrupt_page(corrupt_page_id);
+      }
+
+      space->release_for_io();
+      return err;
+    }
+
+    if (recv_recovery_is_on()) {
+      recv_recover_page(bpage);
+    }
+
+    if (uncompressed
+        && !recv_no_ibuf_operations
+        && (bpage->id.space() == 0
+      || !is_predefined_tablespace(bpage->id.space()))
+        && fil_page_get_type(frame) == FIL_PAGE_INDEX
+        && page_is_leaf(frame)
+        && ibuf_page_exists(*bpage)) {
+      bpage->ibuf_exist = true;
+    }
+
+    space->release_for_io();
+  } else {
+    /* io_type == BUF_IO_WRITE */
+    if (bpage->slot) {
+      /* Mark slot free */
+      bpage->slot->release();
+      bpage->slot = NULL;
+    }
+  }
+
+  BPageMutex* block_mutex = buf_page_get_mutex(bpage);
+  buf_pool_mutex_enter(buf_pool);
+  mutex_enter(block_mutex);
+
+  /* Because this thread which does the unlocking is not the same that
+  did the locking, we use a pass value != 0 in unlock, which simply
+  removes the newest lock debug record, without checking the thread
+  id. */
+
+  buf_page_set_io_fix(bpage, BUF_IO_NONE);
+  buf_page_monitor(bpage, io_type);
+
+  if (io_type == BUF_IO_READ) {
+    /* NOTE that the call to ibuf may have moved the ownership of
+    the x-latch to this OS thread: do not let this confuse you in
+    debugging! */
+
+    ut_ad(buf_pool->n_pend_reads > 0);
+    buf_pool->n_pend_reads--;
+    buf_pool->stat.n_pages_read++;
+
+    if (uncompressed) {
+      rw_lock_x_unlock_gen(&((buf_block_t*) bpage)->lock,
+               BUF_IO_READ);
+    }
+
+    mutex_exit(block_mutex);
+  } else {
+    /* Write means a flush operation: call the completion
+    routine in the flush system */
+
+    buf_flush_write_complete(bpage, dblwr);
+
+    if (uncompressed) {
+      rw_lock_sx_unlock_gen(&((buf_block_t*) bpage)->lock,
+                BUF_IO_WRITE);
+    }
+
+    buf_pool->stat.n_pages_written++;
+
+    /* We decide whether or not to evict the page from the
+    LRU list based on the flush_type.
+    * BUF_FLUSH_LIST: don't evict
+    * BUF_FLUSH_LRU: always evict
+    * BUF_FLUSH_SINGLE_PAGE: eviction preference is passed
+    by the caller explicitly. */
+    if (buf_page_get_flush_type(bpage) == BUF_FLUSH_LRU) {
+      evict = true;
+    }
+
+    mutex_exit(block_mutex);
+
+    if (evict) {
+      buf_LRU_free_page(bpage, true);
+    }
+  }
+
+  DBUG_PRINT("ib_buf", ("%s page %u:%u",
+            io_type == BUF_IO_READ ? "read" : "wrote",
+            bpage->id.space(), bpage->id.page_no()));
+
+  buf_pool_mutex_exit(buf_pool);
+
+  return DB_SUCCESS;
 }
 
 /*********************************************************************//**
@@ -6169,28 +6272,28 @@ static
 ibool
 buf_all_freed_instance(
 /*===================*/
-	buf_pool_t*	buf_pool)	/*!< in: buffer pool instancce */
+  buf_pool_t*	buf_pool)	/*!< in: buffer pool instancce */
 {
-	ulint		i;
-	buf_chunk_t*	chunk;
+  ulint		i;
+  buf_chunk_t*	chunk;
 
-	ut_ad(buf_pool);
+  ut_ad(buf_pool);
 
-	buf_pool_mutex_enter(buf_pool);
+  buf_pool_mutex_enter(buf_pool);
 
-	chunk = buf_pool->chunks;
+  chunk = buf_pool->chunks;
 
-	for (i = buf_pool->n_chunks; i--; chunk++) {
+  for (i = buf_pool->n_chunks; i--; chunk++) {
 
-		if (const buf_block_t* block = buf_chunk_not_freed(chunk)) {
-			ib::fatal() << "Page " << block->page.id
-				<< " still fixed or dirty";
-		}
-	}
+    if (const buf_block_t* block = buf_chunk_not_freed(chunk)) {
+      ib::fatal() << "Page " << block->page.id
+        << " still fixed or dirty";
+    }
+  }
 
-	buf_pool_mutex_exit(buf_pool);
+  buf_pool_mutex_exit(buf_pool);
 
-	return(TRUE);
+  return(TRUE);
 }
 
 /** Refreshes the statistics used to print per-second averages.
@@ -6198,10 +6301,10 @@ buf_all_freed_instance(
 static
 void
 buf_refresh_io_stats(
-	buf_pool_t*	buf_pool)
+  buf_pool_t*	buf_pool)
 {
-	buf_pool->last_printout_time = time(NULL);
-	buf_pool->old_stat = buf_pool->stat;
+  buf_pool->last_printout_time = time(NULL);
+  buf_pool->old_stat = buf_pool->stat;
 }
 
 /*********************************************************************//**
@@ -6210,54 +6313,54 @@ static
 void
 buf_pool_invalidate_instance(
 /*=========================*/
-	buf_pool_t*	buf_pool)	/*!< in: buffer pool instance */
+  buf_pool_t*	buf_pool)	/*!< in: buffer pool instance */
 {
-	ulint		i;
+  ulint		i;
 
-	buf_pool_mutex_enter(buf_pool);
+  buf_pool_mutex_enter(buf_pool);
 
-	for (i = BUF_FLUSH_LRU; i < BUF_FLUSH_N_TYPES; i++) {
+  for (i = BUF_FLUSH_LRU; i < BUF_FLUSH_N_TYPES; i++) {
 
-		/* As this function is called during startup and
-		during redo application phase during recovery, InnoDB
-		is single threaded (apart from IO helper threads) at
-		this stage. No new write batch can be in intialization
-		stage at this point. */
-		ut_ad(buf_pool->init_flush[i] == FALSE);
+    /* As this function is called during startup and
+    during redo application phase during recovery, InnoDB
+    is single threaded (apart from IO helper threads) at
+    this stage. No new write batch can be in intialization
+    stage at this point. */
+    ut_ad(buf_pool->init_flush[i] == FALSE);
 
-		/* However, it is possible that a write batch that has
-		been posted earlier is still not complete. For buffer
-		pool invalidation to proceed we must ensure there is NO
-		write activity happening. */
-		if (buf_pool->n_flush[i] > 0) {
-			buf_flush_t	type = static_cast<buf_flush_t>(i);
+    /* However, it is possible that a write batch that has
+    been posted earlier is still not complete. For buffer
+    pool invalidation to proceed we must ensure there is NO
+    write activity happening. */
+    if (buf_pool->n_flush[i] > 0) {
+      buf_flush_t	type = static_cast<buf_flush_t>(i);
 
-			buf_pool_mutex_exit(buf_pool);
-			buf_flush_wait_batch_end(buf_pool, type);
-			buf_pool_mutex_enter(buf_pool);
-		}
-	}
+      buf_pool_mutex_exit(buf_pool);
+      buf_flush_wait_batch_end(buf_pool, type);
+      buf_pool_mutex_enter(buf_pool);
+    }
+  }
 
-	buf_pool_mutex_exit(buf_pool);
+  buf_pool_mutex_exit(buf_pool);
 
-	ut_ad(buf_all_freed_instance(buf_pool));
+  ut_ad(buf_all_freed_instance(buf_pool));
 
-	buf_pool_mutex_enter(buf_pool);
+  buf_pool_mutex_enter(buf_pool);
 
-	while (buf_LRU_scan_and_free_block(buf_pool, true)) {
-	}
+  while (buf_LRU_scan_and_free_block(buf_pool, true)) {
+  }
 
-	ut_ad(UT_LIST_GET_LEN(buf_pool->LRU) == 0);
-	ut_ad(UT_LIST_GET_LEN(buf_pool->unzip_LRU) == 0);
+  ut_ad(UT_LIST_GET_LEN(buf_pool->LRU) == 0);
+  ut_ad(UT_LIST_GET_LEN(buf_pool->unzip_LRU) == 0);
 
-	buf_pool->freed_page_clock = 0;
-	buf_pool->LRU_old = NULL;
-	buf_pool->LRU_old_len = 0;
+  buf_pool->freed_page_clock = 0;
+  buf_pool->LRU_old = NULL;
+  buf_pool->LRU_old_len = 0;
 
-	memset(&buf_pool->stat, 0x00, sizeof(buf_pool->stat));
-	buf_refresh_io_stats(buf_pool);
+  memset(&buf_pool->stat, 0x00, sizeof(buf_pool->stat));
+  buf_refresh_io_stats(buf_pool);
 
-	buf_pool_mutex_exit(buf_pool);
+  buf_pool_mutex_exit(buf_pool);
 }
 
 /*********************************************************************//**
@@ -6268,11 +6371,11 @@ void
 buf_pool_invalidate(void)
 /*=====================*/
 {
-	ulint   i;
+  ulint   i;
 
-	for (i = 0; i < srv_buf_pool_instances; i++) {
-		buf_pool_invalidate_instance(buf_pool_from_array(i));
-	}
+  for (i = 0; i < srv_buf_pool_instances; i++) {
+    buf_pool_invalidate_instance(buf_pool_from_array(i));
+  }
 }
 
 #if defined UNIV_DEBUG || defined UNIV_BUF_DEBUG
@@ -6283,224 +6386,224 @@ static
 ibool
 buf_pool_validate_instance(
 /*=======================*/
-	buf_pool_t*	buf_pool)	/*!< in: buffer pool instance */
+  buf_pool_t*	buf_pool)	/*!< in: buffer pool instance */
 {
-	buf_page_t*	b;
-	buf_chunk_t*	chunk;
-	ulint		i;
-	ulint		n_lru_flush	= 0;
-	ulint		n_page_flush	= 0;
-	ulint		n_list_flush	= 0;
-	ulint		n_lru		= 0;
-	ulint		n_flush		= 0;
-	ulint		n_free		= 0;
-	ulint		n_zip		= 0;
-
-	ut_ad(buf_pool);
-
-	buf_pool_mutex_enter(buf_pool);
-	hash_lock_x_all(buf_pool->page_hash);
-
-	chunk = buf_pool->chunks;
-
-	/* Check the uncompressed blocks. */
-
-	for (i = buf_pool->n_chunks; i--; chunk++) {
-
-		ulint		j;
-		buf_block_t*	block = chunk->blocks;
-
-		for (j = chunk->size; j--; block++) {
-
-			buf_page_mutex_enter(block);
-
-			switch (buf_block_get_state(block)) {
-			case BUF_BLOCK_POOL_WATCH:
-			case BUF_BLOCK_ZIP_PAGE:
-			case BUF_BLOCK_ZIP_DIRTY:
-				/* These should only occur on
-				zip_clean, zip_free[], or flush_list. */
-				ut_error;
-				break;
-
-			case BUF_BLOCK_FILE_PAGE:
-				ut_a(buf_page_hash_get_low(
-						buf_pool, block->page.id)
-				     == &block->page);
-
-				switch (buf_page_get_io_fix(&block->page)) {
-				case BUF_IO_NONE:
-					break;
-
-				case BUF_IO_WRITE:
-					switch (buf_page_get_flush_type(
-							&block->page)) {
-					case BUF_FLUSH_LRU:
-						n_lru_flush++;
-						goto assert_s_latched;
-					case BUF_FLUSH_SINGLE_PAGE:
-						n_page_flush++;
+  buf_page_t*	b;
+  buf_chunk_t*	chunk;
+  ulint		i;
+  ulint		n_lru_flush	= 0;
+  ulint		n_page_flush	= 0;
+  ulint		n_list_flush	= 0;
+  ulint		n_lru		= 0;
+  ulint		n_flush		= 0;
+  ulint		n_free		= 0;
+  ulint		n_zip		= 0;
+
+  ut_ad(buf_pool);
+
+  buf_pool_mutex_enter(buf_pool);
+  hash_lock_x_all(buf_pool->page_hash);
+
+  chunk = buf_pool->chunks;
+
+  /* Check the uncompressed blocks. */
+
+  for (i = buf_pool->n_chunks; i--; chunk++) {
+
+    ulint		j;
+    buf_block_t*	block = chunk->blocks;
+
+    for (j = chunk->size; j--; block++) {
+
+      buf_page_mutex_enter(block);
+
+      switch (buf_block_get_state(block)) {
+      case BUF_BLOCK_POOL_WATCH:
+      case BUF_BLOCK_ZIP_PAGE:
+      case BUF_BLOCK_ZIP_DIRTY:
+        /* These should only occur on
+        zip_clean, zip_free[], or flush_list. */
+        ut_error;
+        break;
+
+      case BUF_BLOCK_FILE_PAGE:
+        ut_a(buf_page_hash_get_low(
+            buf_pool, block->page.id)
+             == &block->page);
+
+        switch (buf_page_get_io_fix(&block->page)) {
+        case BUF_IO_NONE:
+          break;
+
+        case BUF_IO_WRITE:
+          switch (buf_page_get_flush_type(
+              &block->page)) {
+          case BUF_FLUSH_LRU:
+            n_lru_flush++;
+            goto assert_s_latched;
+          case BUF_FLUSH_SINGLE_PAGE:
+            n_page_flush++;
 assert_s_latched:
-						ut_a(rw_lock_is_locked(
-							     &block->lock,
-								     RW_LOCK_S)
-						     || rw_lock_is_locked(
-								&block->lock,
-								RW_LOCK_SX));
-						break;
-					case BUF_FLUSH_LIST:
-						n_list_flush++;
-						break;
-					default:
-						ut_error;
-					}
-
-					break;
-
-				case BUF_IO_READ:
-
-					ut_a(rw_lock_is_locked(&block->lock,
-							       RW_LOCK_X));
-					break;
-
-				case BUF_IO_PIN:
-					break;
-				}
-
-				n_lru++;
-				break;
-
-			case BUF_BLOCK_NOT_USED:
-				n_free++;
-				break;
-
-			case BUF_BLOCK_READY_FOR_USE:
-			case BUF_BLOCK_MEMORY:
-			case BUF_BLOCK_REMOVE_HASH:
-				/* do nothing */
-				break;
-			}
-
-			buf_page_mutex_exit(block);
-		}
-	}
-
-	mutex_enter(&buf_pool->zip_mutex);
-
-	/* Check clean compressed-only blocks. */
-
-	for (b = UT_LIST_GET_FIRST(buf_pool->zip_clean); b;
-	     b = UT_LIST_GET_NEXT(list, b)) {
-		ut_a(buf_page_get_state(b) == BUF_BLOCK_ZIP_PAGE);
-		switch (buf_page_get_io_fix(b)) {
-		case BUF_IO_NONE:
-		case BUF_IO_PIN:
-			/* All clean blocks should be I/O-unfixed. */
-			break;
-		case BUF_IO_READ:
-			/* In buf_LRU_free_page(), we temporarily set
-			b->io_fix = BUF_IO_READ for a newly allocated
-			control block in order to prevent
-			buf_page_get_gen() from decompressing the block. */
-			break;
-		default:
-			ut_error;
-			break;
-		}
-
-		/* It is OK to read oldest_modification here because
-		we have acquired buf_pool->zip_mutex above which acts
-		as the 'block->mutex' for these bpages. */
-		ut_a(!b->oldest_modification);
-		ut_a(buf_page_hash_get_low(buf_pool, b->id) == b);
-		n_lru++;
-		n_zip++;
-	}
-
-	/* Check dirty blocks. */
-
-	buf_flush_list_mutex_enter(buf_pool);
-	for (b = UT_LIST_GET_FIRST(buf_pool->flush_list); b;
-	     b = UT_LIST_GET_NEXT(list, b)) {
-		ut_ad(b->in_flush_list);
-		ut_a(b->oldest_modification);
-		n_flush++;
-
-		switch (buf_page_get_state(b)) {
-		case BUF_BLOCK_ZIP_DIRTY:
-			n_lru++;
-			n_zip++;
-			switch (buf_page_get_io_fix(b)) {
-			case BUF_IO_NONE:
-			case BUF_IO_READ:
-			case BUF_IO_PIN:
-				break;
-			case BUF_IO_WRITE:
-				switch (buf_page_get_flush_type(b)) {
-				case BUF_FLUSH_LRU:
-					n_lru_flush++;
-					break;
-				case BUF_FLUSH_SINGLE_PAGE:
-					n_page_flush++;
-					break;
-				case BUF_FLUSH_LIST:
-					n_list_flush++;
-					break;
-				default:
-					ut_error;
-				}
-				break;
-			}
-			break;
-		case BUF_BLOCK_FILE_PAGE:
-			/* uncompressed page */
-			break;
-		case BUF_BLOCK_POOL_WATCH:
-		case BUF_BLOCK_ZIP_PAGE:
-		case BUF_BLOCK_NOT_USED:
-		case BUF_BLOCK_READY_FOR_USE:
-		case BUF_BLOCK_MEMORY:
-		case BUF_BLOCK_REMOVE_HASH:
-			ut_error;
-			break;
-		}
-		ut_a(buf_page_hash_get_low(buf_pool, b->id) == b);
-	}
-
-	ut_a(UT_LIST_GET_LEN(buf_pool->flush_list) == n_flush);
-
-	hash_unlock_x_all(buf_pool->page_hash);
-	buf_flush_list_mutex_exit(buf_pool);
-
-	mutex_exit(&buf_pool->zip_mutex);
-
-	if (buf_pool->curr_size == buf_pool->old_size
-	    && n_lru + n_free > buf_pool->curr_size + n_zip) {
-
-		ib::fatal() << "n_LRU " << n_lru << ", n_free " << n_free
-			<< ", pool " << buf_pool->curr_size
-			<< " zip " << n_zip << ". Aborting...";
-	}
-
-	ut_a(UT_LIST_GET_LEN(buf_pool->LRU) == n_lru);
-	if (buf_pool->curr_size == buf_pool->old_size
-	    && UT_LIST_GET_LEN(buf_pool->free) != n_free) {
-
-		ib::fatal() << "Free list len "
-			<< UT_LIST_GET_LEN(buf_pool->free)
-			<< ", free blocks " << n_free << ". Aborting...";
-	}
-
-	ut_a(buf_pool->n_flush[BUF_FLUSH_LIST] == n_list_flush);
-	ut_a(buf_pool->n_flush[BUF_FLUSH_LRU] == n_lru_flush);
-	ut_a(buf_pool->n_flush[BUF_FLUSH_SINGLE_PAGE] == n_page_flush);
-
-	buf_pool_mutex_exit(buf_pool);
-
-	ut_a(buf_LRU_validate());
-	ut_a(buf_flush_validate(buf_pool));
-
-	return(TRUE);
+            ut_a(rw_lock_is_locked(
+                   &block->lock,
+                     RW_LOCK_S)
+                 || rw_lock_is_locked(
+                &block->lock,
+                RW_LOCK_SX));
+            break;
+          case BUF_FLUSH_LIST:
+            n_list_flush++;
+            break;
+          default:
+            ut_error;
+          }
+
+          break;
+
+        case BUF_IO_READ:
+
+          ut_a(rw_lock_is_locked(&block->lock,
+                     RW_LOCK_X));
+          break;
+
+        case BUF_IO_PIN:
+          break;
+        }
+
+        n_lru++;
+        break;
+
+      case BUF_BLOCK_NOT_USED:
+        n_free++;
+        break;
+
+      case BUF_BLOCK_READY_FOR_USE:
+      case BUF_BLOCK_MEMORY:
+      case BUF_BLOCK_REMOVE_HASH:
+        /* do nothing */
+        break;
+      }
+
+      buf_page_mutex_exit(block);
+    }
+  }
+
+  mutex_enter(&buf_pool->zip_mutex);
+
+  /* Check clean compressed-only blocks. */
+
+  for (b = UT_LIST_GET_FIRST(buf_pool->zip_clean); b;
+       b = UT_LIST_GET_NEXT(list, b)) {
+    ut_a(buf_page_get_state(b) == BUF_BLOCK_ZIP_PAGE);
+    switch (buf_page_get_io_fix(b)) {
+    case BUF_IO_NONE:
+    case BUF_IO_PIN:
+      /* All clean blocks should be I/O-unfixed. */
+      break;
+    case BUF_IO_READ:
+      /* In buf_LRU_free_page(), we temporarily set
+      b->io_fix = BUF_IO_READ for a newly allocated
+      control block in order to prevent
+      buf_page_get_gen() from decompressing the block. */
+      break;
+    default:
+      ut_error;
+      break;
+    }
+
+    /* It is OK to read oldest_modification here because
+    we have acquired buf_pool->zip_mutex above which acts
+    as the 'block->mutex' for these bpages. */
+    ut_a(!b->oldest_modification);
+    ut_a(buf_page_hash_get_low(buf_pool, b->id) == b);
+    n_lru++;
+    n_zip++;
+  }
+
+  /* Check dirty blocks. */
+
+  buf_flush_list_mutex_enter(buf_pool);
+  for (b = UT_LIST_GET_FIRST(buf_pool->flush_list); b;
+       b = UT_LIST_GET_NEXT(list, b)) {
+    ut_ad(b->in_flush_list);
+    ut_a(b->oldest_modification);
+    n_flush++;
+
+    switch (buf_page_get_state(b)) {
+    case BUF_BLOCK_ZIP_DIRTY:
+      n_lru++;
+      n_zip++;
+      switch (buf_page_get_io_fix(b)) {
+      case BUF_IO_NONE:
+      case BUF_IO_READ:
+      case BUF_IO_PIN:
+        break;
+      case BUF_IO_WRITE:
+        switch (buf_page_get_flush_type(b)) {
+        case BUF_FLUSH_LRU:
+          n_lru_flush++;
+          break;
+        case BUF_FLUSH_SINGLE_PAGE:
+          n_page_flush++;
+          break;
+        case BUF_FLUSH_LIST:
+          n_list_flush++;
+          break;
+        default:
+          ut_error;
+        }
+        break;
+      }
+      break;
+    case BUF_BLOCK_FILE_PAGE:
+      /* uncompressed page */
+      break;
+    case BUF_BLOCK_POOL_WATCH:
+    case BUF_BLOCK_ZIP_PAGE:
+    case BUF_BLOCK_NOT_USED:
+    case BUF_BLOCK_READY_FOR_USE:
+    case BUF_BLOCK_MEMORY:
+    case BUF_BLOCK_REMOVE_HASH:
+      ut_error;
+      break;
+    }
+    ut_a(buf_page_hash_get_low(buf_pool, b->id) == b);
+  }
+
+  ut_a(UT_LIST_GET_LEN(buf_pool->flush_list) == n_flush);
+
+  hash_unlock_x_all(buf_pool->page_hash);
+  buf_flush_list_mutex_exit(buf_pool);
+
+  mutex_exit(&buf_pool->zip_mutex);
+
+  if (buf_pool->curr_size == buf_pool->old_size
+      && n_lru + n_free > buf_pool->curr_size + n_zip) {
+
+    ib::fatal() << "n_LRU " << n_lru << ", n_free " << n_free
+      << ", pool " << buf_pool->curr_size
+      << " zip " << n_zip << ". Aborting...";
+  }
+
+  ut_a(UT_LIST_GET_LEN(buf_pool->LRU) == n_lru);
+  if (buf_pool->curr_size == buf_pool->old_size
+      && UT_LIST_GET_LEN(buf_pool->free) != n_free) {
+
+    ib::fatal() << "Free list len "
+      << UT_LIST_GET_LEN(buf_pool->free)
+      << ", free blocks " << n_free << ". Aborting...";
+  }
+
+  ut_a(buf_pool->n_flush[BUF_FLUSH_LIST] == n_list_flush);
+  ut_a(buf_pool->n_flush[BUF_FLUSH_LRU] == n_lru_flush);
+  ut_a(buf_pool->n_flush[BUF_FLUSH_SINGLE_PAGE] == n_page_flush);
+
+  buf_pool_mutex_exit(buf_pool);
+
+  ut_a(buf_LRU_validate());
+  ut_a(buf_flush_validate(buf_pool));
+
+  return(TRUE);
 }
 
 /*********************************************************************//**
@@ -6510,16 +6613,16 @@ ibool
 buf_validate(void)
 /*==============*/
 {
-	ulint	i;
+  ulint	i;
 
-	for (i = 0; i < srv_buf_pool_instances; i++) {
-		buf_pool_t*	buf_pool;
+  for (i = 0; i < srv_buf_pool_instances; i++) {
+    buf_pool_t*	buf_pool;
 
-		buf_pool = buf_pool_from_array(i);
+    buf_pool = buf_pool_from_array(i);
 
-		buf_pool_validate_instance(buf_pool);
-	}
-	return(TRUE);
+    buf_pool_validate_instance(buf_pool);
+  }
+  return(TRUE);
 }
 
 #endif /* UNIV_DEBUG || UNIV_BUF_DEBUG */
@@ -6531,94 +6634,94 @@ static
 void
 buf_print_instance(
 /*===============*/
-	buf_pool_t*	buf_pool)
+  buf_pool_t*	buf_pool)
 {
-	index_id_t*	index_ids;
-	ulint*		counts;
-	ulint		size;
-	ulint		i;
-	ulint		j;
-	index_id_t	id;
-	ulint		n_found;
-	buf_chunk_t*	chunk;
-	dict_index_t*	index;
-
-	ut_ad(buf_pool);
+  index_id_t*	index_ids;
+  ulint*		counts;
+  ulint		size;
+  ulint		i;
+  ulint		j;
+  index_id_t	id;
+  ulint		n_found;
+  buf_chunk_t*	chunk;
+  dict_index_t*	index;
 
-	size = buf_pool->curr_size;
+  ut_ad(buf_pool);
 
-	index_ids = static_cast<index_id_t*>(
-		ut_malloc_nokey(size * sizeof *index_ids));
+  size = buf_pool->curr_size;
 
-	counts = static_cast<ulint*>(ut_malloc_nokey(sizeof(ulint) * size));
+  index_ids = static_cast<index_id_t*>(
+    ut_malloc_nokey(size * sizeof *index_ids));
 
-	buf_pool_mutex_enter(buf_pool);
-	buf_flush_list_mutex_enter(buf_pool);
+  counts = static_cast<ulint*>(ut_malloc_nokey(sizeof(ulint) * size));
 
-	ib::info() << *buf_pool;
+  buf_pool_mutex_enter(buf_pool);
+  buf_flush_list_mutex_enter(buf_pool);
 
-	buf_flush_list_mutex_exit(buf_pool);
+  ib::info() << *buf_pool;
 
-	/* Count the number of blocks belonging to each index in the buffer */
+  buf_flush_list_mutex_exit(buf_pool);
 
-	n_found = 0;
+  /* Count the number of blocks belonging to each index in the buffer */
 
-	chunk = buf_pool->chunks;
+  n_found = 0;
 
-	for (i = buf_pool->n_chunks; i--; chunk++) {
-		buf_block_t*	block		= chunk->blocks;
-		ulint		n_blocks	= chunk->size;
+  chunk = buf_pool->chunks;
 
-		for (; n_blocks--; block++) {
-			const buf_frame_t* frame = block->frame;
+  for (i = buf_pool->n_chunks; i--; chunk++) {
+    buf_block_t*	block		= chunk->blocks;
+    ulint		n_blocks	= chunk->size;
 
-			if (fil_page_index_page_check(frame)) {
+    for (; n_blocks--; block++) {
+      const buf_frame_t* frame = block->frame;
 
-				id = btr_page_get_index_id(frame);
+      if (fil_page_index_page_check(frame)) {
 
-				/* Look for the id in the index_ids array */
-				j = 0;
+        id = btr_page_get_index_id(frame);
 
-				while (j < n_found) {
+        /* Look for the id in the index_ids array */
+        j = 0;
 
-					if (index_ids[j] == id) {
-						counts[j]++;
+        while (j < n_found) {
 
-						break;
-					}
-					j++;
-				}
+          if (index_ids[j] == id) {
+            counts[j]++;
 
-				if (j == n_found) {
-					n_found++;
-					index_ids[j] = id;
-					counts[j] = 1;
-				}
-			}
-		}
-	}
+            break;
+          }
+          j++;
+        }
 
-	buf_pool_mutex_exit(buf_pool);
-
-	for (i = 0; i < n_found; i++) {
-		index = dict_index_get_if_in_cache(index_ids[i]);
-
-		if (!index) {
-			ib::info() << "Block count for index "
-				<< index_ids[i] << " in buffer is about "
-				<< counts[i];
-		} else {
-			ib::info() << "Block count for index " << index_ids[i]
-				<< " in buffer is about " << counts[i]
-				<< ", index " << index->name
-				<< " of table " << index->table->name;
-		}
-	}
+        if (j == n_found) {
+          n_found++;
+          index_ids[j] = id;
+          counts[j] = 1;
+        }
+      }
+    }
+  }
+
+  buf_pool_mutex_exit(buf_pool);
+
+  for (i = 0; i < n_found; i++) {
+    index = dict_index_get_if_in_cache(index_ids[i]);
+
+    if (!index) {
+      ib::info() << "Block count for index "
+        << index_ids[i] << " in buffer is about "
+        << counts[i];
+    } else {
+      ib::info() << "Block count for index " << index_ids[i]
+        << " in buffer is about " << counts[i]
+        << ", index " << index->name
+        << " of table " << index->table->name;
+    }
+  }
 
-	ut_free(index_ids);
-	ut_free(counts);
+  ut_free(index_ids);
+  ut_free(counts);
 
-	ut_a(buf_pool_validate_instance(buf_pool));
+  ut_a(buf_pool_validate_instance(buf_pool));
 }
 
 /*********************************************************************//**
@@ -6627,14 +6730,14 @@ void
 buf_print(void)
 /*===========*/
 {
-	ulint   i;
+  ulint   i;
 
-	for (i = 0; i < srv_buf_pool_instances; i++) {
-		buf_pool_t*	buf_pool;
+  for (i = 0; i < srv_buf_pool_instances; i++) {
+    buf_pool_t*	buf_pool;
 
-		buf_pool = buf_pool_from_array(i);
-		buf_print_instance(buf_pool);
-	}
+    buf_pool = buf_pool_from_array(i);
+    buf_print_instance(buf_pool);
+  }
 }
 #endif /* UNIV_DEBUG_PRINT || UNIV_DEBUG || UNIV_BUF_DEBUG */
 
@@ -6646,88 +6749,88 @@ static
 ulint
 buf_get_latched_pages_number_instance(
 /*==================================*/
-	buf_pool_t*	buf_pool)	/*!< in: buffer pool instance */
+  buf_pool_t*	buf_pool)	/*!< in: buffer pool instance */
 {
-	buf_page_t*	b;
-	ulint		i;
-	buf_chunk_t*	chunk;
-	ulint		fixed_pages_number = 0;
-
-	buf_pool_mutex_enter(buf_pool);
-
-	chunk = buf_pool->chunks;
-
-	for (i = buf_pool->n_chunks; i--; chunk++) {
-		buf_block_t*	block;
-		ulint		j;
-
-		block = chunk->blocks;
-
-		for (j = chunk->size; j--; block++) {
-			if (buf_block_get_state(block)
-			    != BUF_BLOCK_FILE_PAGE) {
-
-				continue;
-			}
-
-			buf_page_mutex_enter(block);
-
-			if (block->page.buf_fix_count != 0
-			    || buf_page_get_io_fix(&block->page)
-			    != BUF_IO_NONE) {
-				fixed_pages_number++;
-			}
-
-			buf_page_mutex_exit(block);
-		}
-	}
-
-	mutex_enter(&buf_pool->zip_mutex);
-
-	/* Traverse the lists of clean and dirty compressed-only blocks. */
-
-	for (b = UT_LIST_GET_FIRST(buf_pool->zip_clean); b;
-	     b = UT_LIST_GET_NEXT(list, b)) {
-		ut_a(buf_page_get_state(b) == BUF_BLOCK_ZIP_PAGE);
-		ut_a(buf_page_get_io_fix(b) != BUF_IO_WRITE);
-
-		if (b->buf_fix_count != 0
-		    || buf_page_get_io_fix(b) != BUF_IO_NONE) {
-			fixed_pages_number++;
-		}
-	}
-
-	buf_flush_list_mutex_enter(buf_pool);
-	for (b = UT_LIST_GET_FIRST(buf_pool->flush_list); b;
-	     b = UT_LIST_GET_NEXT(list, b)) {
-		ut_ad(b->in_flush_list);
-
-		switch (buf_page_get_state(b)) {
-		case BUF_BLOCK_ZIP_DIRTY:
-			if (b->buf_fix_count != 0
-			    || buf_page_get_io_fix(b) != BUF_IO_NONE) {
-				fixed_pages_number++;
-			}
-			break;
-		case BUF_BLOCK_FILE_PAGE:
-			/* uncompressed page */
-			break;
-		case BUF_BLOCK_POOL_WATCH:
-		case BUF_BLOCK_ZIP_PAGE:
-		case BUF_BLOCK_NOT_USED:
-		case BUF_BLOCK_READY_FOR_USE:
-		case BUF_BLOCK_MEMORY:
-		case BUF_BLOCK_REMOVE_HASH:
-			ut_error;
-			break;
-		}
-	}
-
-	buf_flush_list_mutex_exit(buf_pool);
-	mutex_exit(&buf_pool->zip_mutex);
-	buf_pool_mutex_exit(buf_pool);
-
-	return(fixed_pages_number);
+  buf_page_t*	b;
+  ulint		i;
+  buf_chunk_t*	chunk;
+  ulint		fixed_pages_number = 0;
+
+  buf_pool_mutex_enter(buf_pool);
+
+  chunk = buf_pool->chunks;
+
+  for (i = buf_pool->n_chunks; i--; chunk++) {
+    buf_block_t*	block;
+    ulint		j;
+
+    block = chunk->blocks;
+
+    for (j = chunk->size; j--; block++) {
+      if (buf_block_get_state(block)
+          != BUF_BLOCK_FILE_PAGE) {
+
+        continue;
+      }
+
+      buf_page_mutex_enter(block);
+
+      if (block->page.buf_fix_count != 0
+          || buf_page_get_io_fix(&block->page)
+          != BUF_IO_NONE) {
+        fixed_pages_number++;
+      }
+
+      buf_page_mutex_exit(block);
+    }
+  }
+
+  mutex_enter(&buf_pool->zip_mutex);
+
+  /* Traverse the lists of clean and dirty compressed-only blocks. */
+
+  for (b = UT_LIST_GET_FIRST(buf_pool->zip_clean); b;
+       b = UT_LIST_GET_NEXT(list, b)) {
+    ut_a(buf_page_get_state(b) == BUF_BLOCK_ZIP_PAGE);
+    ut_a(buf_page_get_io_fix(b) != BUF_IO_WRITE);
+
+    if (b->buf_fix_count != 0
+        || buf_page_get_io_fix(b) != BUF_IO_NONE) {
+      fixed_pages_number++;
+    }
+  }
+
+  buf_flush_list_mutex_enter(buf_pool);
+  for (b = UT_LIST_GET_FIRST(buf_pool->flush_list); b;
+       b = UT_LIST_GET_NEXT(list, b)) {
+    ut_ad(b->in_flush_list);
+
+    switch (buf_page_get_state(b)) {
+    case BUF_BLOCK_ZIP_DIRTY:
+      if (b->buf_fix_count != 0
+          || buf_page_get_io_fix(b) != BUF_IO_NONE) {
+        fixed_pages_number++;
+      }
+      break;
+    case BUF_BLOCK_FILE_PAGE:
+      /* uncompressed page */
+      break;
+    case BUF_BLOCK_POOL_WATCH:
+    case BUF_BLOCK_ZIP_PAGE:
+    case BUF_BLOCK_NOT_USED:
+    case BUF_BLOCK_READY_FOR_USE:
+    case BUF_BLOCK_MEMORY:
+    case BUF_BLOCK_REMOVE_HASH:
+      ut_error;
+      break;
+    }
+  }
+
+  buf_flush_list_mutex_exit(buf_pool);
+  mutex_exit(&buf_pool->zip_mutex);
+  buf_pool_mutex_exit(buf_pool);
+
+  return(fixed_pages_number);
 }
 
 /*********************************************************************//**
@@ -6737,19 +6840,19 @@ ulint
 buf_get_latched_pages_number(void)
 /*==============================*/
 {
-	ulint	i;
-	ulint	total_latched_pages = 0;
+  ulint	i;
+  ulint	total_latched_pages = 0;
 
-	for (i = 0; i < srv_buf_pool_instances; i++) {
-		buf_pool_t*	buf_pool;
+  for (i = 0; i < srv_buf_pool_instances; i++) {
+    buf_pool_t*	buf_pool;
 
-		buf_pool = buf_pool_from_array(i);
+    buf_pool = buf_pool_from_array(i);
 
-		total_latched_pages += buf_get_latched_pages_number_instance(
-			buf_pool);
-	}
+    total_latched_pages += buf_get_latched_pages_number_instance(
+      buf_pool);
+  }
 
-	return(total_latched_pages);
+  return(total_latched_pages);
 }
 
 #endif /* UNIV_DEBUG */
@@ -6761,13 +6864,13 @@ ulint
 buf_get_n_pending_read_ios(void)
 /*============================*/
 {
-	ulint	pend_ios = 0;
+  ulint	pend_ios = 0;
 
-	for (ulint i = 0; i < srv_buf_pool_instances; i++) {
-		pend_ios += buf_pool_from_array(i)->n_pend_reads;
-	}
+  for (ulint i = 0; i < srv_buf_pool_instances; i++) {
+    pend_ios += buf_pool_from_array(i)->n_pend_reads;
+  }
 
-	return(pend_ios);
+  return(pend_ios);
 }
 
 /*********************************************************************//**
@@ -6778,19 +6881,19 @@ double
 buf_get_modified_ratio_pct(void)
 /*============================*/
 {
-	double		ratio;
-	ulint		lru_len = 0;
-	ulint		free_len = 0;
-	ulint		flush_list_len = 0;
+  double		ratio;
+  ulint		lru_len = 0;
+  ulint		free_len = 0;
+  ulint		flush_list_len = 0;
 
-	buf_get_total_list_len(&lru_len, &free_len, &flush_list_len);
+  buf_get_total_list_len(&lru_len, &free_len, &flush_list_len);
 
-	ratio = static_cast<double>(100 * flush_list_len)
-		/ (1 + lru_len + free_len);
+  ratio = static_cast<double>(100 * flush_list_len)
+    / (1 + lru_len + free_len);
 
-	/* 1 + is there to avoid division by zero */
+  /* 1 + is there to avoid division by zero */
 
-	return(ratio);
+  return(ratio);
 }
 
 /*******************************************************************//**
@@ -6799,55 +6902,55 @@ static
 void
 buf_stats_aggregate_pool_info(
 /*==========================*/
-	buf_pool_info_t*	total_info,	/*!< in/out: the buffer pool
-						info to store aggregated
-						result */
-	const buf_pool_info_t*	pool_info)	/*!< in: individual buffer pool
-						stats info */
+  buf_pool_info_t*	total_info,	/*!< in/out: the buffer pool
+            info to store aggregated
+            result */
+  const buf_pool_info_t*	pool_info)	/*!< in: individual buffer pool
+            stats info */
 {
-	ut_a(total_info && pool_info);
-
-	/* Nothing to copy if total_info is the same as pool_info */
-	if (total_info == pool_info) {
-		return;
-	}
-
-	total_info->pool_size += pool_info->pool_size;
-	total_info->lru_len += pool_info->lru_len;
-	total_info->old_lru_len += pool_info->old_lru_len;
-	total_info->free_list_len += pool_info->free_list_len;
-	total_info->flush_list_len += pool_info->flush_list_len;
-	total_info->n_pend_unzip += pool_info->n_pend_unzip;
-	total_info->n_pend_reads += pool_info->n_pend_reads;
-	total_info->n_pending_flush_lru += pool_info->n_pending_flush_lru;
-	total_info->n_pending_flush_list += pool_info->n_pending_flush_list;
-	total_info->n_pages_made_young += pool_info->n_pages_made_young;
-	total_info->n_pages_not_made_young += pool_info->n_pages_not_made_young;
-	total_info->n_pages_read += pool_info->n_pages_read;
-	total_info->n_pages_created += pool_info->n_pages_created;
-	total_info->n_pages_written += pool_info->n_pages_written;
-	total_info->n_page_gets += pool_info->n_page_gets;
-	total_info->n_ra_pages_read_rnd += pool_info->n_ra_pages_read_rnd;
-	total_info->n_ra_pages_read += pool_info->n_ra_pages_read;
-	total_info->n_ra_pages_evicted += pool_info->n_ra_pages_evicted;
-	total_info->page_made_young_rate += pool_info->page_made_young_rate;
-	total_info->page_not_made_young_rate +=
-		pool_info->page_not_made_young_rate;
-	total_info->pages_read_rate += pool_info->pages_read_rate;
-	total_info->pages_created_rate += pool_info->pages_created_rate;
-	total_info->pages_written_rate += pool_info->pages_written_rate;
-	total_info->n_page_get_delta += pool_info->n_page_get_delta;
-	total_info->page_read_delta += pool_info->page_read_delta;
-	total_info->young_making_delta += pool_info->young_making_delta;
-	total_info->not_young_making_delta += pool_info->not_young_making_delta;
-	total_info->pages_readahead_rnd_rate += pool_info->pages_readahead_rnd_rate;
-	total_info->pages_readahead_rate += pool_info->pages_readahead_rate;
-	total_info->pages_evicted_rate += pool_info->pages_evicted_rate;
-	total_info->unzip_lru_len += pool_info->unzip_lru_len;
-	total_info->io_sum += pool_info->io_sum;
-	total_info->io_cur += pool_info->io_cur;
-	total_info->unzip_sum += pool_info->unzip_sum;
-	total_info->unzip_cur += pool_info->unzip_cur;
+  ut_a(total_info && pool_info);
+
+  /* Nothing to copy if total_info is the same as pool_info */
+  if (total_info == pool_info) {
+    return;
+  }
+
+  total_info->pool_size += pool_info->pool_size;
+  total_info->lru_len += pool_info->lru_len;
+  total_info->old_lru_len += pool_info->old_lru_len;
+  total_info->free_list_len += pool_info->free_list_len;
+  total_info->flush_list_len += pool_info->flush_list_len;
+  total_info->n_pend_unzip += pool_info->n_pend_unzip;
+  total_info->n_pend_reads += pool_info->n_pend_reads;
+  total_info->n_pending_flush_lru += pool_info->n_pending_flush_lru;
+  total_info->n_pending_flush_list += pool_info->n_pending_flush_list;
+  total_info->n_pages_made_young += pool_info->n_pages_made_young;
+  total_info->n_pages_not_made_young += pool_info->n_pages_not_made_young;
+  total_info->n_pages_read += pool_info->n_pages_read;
+  total_info->n_pages_created += pool_info->n_pages_created;
+  total_info->n_pages_written += pool_info->n_pages_written;
+  total_info->n_page_gets += pool_info->n_page_gets;
+  total_info->n_ra_pages_read_rnd += pool_info->n_ra_pages_read_rnd;
+  total_info->n_ra_pages_read += pool_info->n_ra_pages_read;
+  total_info->n_ra_pages_evicted += pool_info->n_ra_pages_evicted;
+  total_info->page_made_young_rate += pool_info->page_made_young_rate;
+  total_info->page_not_made_young_rate +=
+    pool_info->page_not_made_young_rate;
+  total_info->pages_read_rate += pool_info->pages_read_rate;
+  total_info->pages_created_rate += pool_info->pages_created_rate;
+  total_info->pages_written_rate += pool_info->pages_written_rate;
+  total_info->n_page_get_delta += pool_info->n_page_get_delta;
+  total_info->page_read_delta += pool_info->page_read_delta;
+  total_info->young_making_delta += pool_info->young_making_delta;
+  total_info->not_young_making_delta += pool_info->not_young_making_delta;
+  total_info->pages_readahead_rnd_rate += pool_info->pages_readahead_rnd_rate;
+  total_info->pages_readahead_rate += pool_info->pages_readahead_rate;
+  total_info->pages_evicted_rate += pool_info->pages_evicted_rate;
+  total_info->unzip_lru_len += pool_info->unzip_lru_len;
+  total_info->io_sum += pool_info->io_sum;
+  total_info->io_cur += pool_info->io_cur;
+  total_info->unzip_sum += pool_info->unzip_sum;
+  total_info->unzip_cur += pool_info->unzip_cur;
 }
 /*******************************************************************//**
 Collect buffer pool stats information for a buffer pool. Also
@@ -6856,133 +6959,133 @@ in the server */
 void
 buf_stats_get_pool_info(
 /*====================*/
-	buf_pool_t*		buf_pool,	/*!< in: buffer pool */
-	uint			pool_id,	/*!< in: buffer pool ID */
-	buf_pool_info_t*	all_pool_info)	/*!< in/out: buffer pool info
-						to fill */
+  buf_pool_t*		buf_pool,	/*!< in: buffer pool */
+  uint			pool_id,	/*!< in: buffer pool ID */
+  buf_pool_info_t*	all_pool_info)	/*!< in/out: buffer pool info
+            to fill */
 {
-	buf_pool_info_t*	pool_info;
-	time_t			current_time;
-	double			time_elapsed;
+  buf_pool_info_t*	pool_info;
+  time_t			current_time;
+  double			time_elapsed;
 
-	/* Find appropriate pool_info to store stats for this buffer pool */
-	pool_info = &all_pool_info[pool_id];
+  /* Find appropriate pool_info to store stats for this buffer pool */
+  pool_info = &all_pool_info[pool_id];
 
-	buf_pool_mutex_enter(buf_pool);
-	buf_flush_list_mutex_enter(buf_pool);
+  buf_pool_mutex_enter(buf_pool);
+  buf_flush_list_mutex_enter(buf_pool);
 
-	pool_info->pool_unique_id = pool_id;
+  pool_info->pool_unique_id = pool_id;
 
-	pool_info->pool_size = buf_pool->curr_size;
+  pool_info->pool_size = buf_pool->curr_size;
 
-	pool_info->lru_len = UT_LIST_GET_LEN(buf_pool->LRU);
+  pool_info->lru_len = UT_LIST_GET_LEN(buf_pool->LRU);
 
-	pool_info->old_lru_len = buf_pool->LRU_old_len;
+  pool_info->old_lru_len = buf_pool->LRU_old_len;
 
-	pool_info->free_list_len = UT_LIST_GET_LEN(buf_pool->free);
+  pool_info->free_list_len = UT_LIST_GET_LEN(buf_pool->free);
 
-	pool_info->flush_list_len = UT_LIST_GET_LEN(buf_pool->flush_list);
+  pool_info->flush_list_len = UT_LIST_GET_LEN(buf_pool->flush_list);
 
-	pool_info->n_pend_unzip = UT_LIST_GET_LEN(buf_pool->unzip_LRU);
+  pool_info->n_pend_unzip = UT_LIST_GET_LEN(buf_pool->unzip_LRU);
 
-	pool_info->n_pend_reads = buf_pool->n_pend_reads;
+  pool_info->n_pend_reads = buf_pool->n_pend_reads;
 
-	pool_info->n_pending_flush_lru =
-		 (buf_pool->n_flush[BUF_FLUSH_LRU]
-		  + buf_pool->init_flush[BUF_FLUSH_LRU]);
+  pool_info->n_pending_flush_lru =
+     (buf_pool->n_flush[BUF_FLUSH_LRU]
+      + buf_pool->init_flush[BUF_FLUSH_LRU]);
 
-	pool_info->n_pending_flush_list =
-		 (buf_pool->n_flush[BUF_FLUSH_LIST]
-		  + buf_pool->init_flush[BUF_FLUSH_LIST]);
+  pool_info->n_pending_flush_list =
+     (buf_pool->n_flush[BUF_FLUSH_LIST]
+      + buf_pool->init_flush[BUF_FLUSH_LIST]);
 
-	pool_info->n_pending_flush_single_page =
-		 (buf_pool->n_flush[BUF_FLUSH_SINGLE_PAGE]
-		  + buf_pool->init_flush[BUF_FLUSH_SINGLE_PAGE]);
+  pool_info->n_pending_flush_single_page =
+     (buf_pool->n_flush[BUF_FLUSH_SINGLE_PAGE]
+      + buf_pool->init_flush[BUF_FLUSH_SINGLE_PAGE]);
 
-	buf_flush_list_mutex_exit(buf_pool);
+  buf_flush_list_mutex_exit(buf_pool);
 
-	current_time = time(NULL);
-	time_elapsed = 0.001 + difftime(current_time,
-					buf_pool->last_printout_time);
+  current_time = time(NULL);
+  time_elapsed = 0.001 + difftime(current_time,
+          buf_pool->last_printout_time);
 
-	pool_info->n_pages_made_young = buf_pool->stat.n_pages_made_young;
+  pool_info->n_pages_made_young = buf_pool->stat.n_pages_made_young;
 
-	pool_info->n_pages_not_made_young =
-		buf_pool->stat.n_pages_not_made_young;
+  pool_info->n_pages_not_made_young =
+    buf_pool->stat.n_pages_not_made_young;
 
-	pool_info->n_pages_read = buf_pool->stat.n_pages_read;
+  pool_info->n_pages_read = buf_pool->stat.n_pages_read;
 
-	pool_info->n_pages_created = buf_pool->stat.n_pages_created;
+  pool_info->n_pages_created = buf_pool->stat.n_pages_created;
 
-	pool_info->n_pages_written = buf_pool->stat.n_pages_written;
+  pool_info->n_pages_written = buf_pool->stat.n_pages_written;
 
-	pool_info->n_page_gets = buf_pool->stat.n_page_gets;
+  pool_info->n_page_gets = buf_pool->stat.n_page_gets;
 
-	pool_info->n_ra_pages_read_rnd = buf_pool->stat.n_ra_pages_read_rnd;
-	pool_info->n_ra_pages_read = buf_pool->stat.n_ra_pages_read;
+  pool_info->n_ra_pages_read_rnd = buf_pool->stat.n_ra_pages_read_rnd;
+  pool_info->n_ra_pages_read = buf_pool->stat.n_ra_pages_read;
 
-	pool_info->n_ra_pages_evicted = buf_pool->stat.n_ra_pages_evicted;
+  pool_info->n_ra_pages_evicted = buf_pool->stat.n_ra_pages_evicted;
 
-	pool_info->page_made_young_rate =
-		 (buf_pool->stat.n_pages_made_young
-		  - buf_pool->old_stat.n_pages_made_young) / time_elapsed;
+  pool_info->page_made_young_rate =
+     (buf_pool->stat.n_pages_made_young
+      - buf_pool->old_stat.n_pages_made_young) / time_elapsed;
 
-	pool_info->page_not_made_young_rate =
-		 (buf_pool->stat.n_pages_not_made_young
-		  - buf_pool->old_stat.n_pages_not_made_young) / time_elapsed;
+  pool_info->page_not_made_young_rate =
+     (buf_pool->stat.n_pages_not_made_young
+      - buf_pool->old_stat.n_pages_not_made_young) / time_elapsed;
 
-	pool_info->pages_read_rate =
-		(buf_pool->stat.n_pages_read
-		  - buf_pool->old_stat.n_pages_read) / time_elapsed;
+  pool_info->pages_read_rate =
+    (buf_pool->stat.n_pages_read
+      - buf_pool->old_stat.n_pages_read) / time_elapsed;
 
-	pool_info->pages_created_rate =
-		(buf_pool->stat.n_pages_created
-		 - buf_pool->old_stat.n_pages_created) / time_elapsed;
+  pool_info->pages_created_rate =
+    (buf_pool->stat.n_pages_created
+     - buf_pool->old_stat.n_pages_created) / time_elapsed;
 
-	pool_info->pages_written_rate =
-		(buf_pool->stat.n_pages_written
-		 - buf_pool->old_stat.n_pages_written) / time_elapsed;
+  pool_info->pages_written_rate =
+    (buf_pool->stat.n_pages_written
+     - buf_pool->old_stat.n_pages_written) / time_elapsed;
 
-	pool_info->n_page_get_delta = buf_pool->stat.n_page_gets
-				      - buf_pool->old_stat.n_page_gets;
+  pool_info->n_page_get_delta = buf_pool->stat.n_page_gets
+              - buf_pool->old_stat.n_page_gets;
 
-	if (pool_info->n_page_get_delta) {
-		pool_info->page_read_delta = buf_pool->stat.n_pages_read
-					     - buf_pool->old_stat.n_pages_read;
+  if (pool_info->n_page_get_delta) {
+    pool_info->page_read_delta = buf_pool->stat.n_pages_read
+               - buf_pool->old_stat.n_pages_read;
 
-		pool_info->young_making_delta =
-			buf_pool->stat.n_pages_made_young
-			- buf_pool->old_stat.n_pages_made_young;
+    pool_info->young_making_delta =
+      buf_pool->stat.n_pages_made_young
+      - buf_pool->old_stat.n_pages_made_young;
 
-		pool_info->not_young_making_delta =
-			buf_pool->stat.n_pages_not_made_young
-			- buf_pool->old_stat.n_pages_not_made_young;
-	}
-	pool_info->pages_readahead_rnd_rate =
-		 (buf_pool->stat.n_ra_pages_read_rnd
-		  - buf_pool->old_stat.n_ra_pages_read_rnd) / time_elapsed;
+    pool_info->not_young_making_delta =
+      buf_pool->stat.n_pages_not_made_young
+      - buf_pool->old_stat.n_pages_not_made_young;
+  }
+  pool_info->pages_readahead_rnd_rate =
+     (buf_pool->stat.n_ra_pages_read_rnd
+      - buf_pool->old_stat.n_ra_pages_read_rnd) / time_elapsed;
 
 
-	pool_info->pages_readahead_rate =
-		 (buf_pool->stat.n_ra_pages_read
-		  - buf_pool->old_stat.n_ra_pages_read) / time_elapsed;
+  pool_info->pages_readahead_rate =
+     (buf_pool->stat.n_ra_pages_read
+      - buf_pool->old_stat.n_ra_pages_read) / time_elapsed;
 
-	pool_info->pages_evicted_rate =
-		(buf_pool->stat.n_ra_pages_evicted
-		 - buf_pool->old_stat.n_ra_pages_evicted) / time_elapsed;
+  pool_info->pages_evicted_rate =
+    (buf_pool->stat.n_ra_pages_evicted
+     - buf_pool->old_stat.n_ra_pages_evicted) / time_elapsed;
 
-	pool_info->unzip_lru_len = UT_LIST_GET_LEN(buf_pool->unzip_LRU);
+  pool_info->unzip_lru_len = UT_LIST_GET_LEN(buf_pool->unzip_LRU);
 
-	pool_info->io_sum = buf_LRU_stat_sum.io;
+  pool_info->io_sum = buf_LRU_stat_sum.io;
 
-	pool_info->io_cur = buf_LRU_stat_cur.io;
+  pool_info->io_cur = buf_LRU_stat_cur.io;
 
-	pool_info->unzip_sum = buf_LRU_stat_sum.unzip;
+  pool_info->unzip_sum = buf_LRU_stat_sum.unzip;
 
-	pool_info->unzip_cur = buf_LRU_stat_cur.unzip;
+  pool_info->unzip_cur = buf_LRU_stat_cur.unzip;
 
-	buf_refresh_io_stats(buf_pool);
-	buf_pool_mutex_exit(buf_pool);
+  buf_refresh_io_stats(buf_pool);
+  buf_pool_mutex_exit(buf_pool);
 }
 
 /*********************************************************************//**
@@ -6991,92 +7094,92 @@ static
 void
 buf_print_io_instance(
 /*==================*/
-	buf_pool_info_t*pool_info,	/*!< in: buffer pool info */
-	FILE*		file)		/*!< in/out: buffer where to print */
+  buf_pool_info_t*pool_info,	/*!< in: buffer pool info */
+  FILE*		file)		/*!< in/out: buffer where to print */
 {
-	ut_ad(pool_info);
-
-	fprintf(file,
-		"Buffer pool size   " ULINTPF "\n"
-		"Free buffers       " ULINTPF "\n"
-		"Database pages     " ULINTPF "\n"
-		"Old database pages " ULINTPF "\n"
-		"Modified db pages  " ULINTPF "\n"
-		"Percent of dirty pages(LRU & free pages): %.3f\n"
-		"Max dirty pages percent: %.3f\n"
-		"Pending reads " ULINTPF "\n"
-		"Pending writes: LRU " ULINTPF ", flush list " ULINTPF
-		", single page " ULINTPF "\n",
-		pool_info->pool_size,
-		pool_info->free_list_len,
-		pool_info->lru_len,
-		pool_info->old_lru_len,
-		pool_info->flush_list_len,
-		(((double) pool_info->flush_list_len) /
-		  (pool_info->lru_len + pool_info->free_list_len + 1.0)) * 100.0,
-		srv_max_buf_pool_modified_pct,
-		pool_info->n_pend_reads,
-		pool_info->n_pending_flush_lru,
-		pool_info->n_pending_flush_list,
-		pool_info->n_pending_flush_single_page);
-
-	fprintf(file,
-		"Pages made young " ULINTPF ", not young " ULINTPF "\n"
-		"%.2f youngs/s, %.2f non-youngs/s\n"
-		"Pages read " ULINTPF ", created " ULINTPF
-		", written " ULINTPF "\n"
-		"%.2f reads/s, %.2f creates/s, %.2f writes/s\n",
-		pool_info->n_pages_made_young,
-		pool_info->n_pages_not_made_young,
-		pool_info->page_made_young_rate,
-		pool_info->page_not_made_young_rate,
-		pool_info->n_pages_read,
-		pool_info->n_pages_created,
-		pool_info->n_pages_written,
-		pool_info->pages_read_rate,
-		pool_info->pages_created_rate,
-		pool_info->pages_written_rate);
-
-	if (pool_info->n_page_get_delta) {
-		double hit_rate = double(pool_info->page_read_delta)
-			/ pool_info->n_page_get_delta;
-
-		if (hit_rate > 1) {
-			hit_rate = 1;
-		}
-
-		fprintf(file,
-			"Buffer pool hit rate " ULINTPF " / 1000,"
-			" young-making rate " ULINTPF " / 1000 not "
-			ULINTPF " / 1000\n",
-			ulint(1000 * (1 - hit_rate)),
-			ulint(1000 * double(pool_info->young_making_delta)
-			      / pool_info->n_page_get_delta),
-			ulint(1000 * double(pool_info->not_young_making_delta)
-			      / pool_info->n_page_get_delta));
-	} else {
-		fputs("No buffer pool page gets since the last printout\n",
-		      file);
-	}
-
-	/* Statistics about read ahead algorithm */
-	fprintf(file, "Pages read ahead %.2f/s,"
-		" evicted without access %.2f/s,"
-		" Random read ahead %.2f/s\n",
-
-		pool_info->pages_readahead_rate,
-		pool_info->pages_evicted_rate,
-		pool_info->pages_readahead_rnd_rate);
-
-	/* Print some values to help us with visualizing what is
-	happening with LRU eviction. */
-	fprintf(file,
-		"LRU len: " ULINTPF ", unzip_LRU len: " ULINTPF "\n"
-		"I/O sum[" ULINTPF "]:cur[" ULINTPF "], "
-		"unzip sum[" ULINTPF "]:cur[" ULINTPF "]\n",
-		pool_info->lru_len, pool_info->unzip_lru_len,
-		pool_info->io_sum, pool_info->io_cur,
-		pool_info->unzip_sum, pool_info->unzip_cur);
+  ut_ad(pool_info);
+
+  fprintf(file,
+    "Buffer pool size   " ULINTPF "\n"
+    "Free buffers       " ULINTPF "\n"
+    "Database pages     " ULINTPF "\n"
+    "Old database pages " ULINTPF "\n"
+    "Modified db pages  " ULINTPF "\n"
+    "Percent of dirty pages(LRU & free pages): %.3f\n"
+    "Max dirty pages percent: %.3f\n"
+    "Pending reads " ULINTPF "\n"
+    "Pending writes: LRU " ULINTPF ", flush list " ULINTPF
+    ", single page " ULINTPF "\n",
+    pool_info->pool_size,
+    pool_info->free_list_len,
+    pool_info->lru_len,
+    pool_info->old_lru_len,
+    pool_info->flush_list_len,
+    (((double) pool_info->flush_list_len) /
+      (pool_info->lru_len + pool_info->free_list_len + 1.0)) * 100.0,
+    srv_max_buf_pool_modified_pct,
+    pool_info->n_pend_reads,
+    pool_info->n_pending_flush_lru,
+    pool_info->n_pending_flush_list,
+    pool_info->n_pending_flush_single_page);
+
+  fprintf(file,
+    "Pages made young " ULINTPF ", not young " ULINTPF "\n"
+    "%.2f youngs/s, %.2f non-youngs/s\n"
+    "Pages read " ULINTPF ", created " ULINTPF
+    ", written " ULINTPF "\n"
+    "%.2f reads/s, %.2f creates/s, %.2f writes/s\n",
+    pool_info->n_pages_made_young,
+    pool_info->n_pages_not_made_young,
+    pool_info->page_made_young_rate,
+    pool_info->page_not_made_young_rate,
+    pool_info->n_pages_read,
+    pool_info->n_pages_created,
+    pool_info->n_pages_written,
+    pool_info->pages_read_rate,
+    pool_info->pages_created_rate,
+    pool_info->pages_written_rate);
+
+  if (pool_info->n_page_get_delta) {
+    double hit_rate = double(pool_info->page_read_delta)
+      / pool_info->n_page_get_delta;
+
+    if (hit_rate > 1) {
+      hit_rate = 1;
+    }
+
+    fprintf(file,
+      "Buffer pool hit rate " ULINTPF " / 1000,"
+      " young-making rate " ULINTPF " / 1000 not "
+      ULINTPF " / 1000\n",
+      ulint(1000 * (1 - hit_rate)),
+      ulint(1000 * double(pool_info->young_making_delta)
+            / pool_info->n_page_get_delta),
+      ulint(1000 * double(pool_info->not_young_making_delta)
+            / pool_info->n_page_get_delta));
+  } else {
+    fputs("No buffer pool page gets since the last printout\n",
+          file);
+  }
+
+  /* Statistics about read ahead algorithm */
+  fprintf(file, "Pages read ahead %.2f/s,"
+    " evicted without access %.2f/s,"
+    " Random read ahead %.2f/s\n",
+
+    pool_info->pages_readahead_rate,
+    pool_info->pages_evicted_rate,
+    pool_info->pages_readahead_rnd_rate);
+
+  /* Print some values to help us with visualizing what is
+  happening with LRU eviction. */
+  fprintf(file,
+    "LRU len: " ULINTPF ", unzip_LRU len: " ULINTPF "\n"
+    "I/O sum[" ULINTPF "]:cur[" ULINTPF "], "
+    "unzip sum[" ULINTPF "]:cur[" ULINTPF "]\n",
+    pool_info->lru_len, pool_info->unzip_lru_len,
+    pool_info->io_sum, pool_info->io_cur,
+    pool_info->unzip_sum, pool_info->unzip_cur);
 }
 
 /*********************************************************************//**
@@ -7084,61 +7187,61 @@ Prints info of the buffer i/o. */
 void
 buf_print_io(
 /*=========*/
-	FILE*	file)	/*!< in/out: buffer where to print */
+  FILE*	file)	/*!< in/out: buffer where to print */
 {
-	buf_pool_info_t*	pool_info;
-	buf_pool_info_t*	pool_info_total;
-
-	/* If srv_buf_pool_instances is greater than 1, allocate
-	one extra buf_pool_info_t, the last one stores
-	aggregated/total values from all pools */
-	if (srv_buf_pool_instances > 1) {
-		pool_info = (buf_pool_info_t*) ut_zalloc_nokey((
-			srv_buf_pool_instances + 1) * sizeof *pool_info);
-
-		pool_info_total = &pool_info[srv_buf_pool_instances];
-	} else {
-		ut_a(srv_buf_pool_instances == 1);
-
-		pool_info_total = pool_info =
-			static_cast<buf_pool_info_t*>(
-				ut_zalloc_nokey(sizeof *pool_info));
-	}
-
-	for (uint i = 0; i < srv_buf_pool_instances; i++) {
-		buf_pool_t*	buf_pool;
-
-		buf_pool = buf_pool_from_array(i);
-
-		/* Fetch individual buffer pool info and calculate
-		aggregated stats along the way */
-		buf_stats_get_pool_info(buf_pool, i, pool_info);
-
-		/* If we have more than one buffer pool, store
-		the aggregated stats  */
-		if (srv_buf_pool_instances > 1) {
-			buf_stats_aggregate_pool_info(pool_info_total,
-						      &pool_info[i]);
-		}
-	}
-
-	/* Print the aggreate buffer pool info */
-	buf_print_io_instance(pool_info_total, file);
-
-	/* If there are more than one buffer pool, print each individual pool
-	info */
-	if (srv_buf_pool_instances > 1) {
-		fputs("----------------------\n"
-		"INDIVIDUAL BUFFER POOL INFO\n"
-		"----------------------\n", file);
-
-		for (uint i = 0; i < srv_buf_pool_instances; i++) {
-			fprintf(file, "---BUFFER POOL %u\n", i);
-			buf_print_io_instance(&pool_info[i], file);
-		}
-	}
-
-	ut_free(pool_info);
+  buf_pool_info_t*	pool_info;
+  buf_pool_info_t*	pool_info_total;
+
+  /* If srv_buf_pool_instances is greater than 1, allocate
+  one extra buf_pool_info_t, the last one stores
+  aggregated/total values from all pools */
+  if (srv_buf_pool_instances > 1) {
+    pool_info = (buf_pool_info_t*) ut_zalloc_nokey((
+      srv_buf_pool_instances + 1) * sizeof *pool_info);
+
+    pool_info_total = &pool_info[srv_buf_pool_instances];
+  } else {
+    ut_a(srv_buf_pool_instances == 1);
+
+    pool_info_total = pool_info =
+      static_cast<buf_pool_info_t*>(
+        ut_zalloc_nokey(sizeof *pool_info));
+  }
+
+  for (uint i = 0; i < srv_buf_pool_instances; i++) {
+    buf_pool_t*	buf_pool;
+
+    buf_pool = buf_pool_from_array(i);
+
+    /* Fetch individual buffer pool info and calculate
+    aggregated stats along the way */
+    buf_stats_get_pool_info(buf_pool, i, pool_info);
+
+    /* If we have more than one buffer pool, store
+    the aggregated stats  */
+    if (srv_buf_pool_instances > 1) {
+      buf_stats_aggregate_pool_info(pool_info_total,
+                  &pool_info[i]);
+    }
+  }
+
+  /* Print the aggreate buffer pool info */
+  buf_print_io_instance(pool_info_total, file);
+
+  /* If there are more than one buffer pool, print each individual pool
+  info */
+  if (srv_buf_pool_instances > 1) {
+    fputs("----------------------\n"
+    "INDIVIDUAL BUFFER POOL INFO\n"
+    "----------------------\n", file);
+
+    for (uint i = 0; i < srv_buf_pool_instances; i++) {
+      fprintf(file, "---BUFFER POOL %u\n", i);
+      buf_print_io_instance(&pool_info[i], file);
+    }
+  }
+
+  ut_free(pool_info);
 }
 
 /**********************************************************************//**
@@ -7147,13 +7250,13 @@ void
 buf_refresh_io_stats_all(void)
 /*==========================*/
 {
-	for (ulint i = 0; i < srv_buf_pool_instances; i++) {
-		buf_pool_t*	buf_pool;
+  for (ulint i = 0; i < srv_buf_pool_instances; i++) {
+    buf_pool_t*	buf_pool;
 
-		buf_pool = buf_pool_from_array(i);
+    buf_pool = buf_pool_from_array(i);
 
-		buf_refresh_io_stats(buf_pool);
-	}
+    buf_refresh_io_stats(buf_pool);
+  }
 }
 
 /**********************************************************************//**
@@ -7163,17 +7266,17 @@ ibool
 buf_all_freed(void)
 /*===============*/
 {
-	for (ulint i = 0; i < srv_buf_pool_instances; i++) {
-		buf_pool_t*	buf_pool;
+  for (ulint i = 0; i < srv_buf_pool_instances; i++) {
+    buf_pool_t*	buf_pool;
 
-		buf_pool = buf_pool_from_array(i);
+    buf_pool = buf_pool_from_array(i);
 
-		if (!buf_all_freed_instance(buf_pool)) {
-			return(FALSE);
-		}
-	}
+    if (!buf_all_freed_instance(buf_pool)) {
+      return(FALSE);
+    }
+  }
 
-	return(TRUE);
+  return(TRUE);
 }
 
 /** Verify that post encryption checksum match with the calculated checksum.
@@ -7183,12 +7286,12 @@ This function should be called only if tablespace contains crypt data metadata.
 @return true if true if page is encrypted and OK, false otherwise */
 bool buf_page_verify_crypt_checksum(const byte* page, ulint fsp_flags)
 {
-	if (!fil_space_t::full_crc32(fsp_flags)) {
-		return fil_space_verify_crypt_checksum(
-			page, fil_space_t::zip_size(fsp_flags));
-	}
+  if (!fil_space_t::full_crc32(fsp_flags)) {
+    return fil_space_verify_crypt_checksum(
+      page, fil_space_t::zip_size(fsp_flags));
+  }
 
-	return !buf_page_is_corrupted(true, page, fsp_flags);
+  return !buf_page_is_corrupted(true, page, fsp_flags);
 }
 
 /*********************************************************************//**
@@ -7199,26 +7302,26 @@ ulint
 buf_pool_check_no_pending_io(void)
 /*==============================*/
 {
-	ulint		i;
-	ulint		pending_io = 0;
+  ulint		i;
+  ulint		pending_io = 0;
 
-	buf_pool_mutex_enter_all();
+  buf_pool_mutex_enter_all();
 
-	for (i = 0; i < srv_buf_pool_instances; i++) {
-		const buf_pool_t*	buf_pool;
+  for (i = 0; i < srv_buf_pool_instances; i++) {
+    const buf_pool_t*	buf_pool;
 
-		buf_pool = buf_pool_from_array(i);
+    buf_pool = buf_pool_from_array(i);
 
-		pending_io += buf_pool->n_pend_reads
-			      + buf_pool->n_flush[BUF_FLUSH_LRU]
-			      + buf_pool->n_flush[BUF_FLUSH_SINGLE_PAGE]
-			      + buf_pool->n_flush[BUF_FLUSH_LIST];
+    pending_io += buf_pool->n_pend_reads
+            + buf_pool->n_flush[BUF_FLUSH_LRU]
+            + buf_pool->n_flush[BUF_FLUSH_SINGLE_PAGE]
+            + buf_pool->n_flush[BUF_FLUSH_LIST];
 
-	}
+  }
 
-	buf_pool_mutex_exit_all();
+  buf_pool_mutex_exit_all();
 
-	return(pending_io);
+  return(pending_io);
 }
 
 /** Print the given page_id_t object.
@@ -7227,12 +7330,12 @@ buf_pool_check_no_pending_io(void)
 @return the output stream */
 std::ostream&
 operator<<(
-	std::ostream&		out,
-	const page_id_t		page_id)
+  std::ostream&		out,
+  const page_id_t		page_id)
 {
-	out << "[page id: space=" << page_id.m_space
-		<< ", page number=" << page_id.m_page_no << "]";
-	return(out);
+  out << "[page id: space=" << page_id.m_space
+    << ", page number=" << page_id.m_page_no << "]";
+  return(out);
 }
 
 /** Print the given buf_pool_t object.
@@ -7241,26 +7344,26 @@ operator<<(
 @return the output stream */
 std::ostream&
 operator<<(
-	std::ostream&		out,
-	const buf_pool_t&	buf_pool)
+  std::ostream&		out,
+  const buf_pool_t&	buf_pool)
 {
-	out << "[buffer pool instance: "
-		<< "buf_pool size=" << buf_pool.curr_size
-		<< ", database pages=" << UT_LIST_GET_LEN(buf_pool.LRU)
-		<< ", free pages=" << UT_LIST_GET_LEN(buf_pool.free)
-		<< ", modified database pages="
-		<< UT_LIST_GET_LEN(buf_pool.flush_list)
-		<< ", n pending decompressions=" << buf_pool.n_pend_unzip
-		<< ", n pending reads=" << buf_pool.n_pend_reads
-		<< ", n pending flush LRU=" << buf_pool.n_flush[BUF_FLUSH_LRU]
-		<< " list=" << buf_pool.n_flush[BUF_FLUSH_LIST]
-		<< " single page=" << buf_pool.n_flush[BUF_FLUSH_SINGLE_PAGE]
-		<< ", pages made young=" << buf_pool.stat.n_pages_made_young
-		<< ", not young=" << buf_pool.stat.n_pages_not_made_young
-		<< ", pages read=" << buf_pool.stat.n_pages_read
-		<< ", created=" << buf_pool.stat.n_pages_created
-		<< ", written=" << buf_pool.stat.n_pages_written << "]";
-	return(out);
+  out << "[buffer pool instance: "
+    << "buf_pool size=" << buf_pool.curr_size
+    << ", database pages=" << UT_LIST_GET_LEN(buf_pool.LRU)
+    << ", free pages=" << UT_LIST_GET_LEN(buf_pool.free)
+    << ", modified database pages="
+    << UT_LIST_GET_LEN(buf_pool.flush_list)
+    << ", n pending decompressions=" << buf_pool.n_pend_unzip
+    << ", n pending reads=" << buf_pool.n_pend_reads
+    << ", n pending flush LRU=" << buf_pool.n_flush[BUF_FLUSH_LRU]
+    << " list=" << buf_pool.n_flush[BUF_FLUSH_LIST]
+    << " single page=" << buf_pool.n_flush[BUF_FLUSH_SINGLE_PAGE]
+    << ", pages made young=" << buf_pool.stat.n_pages_made_young
+    << ", not young=" << buf_pool.stat.n_pages_not_made_young
+    << ", pages read=" << buf_pool.stat.n_pages_read
+    << ", created=" << buf_pool.stat.n_pages_created
+    << ", written=" << buf_pool.stat.n_pages_written << "]";
+  return(out);
 }
 
 /** Encrypt a buffer of temporary tablespace
@@ -7269,29 +7372,29 @@ operator<<(
 @param[in,out]	dst_frame	Output buffer
 @return encrypted buffer or NULL */
 static byte* buf_tmp_page_encrypt(
-	ulint	offset,
-	byte*	src_frame,
-	byte*	dst_frame)
+  ulint	offset,
+  byte*	src_frame,
+  byte*	dst_frame)
 {
-	/* Calculate the start offset in a page */
-	uint srclen = srv_page_size - (FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION
-				       + FIL_PAGE_FCRC32_CHECKSUM);
-	const byte* src = src_frame + FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION;
-	byte* dst = dst_frame + FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION;
+  /* Calculate the start offset in a page */
+  uint srclen = srv_page_size - (FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION
+               + FIL_PAGE_FCRC32_CHECKSUM);
+  const byte* src = src_frame + FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION;
+  byte* dst = dst_frame + FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION;
 
-	memcpy(dst_frame, src_frame, FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION);
+  memcpy(dst_frame, src_frame, FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION);
 
-	if (!log_tmp_block_encrypt(src, srclen, dst, (offset * srv_page_size),
-				   true)) {
-		return NULL;
-	}
+  if (!log_tmp_block_encrypt(src, srclen, dst, (offset * srv_page_size),
+           true)) {
+    return NULL;
+  }
 
-	const ulint payload = srv_page_size - FIL_PAGE_FCRC32_CHECKSUM;
-	mach_write_to_4(dst_frame + payload, ut_crc32(dst_frame, payload));
+  const ulint payload = srv_page_size - FIL_PAGE_FCRC32_CHECKSUM;
+  mach_write_to_4(dst_frame + payload, ut_crc32(dst_frame, payload));
 
-	srv_stats.pages_encrypted.inc();
-	srv_stats.n_temp_blocks_encrypted.inc();
-	return dst_frame;
+  srv_stats.pages_encrypted.inc();
+  srv_stats.n_temp_blocks_encrypted.inc();
+  return dst_frame;
 }
 
 /** Encryption and page_compression hook that is called just before
@@ -7304,154 +7407,154 @@ a page is written to disk.
 UNIV_INTERN
 byte*
 buf_page_encrypt(
-	fil_space_t*	space,
-	buf_page_t*	bpage,
-	byte*		src_frame)
+  fil_space_t*	space,
+  buf_page_t*	bpage,
+  byte*		src_frame)
 {
-	ut_ad(space->id == bpage->id.space());
-	bpage->real_size = srv_page_size;
-
-	ut_d(fil_page_type_validate(space, src_frame));
-
-	switch (bpage->id.page_no()) {
-	case 0:
-		/* Page 0 of a tablespace is not encrypted/compressed */
-		return src_frame;
-	case TRX_SYS_PAGE_NO:
-		if (bpage->id.space() == TRX_SYS_SPACE) {
-			/* don't encrypt/compress page as it contains
-			address to dblwr buffer */
-			return src_frame;
-		}
-	}
-
-	fil_space_crypt_t* crypt_data = space->crypt_data;
-
-	bool encrypted, page_compressed;
-
-	if (space->purpose == FIL_TYPE_TEMPORARY) {
-		ut_ad(!crypt_data);
-		encrypted = innodb_encrypt_temporary_tables;
-		page_compressed = false;
-	} else {
-		encrypted = crypt_data
-			&& !crypt_data->not_encrypted()
-			&& crypt_data->type != CRYPT_SCHEME_UNENCRYPTED
-			&& (!crypt_data->is_default_encryption()
-			    || srv_encrypt_tables);
-		page_compressed = space->is_compressed();
-	}
-
-	if (!encrypted && !page_compressed) {
-		/* No need to encrypt or page compress the page.
-		Clear key-version & crypt-checksum. */
-		if (space->full_crc32()) {
-			memset(src_frame + FIL_PAGE_FCRC32_KEY_VERSION, 0, 4);
-		} else {
-			memset(src_frame + FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION,
-			       0, 8);
-		}
-
-		return src_frame;
-	}
-
-	ut_ad(!bpage->zip_size() || !page_compressed);
-	buf_pool_t* buf_pool = buf_pool_from_bpage(bpage);
-	/* Find free slot from temporary memory array */
-	buf_tmp_buffer_t* slot = buf_pool_reserve_tmp_slot(buf_pool);
-	slot->out_buf = NULL;
-	bpage->slot = slot;
-
-	buf_tmp_reserve_crypt_buf(slot);
-	byte *dst_frame = slot->crypt_buf;
-	const bool full_crc32 = space->full_crc32();
-
-	if (full_crc32) {
-		/* Write LSN for the full crc32 checksum before
-		encryption. Because lsn is one of the input for encryption. */
-		mach_write_to_8(src_frame + FIL_PAGE_LSN,
-				bpage->newest_modification);
-		if (!page_compressed) {
-			mach_write_to_4(
-				src_frame + srv_page_size - FIL_PAGE_FCRC32_END_LSN,
-				(ulint) bpage->newest_modification);
-		}
-	}
-
-	if (!page_compressed) {
+  ut_ad(space->id == bpage->id.space());
+  bpage->real_size = srv_page_size;
+
+  ut_d(fil_page_type_validate(space, src_frame));
+
+  switch (bpage->id.page_no()) {
+  case 0:
+    /* Page 0 of a tablespace is not encrypted/compressed */
+    return src_frame;
+  case TRX_SYS_PAGE_NO:
+    if (bpage->id.space() == TRX_SYS_SPACE) {
+      /* don't encrypt/compress page as it contains
+      address to dblwr buffer */
+      return src_frame;
+    }
+  }
+
+  fil_space_crypt_t* crypt_data = space->crypt_data;
+
+  bool encrypted, page_compressed;
+
+  if (space->purpose == FIL_TYPE_TEMPORARY) {
+    ut_ad(!crypt_data);
+    encrypted = innodb_encrypt_temporary_tables;
+    page_compressed = false;
+  } else {
+    encrypted = crypt_data
+      && !crypt_data->not_encrypted()
+      && crypt_data->type != CRYPT_SCHEME_UNENCRYPTED
+      && (!crypt_data->is_default_encryption()
+          || srv_encrypt_tables);
+    page_compressed = space->is_compressed();
+  }
+
+  if (!encrypted && !page_compressed) {
+    /* No need to encrypt or page compress the page.
+    Clear key-version & crypt-checksum. */
+    if (space->full_crc32()) {
+      memset(src_frame + FIL_PAGE_FCRC32_KEY_VERSION, 0, 4);
+    } else {
+      memset(src_frame + FIL_PAGE_FILE_FLUSH_LSN_OR_KEY_VERSION,
+             0, 8);
+    }
+
+    return src_frame;
+  }
+
+  ut_ad(!bpage->zip_size() || !page_compressed);
+  buf_pool_t* buf_pool = buf_pool_from_bpage(bpage);
+  /* Find free slot from temporary memory array */
+  buf_tmp_buffer_t* slot = buf_pool_reserve_tmp_slot(buf_pool);
+  slot->out_buf = NULL;
+  bpage->slot = slot;
+
+  buf_tmp_reserve_crypt_buf(slot);
+  byte *dst_frame = slot->crypt_buf;
+  const bool full_crc32 = space->full_crc32();
+
+  if (full_crc32) {
+    /* Write LSN for the full crc32 checksum before
+    encryption. Because lsn is one of the input for encryption. */
+    mach_write_to_8(src_frame + FIL_PAGE_LSN,
+        bpage->newest_modification);
+    if (!page_compressed) {
+      mach_write_to_4(
+        src_frame + srv_page_size - FIL_PAGE_FCRC32_END_LSN,
+        (ulint) bpage->newest_modification);
+    }
+  }
+
+  if (!page_compressed) {
 not_compressed:
-		byte* tmp;
-		if (space->purpose == FIL_TYPE_TEMPORARY) {
-			/* Encrypt temporary tablespace page content */
-			tmp = buf_tmp_page_encrypt(bpage->id.page_no(),
-						   src_frame, dst_frame);
-		} else {
-			/* Encrypt page content */
-			tmp = fil_space_encrypt(
-					space, bpage->id.page_no(),
-					bpage->newest_modification,
-					src_frame, dst_frame);
-		}
-
-		bpage->real_size = srv_page_size;
-		slot->out_buf = dst_frame = tmp;
-
-		ut_d(fil_page_type_validate(space, tmp));
-	} else {
-		ut_ad(space->purpose != FIL_TYPE_TEMPORARY);
-		/* First we compress the page content */
-		buf_tmp_reserve_compression_buf(slot);
-		byte* tmp = slot->comp_buf;
-		ulint out_len = fil_page_compress(
-			src_frame, tmp, space->flags,
-			fil_space_get_block_size(space, bpage->id.page_no()),
-			encrypted);
-
-		if (!out_len) {
-			goto not_compressed;
-		}
-
-		bpage->real_size = out_len;
-
-		if (full_crc32) {
-			ut_d(bool compressed = false);
-			out_len = buf_page_full_crc32_size(tmp,
+    byte* tmp;
+    if (space->purpose == FIL_TYPE_TEMPORARY) {
+      /* Encrypt temporary tablespace page content */
+      tmp = buf_tmp_page_encrypt(bpage->id.page_no(),
+               src_frame, dst_frame);
+    } else {
+      /* Encrypt page content */
+      tmp = fil_space_encrypt(
+          space, bpage->id.page_no(),
+          bpage->newest_modification,
+          src_frame, dst_frame);
+    }
+
+    bpage->real_size = srv_page_size;
+    slot->out_buf = dst_frame = tmp;
+
+    ut_d(fil_page_type_validate(space, tmp));
+  } else {
+    ut_ad(space->purpose != FIL_TYPE_TEMPORARY);
+    /* First we compress the page content */
+    buf_tmp_reserve_compression_buf(slot);
+    byte* tmp = slot->comp_buf;
+    ulint out_len = fil_page_compress(
+      src_frame, tmp, space->flags,
+      fil_space_get_block_size(space, bpage->id.page_no()),
+      encrypted);
+
+    if (!out_len) {
+      goto not_compressed;
+    }
+
+    bpage->real_size = out_len;
+
+    if (full_crc32) {
+      ut_d(bool compressed = false);
+      out_len = buf_page_full_crc32_size(tmp,
 #ifdef UNIV_DEBUG
-							   &compressed,
+                 &compressed,
 #else
-							   NULL,
+                 NULL,
 #endif
-							   NULL);
-			ut_ad(compressed);
-		}
-
-		/* Workaround for MDEV-15527. */
-		memset(tmp + out_len, 0 , srv_page_size - out_len);
-		ut_d(fil_page_type_validate(space, tmp));
-
-		if (encrypted) {
-			/* And then we encrypt the page content */
-			tmp = fil_space_encrypt(space,
-						bpage->id.page_no(),
-						bpage->newest_modification,
-						tmp,
-						dst_frame);
-		}
-
-		if (full_crc32) {
-			compile_time_assert(FIL_PAGE_FCRC32_CHECKSUM == 4);
-			mach_write_to_4(tmp + out_len - 4,
-					ut_crc32(tmp, out_len - 4));
-			ut_ad(!buf_page_is_corrupted(true, tmp, space->flags));
-		}
-
-		slot->out_buf = dst_frame = tmp;
-	}
-
-	ut_d(fil_page_type_validate(space, dst_frame));
-
-	// return dst_frame which will be written
-	return dst_frame;
+                 NULL);
+      ut_ad(compressed);
+    }
+
+    /* Workaround for MDEV-15527. */
+    memset(tmp + out_len, 0 , srv_page_size - out_len);
+    ut_d(fil_page_type_validate(space, tmp));
+
+    if (encrypted) {
+      /* And then we encrypt the page content */
+      tmp = fil_space_encrypt(space,
+            bpage->id.page_no(),
+            bpage->newest_modification,
+            tmp,
+            dst_frame);
+    }
+
+    if (full_crc32) {
+      compile_time_assert(FIL_PAGE_FCRC32_CHECKSUM == 4);
+      mach_write_to_4(tmp + out_len - 4,
+          ut_crc32(tmp, out_len - 4));
+      ut_ad(!buf_page_is_corrupted(true, tmp, space->flags));
+    }
+
+    slot->out_buf = dst_frame = tmp;
+  }
+
+  ut_d(fil_page_type_validate(space, dst_frame));
+
+  // return dst_frame which will be written
+  return dst_frame;
 }
 
 /**
@@ -7460,9 +7563,9 @@ Should we punch hole to deallocate unused portion of the page.
 @return true if punch hole should be used, false if not */
 bool
 buf_page_should_punch_hole(
-	const buf_page_t* bpage)
+  const buf_page_t* bpage)
 {
-	return bpage->real_size != bpage->physical_size();
+  return bpage->real_size != bpage->physical_size();
 }
 
 /**
@@ -7472,9 +7575,9 @@ Calculate the length of trim (punch_hole) operation.
 @return length of the trim or zero. */
 ulint
 buf_page_get_trim_length(
-	const buf_page_t*	bpage,
-	ulint			write_length)
+  const buf_page_t*	bpage,
+  ulint			write_length)
 {
-	return bpage->physical_size() - write_length;
+  return bpage->physical_size() - write_length;
 }
 #endif /* !UNIV_INNOCHECKSUM */
diff --git storage/innobase/include/buf0buf.h storage/innobase/include/buf0buf.h
index 332b6d93aeb..bf12396cfb8 100644
--- storage/innobase/include/buf0buf.h
+++ storage/innobase/include/buf0buf.h
@@ -33,6 +33,8 @@ Created 11/5/1995 Heikki Tuuri
 #include "fil0fil.h"
 #include "mtr0types.h"
 #include "buf0types.h"
+#include "my_pthread.h"
+#include <thread>
 #ifndef UNIV_INNOCHECKSUM
 #include "hash0hash.h"
 #include "ut0byte.h"
diff --git storage/innobase/srv/srv0start.cc storage/innobase/srv/srv0start.cc
index 311574a4086..9fdfcefa19f 100644
--- storage/innobase/srv/srv0start.cc
+++ storage/innobase/srv/srv0start.cc
@@ -143,23 +143,23 @@ UNIV_INTERN bool	srv_log_files_created;
 determine which threads need to be stopped if we need to abort during
 the initialisation step. */
 enum srv_start_state_t {
-	/** No thread started */
-	SRV_START_STATE_NONE = 0,		/*!< No thread started */
-	/** lock_wait_timeout_thread started */
-	SRV_START_STATE_LOCK_SYS = 1,		/*!< Started lock-timeout
-						thread. */
-	/** buf_flush_page_cleaner_coordinator,
-	buf_flush_page_cleaner_worker started */
-	SRV_START_STATE_IO = 2,
-	/** srv_error_monitor_thread, srv_monitor_thread started */
-	SRV_START_STATE_MONITOR = 4,
-	/** srv_master_thread started */
-	SRV_START_STATE_MASTER = 8,
-	/** srv_purge_coordinator_thread, srv_worker_thread started */
-	SRV_START_STATE_PURGE = 16,
-	/** fil_crypt_thread, btr_defragment_thread started
-	(all background threads that can generate redo log but not undo log */
-	SRV_START_STATE_REDO = 32
+  /** No thread started */
+  SRV_START_STATE_NONE = 0,		/*!< No thread started */
+  /** lock_wait_timeout_thread started */
+  SRV_START_STATE_LOCK_SYS = 1,		/*!< Started lock-timeout
+            thread. */
+  /** buf_flush_page_cleaner_coordinator,
+  buf_flush_page_cleaner_worker started */
+  SRV_START_STATE_IO = 2,
+  /** srv_error_monitor_thread, srv_monitor_thread started */
+  SRV_START_STATE_MONITOR = 4,
+  /** srv_master_thread started */
+  SRV_START_STATE_MASTER = 8,
+  /** srv_purge_coordinator_thread, srv_worker_thread started */
+  SRV_START_STATE_PURGE = 16,
+  /** fil_crypt_thread, btr_defragment_thread started
+  (all background threads that can generate redo log but not undo log */
+  SRV_START_STATE_REDO = 32
 };
 
 /** Track server thrd starting phases */
@@ -213,14 +213,14 @@ mysql_pfs_key_t	srv_worker_thread_key;
 performance schema. */
 static PSI_stage_info*	srv_stages[] =
 {
-	&srv_stage_alter_table_end,
-	&srv_stage_alter_table_flush,
-	&srv_stage_alter_table_insert,
-	&srv_stage_alter_table_log_index,
-	&srv_stage_alter_table_log_table,
-	&srv_stage_alter_table_merge_sort,
-	&srv_stage_alter_table_read_pk_internal_sort,
-	&srv_stage_buffer_pool_load,
+  &srv_stage_alter_table_end,
+  &srv_stage_alter_table_flush,
+  &srv_stage_alter_table_insert,
+  &srv_stage_alter_table_log_index,
+  &srv_stage_alter_table_log_table,
+  &srv_stage_alter_table_merge_sort,
+  &srv_stage_alter_table_read_pk_internal_sort,
+  &srv_stage_buffer_pool_load,
 };
 #endif /* HAVE_PSI_STAGE_INTERFACE */
 
@@ -231,48 +231,48 @@ static
 bool
 srv_file_check_mode(
 /*================*/
-	const char*	name)		/*!< in: filename to check */
+  const char*	name)		/*!< in: filename to check */
 {
-	os_file_stat_t	stat;
+  os_file_stat_t	stat;
 
-	memset(&stat, 0x0, sizeof(stat));
+  memset(&stat, 0x0, sizeof(stat));
 
-	dberr_t		err = os_file_get_status(
-		name, &stat, true, srv_read_only_mode);
+  dberr_t		err = os_file_get_status(
+    name, &stat, true, srv_read_only_mode);
 
-	if (err == DB_FAIL) {
-		ib::error() << "os_file_get_status() failed on '" << name
-			<< "'. Can't determine file permissions.";
-		return(false);
+  if (err == DB_FAIL) {
+    ib::error() << "os_file_get_status() failed on '" << name
+      << "'. Can't determine file permissions.";
+    return(false);
 
-	} else if (err == DB_SUCCESS) {
+  } else if (err == DB_SUCCESS) {
 
-		/* Note: stat.rw_perm is only valid of files */
+    /* Note: stat.rw_perm is only valid of files */
 
-		if (stat.type == OS_FILE_TYPE_FILE) {
+    if (stat.type == OS_FILE_TYPE_FILE) {
 
-			if (!stat.rw_perm) {
-				const char*	mode = srv_read_only_mode
-					? "read" : "read-write";
-				ib::error() << name << " can't be opened in "
-					<< mode << " mode.";
-				return(false);
-			}
-		} else {
-			/* Not a regular file, bail out. */
-			ib::error() << "'" << name << "' not a regular file.";
+      if (!stat.rw_perm) {
+        const char*	mode = srv_read_only_mode
+          ? "read" : "read-write";
+        ib::error() << name << " can't be opened in "
+          << mode << " mode.";
+        return(false);
+      }
+    } else {
+      /* Not a regular file, bail out. */
+      ib::error() << "'" << name << "' not a regular file.";
 
-			return(false);
-		}
-	} else {
+      return(false);
+    }
+  } else {
 
-		/* This is OK. If the file create fails on RO media, there
-		is nothing we can do. */
+    /* This is OK. If the file create fails on RO media, there
+    is nothing we can do. */
 
-		ut_a(err == DB_NOT_FOUND);
-	}
+    ut_a(err == DB_NOT_FOUND);
+  }
 
-	return(true);
+  return(true);
 }
 
 /********************************************************************//**
@@ -282,56 +282,56 @@ extern "C"
 os_thread_ret_t
 DECLARE_THREAD(io_handler_thread)(
 /*==============================*/
-	void*	arg)	/*!< in: pointer to the number of the segment in
-			the aio array */
+  void*	arg)	/*!< in: pointer to the number of the segment in
+      the aio array */
 {
-	ulint	segment;
+  ulint	segment;
 
-	segment = *((ulint*) arg);
+  segment = *((ulint*) arg);
 
 #ifdef UNIV_DEBUG_THREAD_CREATION
-	ib::info() << "Io handler thread " << segment << " starts, id "
-		<< os_thread_pf(os_thread_get_curr_id());
+  ib::info() << "Io handler thread " << segment << " starts, id "
+    << os_thread_pf(os_thread_get_curr_id());
 #endif
 
-	/* For read only mode, we don't need ibuf and log I/O thread.
-	Please see srv_start() */
-	ulint   start = (srv_read_only_mode) ? 0 : 2;
-
-	if (segment < start) {
-		if (segment == 0) {
-			pfs_register_thread(io_ibuf_thread_key);
-		} else {
-			ut_ad(segment == 1);
-			pfs_register_thread(io_log_thread_key);
-		}
-	} else if (segment >= start
-		   && segment < (start + srv_n_read_io_threads)) {
-			pfs_register_thread(io_read_thread_key);
-
-	} else if (segment >= (start + srv_n_read_io_threads)
-		   && segment < (start + srv_n_read_io_threads
-				 + srv_n_write_io_threads)) {
-		pfs_register_thread(io_write_thread_key);
-
-	} else {
-		pfs_register_thread(io_handler_thread_key);
-	}
-
-	while (srv_shutdown_state != SRV_SHUTDOWN_EXIT_THREADS
-	       || buf_page_cleaner_is_active
-	       || !os_aio_all_slots_free()) {
-		fil_aio_wait(segment);
-	}
-
-	/* We count the number of threads in os_thread_exit(). A created
-	thread should always use that to exit and not use return() to exit.
-	The thread actually never comes here because it is exited in an
-	os_event_wait(). */
-
-	os_thread_exit();
-
-	OS_THREAD_DUMMY_RETURN;
+  /* For read only mode, we don't need ibuf and log I/O thread.
+  Please see srv_start() */
+  ulint   start = (srv_read_only_mode) ? 0 : 2;
+
+  if (segment < start) {
+    if (segment == 0) {
+      pfs_register_thread(io_ibuf_thread_key);
+    } else {
+      ut_ad(segment == 1);
+      pfs_register_thread(io_log_thread_key);
+    }
+  } else if (segment >= start
+       && segment < (start + srv_n_read_io_threads)) {
+      pfs_register_thread(io_read_thread_key);
+
+  } else if (segment >= (start + srv_n_read_io_threads)
+       && segment < (start + srv_n_read_io_threads
+         + srv_n_write_io_threads)) {
+    pfs_register_thread(io_write_thread_key);
+
+  } else {
+    pfs_register_thread(io_handler_thread_key);
+  }
+
+  while (srv_shutdown_state != SRV_SHUTDOWN_EXIT_THREADS
+         || buf_page_cleaner_is_active
+         || !os_aio_all_slots_free()) {
+    fil_aio_wait(segment);
+  }
+
+  /* We count the number of threads in os_thread_exit(). A created
+  thread should always use that to exit and not use return() to exit.
+  The thread actually never comes here because it is exited in an
+  os_event_wait(). */
+
+  os_thread_exit();
+
+  OS_THREAD_DUMMY_RETURN;
 }
 
 /*********************************************************************//**
@@ -341,35 +341,35 @@ static MY_ATTRIBUTE((nonnull, warn_unused_result))
 dberr_t
 create_log_file(
 /*============*/
-	pfs_os_file_t*	file,	/*!< out: file handle */
-	const char*	name)	/*!< in: log file name */
+  pfs_os_file_t*	file,	/*!< out: file handle */
+  const char*	name)	/*!< in: log file name */
 {
-	bool		ret;
+  bool		ret;
 
-	*file = os_file_create(
-		innodb_log_file_key, name,
-		OS_FILE_CREATE|OS_FILE_ON_ERROR_NO_EXIT, OS_FILE_NORMAL,
-		OS_LOG_FILE, srv_read_only_mode, &ret);
+  *file = os_file_create(
+    innodb_log_file_key, name,
+    OS_FILE_CREATE|OS_FILE_ON_ERROR_NO_EXIT, OS_FILE_NORMAL,
+    OS_LOG_FILE, srv_read_only_mode, &ret);
 
-	if (!ret) {
-		ib::error() << "Cannot create " << name;
-		return(DB_ERROR);
-	}
+  if (!ret) {
+    ib::error() << "Cannot create " << name;
+    return(DB_ERROR);
+  }
 
-	ib::info() << "Setting log file " << name << " size to "
-		<< srv_log_file_size << " bytes";
+  ib::info() << "Setting log file " << name << " size to "
+    << srv_log_file_size << " bytes";
 
-	ret = os_file_set_size(name, *file, srv_log_file_size);
-	if (!ret) {
-		ib::error() << "Cannot set log file " << name << " size to "
-			<< srv_log_file_size << " bytes";
-		return(DB_ERROR);
-	}
+  ret = os_file_set_size(name, *file, srv_log_file_size);
+  if (!ret) {
+    ib::error() << "Cannot set log file " << name << " size to "
+      << srv_log_file_size << " bytes";
+    return(DB_ERROR);
+  }
 
-	ret = os_file_close(*file);
-	ut_a(ret);
+  ret = os_file_close(*file);
+  ut_a(ret);
 
-	return(DB_SUCCESS);
+  return(DB_SUCCESS);
 }
 
 /** Initial number of the first redo log file */
@@ -384,19 +384,19 @@ static
 void
 delete_log_files(char* logfilename, size_t dirnamelen, uint n_files, uint i=0)
 {
-	/* Remove any old log files. */
-	for (; i < n_files; i++) {
-		sprintf(logfilename + dirnamelen, "ib_logfile%u", i);
+  /* Remove any old log files. */
+  for (; i < n_files; i++) {
+    sprintf(logfilename + dirnamelen, "ib_logfile%u", i);
 
-		/* Ignore errors about non-existent files or files
-		that cannot be removed. The create_log_file() will
-		return an error when the file exists. */
+    /* Ignore errors about non-existent files or files
+    that cannot be removed. The create_log_file() will
+    return an error when the file exists. */
 #ifdef _WIN32
-		DeleteFile((LPCTSTR) logfilename);
+    DeleteFile((LPCTSTR) logfilename);
 #else
-		unlink(logfilename);
+    unlink(logfilename);
 #endif
-	}
+  }
 }
 
 /*********************************************************************//**
@@ -406,111 +406,111 @@ static
 dberr_t
 create_log_files(
 /*=============*/
-	char*	logfilename,	/*!< in/out: buffer for log file name */
-	size_t	dirnamelen,	/*!< in: length of the directory path */
-	lsn_t	lsn,		/*!< in: FIL_PAGE_FILE_FLUSH_LSN value */
-	char*&	logfile0)	/*!< out: name of the first log file */
+  char*	logfilename,	/*!< in/out: buffer for log file name */
+  size_t	dirnamelen,	/*!< in: length of the directory path */
+  lsn_t	lsn,		/*!< in: FIL_PAGE_FILE_FLUSH_LSN value */
+  char*&	logfile0)	/*!< out: name of the first log file */
 {
-	dberr_t err;
+  dberr_t err;
 
-	if (srv_read_only_mode) {
-		ib::error() << "Cannot create log files in read-only mode";
-		return(DB_READ_ONLY);
-	}
+  if (srv_read_only_mode) {
+    ib::error() << "Cannot create log files in read-only mode";
+    return(DB_READ_ONLY);
+  }
 
-	/* Crashing after deleting the first file should be
-	recoverable. The buffer pool was clean, and we can simply
-	create all log files from the scratch. */
-	DBUG_EXECUTE_IF("innodb_log_abort_6",
-			delete_log_files(logfilename, dirnamelen, 1);
-			return(DB_ERROR););
+  /* Crashing after deleting the first file should be
+  recoverable. The buffer pool was clean, and we can simply
+  create all log files from the scratch. */
+  DBUG_EXECUTE_IF("innodb_log_abort_6",
+      delete_log_files(logfilename, dirnamelen, 1);
+      return(DB_ERROR););
 
-	delete_log_files(logfilename, dirnamelen, INIT_LOG_FILE0 + 1);
+  delete_log_files(logfilename, dirnamelen, INIT_LOG_FILE0 + 1);
 
-	DBUG_PRINT("ib_log", ("After innodb_log_abort_6"));
-	ut_ad(!buf_pool_check_no_pending_io());
+  DBUG_PRINT("ib_log", ("After innodb_log_abort_6"));
+  ut_ad(!buf_pool_check_no_pending_io());
 
-	DBUG_EXECUTE_IF("innodb_log_abort_7", return(DB_ERROR););
-	DBUG_PRINT("ib_log", ("After innodb_log_abort_7"));
+  DBUG_EXECUTE_IF("innodb_log_abort_7", return(DB_ERROR););
+  DBUG_PRINT("ib_log", ("After innodb_log_abort_7"));
 
-	for (unsigned i = 0; i < srv_n_log_files; i++) {
-		sprintf(logfilename + dirnamelen,
-			"ib_logfile%u", i ? i : INIT_LOG_FILE0);
+  for (unsigned i = 0; i < srv_n_log_files; i++) {
+    sprintf(logfilename + dirnamelen,
+      "ib_logfile%u", i ? i : INIT_LOG_FILE0);
 
-		err = create_log_file(&files[i], logfilename);
+    err = create_log_file(&files[i], logfilename);
 
-		if (err != DB_SUCCESS) {
-			return(err);
-		}
-	}
+    if (err != DB_SUCCESS) {
+      return(err);
+    }
+  }
 
-	DBUG_EXECUTE_IF("innodb_log_abort_8", return(DB_ERROR););
-	DBUG_PRINT("ib_log", ("After innodb_log_abort_8"));
+  DBUG_EXECUTE_IF("innodb_log_abort_8", return(DB_ERROR););
+  DBUG_PRINT("ib_log", ("After innodb_log_abort_8"));
 
-	/* We did not create the first log file initially as
-	ib_logfile0, so that crash recovery cannot find it until it
-	has been completed and renamed. */
-	sprintf(logfilename + dirnamelen, "ib_logfile%u", INIT_LOG_FILE0);
+  /* We did not create the first log file initially as
+  ib_logfile0, so that crash recovery cannot find it until it
+  has been completed and renamed. */
+  sprintf(logfilename + dirnamelen, "ib_logfile%u", INIT_LOG_FILE0);
 
-	fil_space_t*	log_space = fil_space_create(
-		"innodb_redo_log", SRV_LOG_SPACE_FIRST_ID, 0, FIL_TYPE_LOG,
-		NULL/* innodb_encrypt_log works at a different level */);
+  fil_space_t*	log_space = fil_space_create(
+    "innodb_redo_log", SRV_LOG_SPACE_FIRST_ID, 0, FIL_TYPE_LOG,
+    NULL/* innodb_encrypt_log works at a different level */);
 
-	ut_a(fil_validate());
-	ut_a(log_space != NULL);
+  ut_a(fil_validate());
+  ut_a(log_space != NULL);
 
-	const ulint size = ulint(srv_log_file_size >> srv_page_size_shift);
+  const ulint size = ulint(srv_log_file_size >> srv_page_size_shift);
 
-	logfile0 = log_space->add(logfilename, OS_FILE_CLOSED, size,
-				  false, false)->name;
-	ut_a(logfile0);
+  logfile0 = log_space->add(logfilename, OS_FILE_CLOSED, size,
+          false, false)->name;
+  ut_a(logfile0);
 
-	for (unsigned i = 1; i < srv_n_log_files; i++) {
+  for (unsigned i = 1; i < srv_n_log_files; i++) {
 
-		sprintf(logfilename + dirnamelen, "ib_logfile%u", i);
+    sprintf(logfilename + dirnamelen, "ib_logfile%u", i);
 
-		log_space->add(logfilename, OS_FILE_CLOSED, size,
-			       false, false);
-	}
+    log_space->add(logfilename, OS_FILE_CLOSED, size,
+             false, false);
+  }
 
-	log_sys.log.create(srv_n_log_files);
-	if (!log_set_capacity(srv_log_file_size_requested)) {
-		return(DB_ERROR);
-	}
+  log_sys.log.create(srv_n_log_files);
+  if (!log_set_capacity(srv_log_file_size_requested)) {
+    return(DB_ERROR);
+  }
 
-	fil_open_log_and_system_tablespace_files();
+  fil_open_log_and_system_tablespace_files();
 
-	/* Create a log checkpoint. */
-	log_mutex_enter();
-	if (log_sys.is_encrypted() && !log_crypt_init()) {
-		return DB_ERROR;
-	}
-	ut_d(recv_no_log_write = false);
-	log_sys.lsn = ut_uint64_align_up(lsn, OS_FILE_LOG_BLOCK_SIZE);
+  /* Create a log checkpoint. */
+  log_mutex_enter();
+  if (log_sys.is_encrypted() && !log_crypt_init()) {
+    return DB_ERROR;
+  }
+  ut_d(recv_no_log_write = false);
+  log_sys.lsn = ut_uint64_align_up(lsn, OS_FILE_LOG_BLOCK_SIZE);
 
-	log_sys.log.set_lsn(log_sys.lsn);
-	log_sys.log.set_lsn_offset(LOG_FILE_HDR_SIZE);
+  log_sys.log.set_lsn(log_sys.lsn);
+  log_sys.log.set_lsn_offset(LOG_FILE_HDR_SIZE);
 
-	log_sys.buf_next_to_write = 0;
-	log_sys.write_lsn = log_sys.lsn;
+  log_sys.buf_next_to_write = 0;
+  log_sys.write_lsn = log_sys.lsn;
 
-	log_sys.next_checkpoint_no = 0;
-	log_sys.last_checkpoint_lsn = 0;
+  log_sys.next_checkpoint_no = 0;
+  log_sys.last_checkpoint_lsn = 0;
 
-	memset(log_sys.buf, 0, srv_log_buffer_size);
-	log_block_init(log_sys.buf, log_sys.lsn);
-	log_block_set_first_rec_group(log_sys.buf, LOG_BLOCK_HDR_SIZE);
+  memset(log_sys.buf, 0, srv_log_buffer_size);
+  log_block_init(log_sys.buf, log_sys.lsn);
+  log_block_set_first_rec_group(log_sys.buf, LOG_BLOCK_HDR_SIZE);
 
-	log_sys.buf_free = LOG_BLOCK_HDR_SIZE;
-	log_sys.lsn += LOG_BLOCK_HDR_SIZE;
+  log_sys.buf_free = LOG_BLOCK_HDR_SIZE;
+  log_sys.lsn += LOG_BLOCK_HDR_SIZE;
 
-	MONITOR_SET(MONITOR_LSN_CHECKPOINT_AGE,
-		    (log_sys.lsn - log_sys.last_checkpoint_lsn));
-	log_mutex_exit();
+  MONITOR_SET(MONITOR_LSN_CHECKPOINT_AGE,
+        (log_sys.lsn - log_sys.last_checkpoint_lsn));
+  log_mutex_exit();
 
-	log_make_checkpoint();
+  log_make_checkpoint();
 
-	return(DB_SUCCESS);
+  return(DB_SUCCESS);
 }
 
 /** Rename the first redo log file.
@@ -525,50 +525,50 @@ static
 dberr_t
 create_log_files_rename(
 /*====================*/
-	char*	logfilename,	/*!< in/out: buffer for log file name */
-	size_t	dirnamelen,	/*!< in: length of the directory path */
-	lsn_t	lsn,		/*!< in: FIL_PAGE_FILE_FLUSH_LSN value */
-	char*	logfile0)	/*!< in/out: name of the first log file */
+  char*	logfilename,	/*!< in/out: buffer for log file name */
+  size_t	dirnamelen,	/*!< in: length of the directory path */
+  lsn_t	lsn,		/*!< in: FIL_PAGE_FILE_FLUSH_LSN value */
+  char*	logfile0)	/*!< in/out: name of the first log file */
 {
-	/* If innodb_flush_method=O_DSYNC,
-	we need to explicitly flush the log buffers. */
-	fil_flush(SRV_LOG_SPACE_FIRST_ID);
+  /* If innodb_flush_method=O_DSYNC,
+  we need to explicitly flush the log buffers. */
+  fil_flush(SRV_LOG_SPACE_FIRST_ID);
 
-	ut_ad(!srv_log_files_created);
-	ut_d(srv_log_files_created = true);
+  ut_ad(!srv_log_files_created);
+  ut_d(srv_log_files_created = true);
 
-	DBUG_EXECUTE_IF("innodb_log_abort_9", return(DB_ERROR););
-	DBUG_PRINT("ib_log", ("After innodb_log_abort_9"));
+  DBUG_EXECUTE_IF("innodb_log_abort_9", return(DB_ERROR););
+  DBUG_PRINT("ib_log", ("After innodb_log_abort_9"));
 
-	/* Close the log files, so that we can rename
-	the first one. */
-	fil_close_log_files(false);
+  /* Close the log files, so that we can rename
+  the first one. */
+  fil_close_log_files(false);
 
-	/* Rename the first log file, now that a log
-	checkpoint has been created. */
-	sprintf(logfilename + dirnamelen, "ib_logfile%u", 0);
+  /* Rename the first log file, now that a log
+  checkpoint has been created. */
+  sprintf(logfilename + dirnamelen, "ib_logfile%u", 0);
 
-	ib::info() << "Renaming log file " << logfile0 << " to "
-		<< logfilename;
+  ib::info() << "Renaming log file " << logfile0 << " to "
+    << logfilename;
 
-	log_mutex_enter();
-	ut_ad(strlen(logfile0) == 2 + strlen(logfilename));
-	dberr_t err = os_file_rename(
-		innodb_log_file_key, logfile0, logfilename)
-		? DB_SUCCESS : DB_ERROR;
+  log_mutex_enter();
+  ut_ad(strlen(logfile0) == 2 + strlen(logfilename));
+  dberr_t err = os_file_rename(
+    innodb_log_file_key, logfile0, logfilename)
+    ? DB_SUCCESS : DB_ERROR;
 
-	/* Replace the first file with ib_logfile0. */
-	strcpy(logfile0, logfilename);
-	log_mutex_exit();
+  /* Replace the first file with ib_logfile0. */
+  strcpy(logfile0, logfilename);
+  log_mutex_exit();
 
-	DBUG_EXECUTE_IF("innodb_log_abort_10", err = DB_ERROR;);
+  DBUG_EXECUTE_IF("innodb_log_abort_10", err = DB_ERROR;);
 
-	if (err == DB_SUCCESS) {
-		fil_open_log_and_system_tablespace_files();
-		ib::info() << "New log files created, LSN=" << lsn;
-	}
+  if (err == DB_SUCCESS) {
+    fil_open_log_and_system_tablespace_files();
+    ib::info() << "New log files created, LSN=" << lsn;
+  }
 
-	return(err);
+  return(err);
 }
 
 /*********************************************************************//**
@@ -578,66 +578,66 @@ static
 dberr_t
 srv_undo_tablespace_create(
 /*=======================*/
-	const char*	name,		/*!< in: tablespace name */
-	ulint		size)		/*!< in: tablespace size in pages */
+  const char*	name,		/*!< in: tablespace name */
+  ulint		size)		/*!< in: tablespace size in pages */
 {
-	pfs_os_file_t	fh;
-	bool		ret;
-	dberr_t		err = DB_SUCCESS;
+  pfs_os_file_t	fh;
+  bool		ret;
+  dberr_t		err = DB_SUCCESS;
 
-	os_file_create_subdirs_if_needed(name);
+  os_file_create_subdirs_if_needed(name);
 
-	fh = os_file_create(
-		innodb_data_file_key,
-		name,
-		srv_read_only_mode ? OS_FILE_OPEN : OS_FILE_CREATE,
-		OS_FILE_NORMAL, OS_DATA_FILE, srv_read_only_mode, &ret);
+  fh = os_file_create(
+    innodb_data_file_key,
+    name,
+    srv_read_only_mode ? OS_FILE_OPEN : OS_FILE_CREATE,
+    OS_FILE_NORMAL, OS_DATA_FILE, srv_read_only_mode, &ret);
 
-	if (srv_read_only_mode && ret) {
+  if (srv_read_only_mode && ret) {
 
-		ib::info() << name << " opened in read-only mode";
+    ib::info() << name << " opened in read-only mode";
 
-	} else if (ret == FALSE) {
-		if (os_file_get_last_error(false) != OS_FILE_ALREADY_EXISTS
+  } else if (ret == FALSE) {
+    if (os_file_get_last_error(false) != OS_FILE_ALREADY_EXISTS
 #ifdef UNIV_AIX
-			/* AIX 5.1 after security patch ML7 may have
-			errno set to 0 here, which causes our function
-			to return 100; work around that AIX problem */
-		    && os_file_get_last_error(false) != 100
+      /* AIX 5.1 after security patch ML7 may have
+      errno set to 0 here, which causes our function
+      to return 100; work around that AIX problem */
+        && os_file_get_last_error(false) != 100
 #endif /* UNIV_AIX */
-		) {
-			ib::error() << "Can't create UNDO tablespace "
-				<< name;
-		}
-		err = DB_ERROR;
-	} else {
-		ut_a(!srv_read_only_mode);
+    ) {
+      ib::error() << "Can't create UNDO tablespace "
+        << name;
+    }
+    err = DB_ERROR;
+  } else {
+    ut_a(!srv_read_only_mode);
 
-		/* We created the data file and now write it full of zeros */
+    /* We created the data file and now write it full of zeros */
 
-		ib::info() << "Data file " << name << " did not exist: new to"
-			" be created";
+    ib::info() << "Data file " << name << " did not exist: new to"
+      " be created";
 
-		ib::info() << "Setting file " << name << " size to "
-			<< (size >> (20 - srv_page_size_shift)) << " MB";
+    ib::info() << "Setting file " << name << " size to "
+      << (size >> (20 - srv_page_size_shift)) << " MB";
 
-		ib::info() << "Database physically writes the file full: "
-			<< "wait...";
+    ib::info() << "Database physically writes the file full: "
+      << "wait...";
 
-		ret = os_file_set_size(
-			name, fh, os_offset_t(size) << srv_page_size_shift);
+    ret = os_file_set_size(
+      name, fh, os_offset_t(size) << srv_page_size_shift);
 
-		if (!ret) {
-			ib::info() << "Error in creating " << name
-				<< ": probably out of disk space";
+    if (!ret) {
+      ib::info() << "Error in creating " << name
+        << ": probably out of disk space";
 
-			err = DB_ERROR;
-		}
+      err = DB_ERROR;
+    }
 
-		os_file_close(fh);
-	}
+    os_file_close(fh);
+  }
 
-	return(err);
+  return(err);
 }
 
 /** Open an undo tablespace.
@@ -646,71 +646,71 @@ srv_undo_tablespace_create(
 @param[in]	create_new_db	whether undo tablespaces are being created
 @return whether the tablespace was opened */
 static bool srv_undo_tablespace_open(const char* name, ulint space_id,
-				     bool create_new_db)
+             bool create_new_db)
 {
-	pfs_os_file_t	fh;
-	bool		success;
-	char		undo_name[sizeof "innodb_undo000"];
-
-	snprintf(undo_name, sizeof(undo_name),
-		 "innodb_undo%03u", static_cast<unsigned>(space_id));
-
-	fh = os_file_create(
-		innodb_data_file_key, name, OS_FILE_OPEN
-		| OS_FILE_ON_ERROR_NO_EXIT | OS_FILE_ON_ERROR_SILENT,
-		OS_FILE_AIO, OS_DATA_FILE, srv_read_only_mode, &success);
-	if (!success) {
-		return false;
-	}
-
-	os_offset_t size = os_file_get_size(fh);
-	ut_a(size != os_offset_t(-1));
-
-	/* Load the tablespace into InnoDB's internal data structures. */
-
-	/* We set the biggest space id to the undo tablespace
-	because InnoDB hasn't opened any other tablespace apart
-	from the system tablespace. */
-
-	fil_set_max_space_id_if_bigger(space_id);
-
-	ulint fsp_flags;
-	switch (srv_checksum_algorithm) {
-	case SRV_CHECKSUM_ALGORITHM_FULL_CRC32:
-	case SRV_CHECKSUM_ALGORITHM_STRICT_FULL_CRC32:
-		fsp_flags = (FSP_FLAGS_FCRC32_MASK_MARKER
-			     | FSP_FLAGS_FCRC32_PAGE_SSIZE());
-		break;
-	default:
-		fsp_flags = FSP_FLAGS_PAGE_SSIZE();
-	}
-
-	fil_space_t* space = fil_space_create(undo_name, space_id, fsp_flags,
-					      FIL_TYPE_TABLESPACE, NULL);
-
-	ut_a(fil_validate());
-	ut_a(space);
-
-	fil_node_t* file = space->add(name, fh, 0, false, true);
-
-	mutex_enter(&fil_system.mutex);
-
-	if (create_new_db) {
-		space->size = file->size = ulint(size >> srv_page_size_shift);
-		space->size_in_header = SRV_UNDO_TABLESPACE_SIZE_IN_PAGES;
-	} else {
-		success = file->read_page0(true);
-		if (!success) {
-			os_file_close(file->handle);
-			file->handle = OS_FILE_CLOSED;
-			ut_a(fil_system.n_open > 0);
-			fil_system.n_open--;
-		}
-	}
-
-	mutex_exit(&fil_system.mutex);
-
-	return success;
+  pfs_os_file_t	fh;
+  bool		success;
+  char		undo_name[sizeof "innodb_undo000"];
+
+  snprintf(undo_name, sizeof(undo_name),
+     "innodb_undo%03u", static_cast<unsigned>(space_id));
+
+  fh = os_file_create(
+    innodb_data_file_key, name, OS_FILE_OPEN
+    | OS_FILE_ON_ERROR_NO_EXIT | OS_FILE_ON_ERROR_SILENT,
+    OS_FILE_AIO, OS_DATA_FILE, srv_read_only_mode, &success);
+  if (!success) {
+    return false;
+  }
+
+  os_offset_t size = os_file_get_size(fh);
+  ut_a(size != os_offset_t(-1));
+
+  /* Load the tablespace into InnoDB's internal data structures. */
+
+  /* We set the biggest space id to the undo tablespace
+  because InnoDB hasn't opened any other tablespace apart
+  from the system tablespace. */
+
+  fil_set_max_space_id_if_bigger(space_id);
+
+  ulint fsp_flags;
+  switch (srv_checksum_algorithm) {
+  case SRV_CHECKSUM_ALGORITHM_FULL_CRC32:
+  case SRV_CHECKSUM_ALGORITHM_STRICT_FULL_CRC32:
+    fsp_flags = (FSP_FLAGS_FCRC32_MASK_MARKER
+           | FSP_FLAGS_FCRC32_PAGE_SSIZE());
+    break;
+  default:
+    fsp_flags = FSP_FLAGS_PAGE_SSIZE();
+  }
+
+  fil_space_t* space = fil_space_create(undo_name, space_id, fsp_flags,
+                FIL_TYPE_TABLESPACE, NULL);
+
+  ut_a(fil_validate());
+  ut_a(space);
+
+  fil_node_t* file = space->add(name, fh, 0, false, true);
+
+  mutex_enter(&fil_system.mutex);
+
+  if (create_new_db) {
+    space->size = file->size = ulint(size >> srv_page_size_shift);
+    space->size_in_header = SRV_UNDO_TABLESPACE_SIZE_IN_PAGES;
+  } else {
+    success = file->read_page0(true);
+    if (!success) {
+      os_file_close(file->handle);
+      file->handle = OS_FILE_CLOSED;
+      ut_a(fil_system.n_open > 0);
+      fil_system.n_open--;
+    }
+  }
+
+  mutex_exit(&fil_system.mutex);
+
+  return success;
 }
 
 /** Check if undo tablespaces and redo log files exist before creating a
@@ -721,72 +721,72 @@ static
 dberr_t
 srv_check_undo_redo_logs_exists()
 {
-	bool		ret;
-	pfs_os_file_t	fh;
-	char	name[OS_FILE_MAX_PATH];
-
-	/* Check if any undo tablespaces exist */
-	for (ulint i = 1; i <= srv_undo_tablespaces; ++i) {
-
-		snprintf(
-			name, sizeof(name),
-			"%s%cundo%03zu",
-			srv_undo_dir, OS_PATH_SEPARATOR,
-			i);
-
-		fh = os_file_create(
-			innodb_data_file_key, name,
-			OS_FILE_OPEN_RETRY
-			| OS_FILE_ON_ERROR_NO_EXIT
-			| OS_FILE_ON_ERROR_SILENT,
-			OS_FILE_NORMAL,
-			OS_DATA_FILE,
-			srv_read_only_mode,
-			&ret);
-
-		if (ret) {
-			os_file_close(fh);
-			ib::error()
-				<< "undo tablespace '" << name << "' exists."
-				" Creating system tablespace with existing undo"
-				" tablespaces is not supported. Please delete"
-				" all undo tablespaces before creating new"
-				" system tablespace.";
-			return(DB_ERROR);
-		}
-	}
-
-	/* Check if any redo log files exist */
-	char	logfilename[OS_FILE_MAX_PATH];
-	size_t dirnamelen = strlen(srv_log_group_home_dir);
-	memcpy(logfilename, srv_log_group_home_dir, dirnamelen);
-
-	for (unsigned i = 0; i < srv_n_log_files; i++) {
-		sprintf(logfilename + dirnamelen,
-			"ib_logfile%u", i);
-
-		fh = os_file_create(
-			innodb_log_file_key, logfilename,
-			OS_FILE_OPEN_RETRY
-			| OS_FILE_ON_ERROR_NO_EXIT
-			| OS_FILE_ON_ERROR_SILENT,
-			OS_FILE_NORMAL,
-			OS_LOG_FILE,
-			srv_read_only_mode,
-			&ret);
-
-		if (ret) {
-			os_file_close(fh);
-			ib::error() << "redo log file '" << logfilename
-				<< "' exists. Creating system tablespace with"
-				" existing redo log files is not recommended."
-				" Please delete all redo log files before"
-				" creating new system tablespace.";
-			return(DB_ERROR);
-		}
-	}
-
-	return(DB_SUCCESS);
+  bool		ret;
+  pfs_os_file_t	fh;
+  char	name[OS_FILE_MAX_PATH];
+
+  /* Check if any undo tablespaces exist */
+  for (ulint i = 1; i <= srv_undo_tablespaces; ++i) {
+
+    snprintf(
+      name, sizeof(name),
+      "%s%cundo%03zu",
+      srv_undo_dir, OS_PATH_SEPARATOR,
+      i);
+
+    fh = os_file_create(
+      innodb_data_file_key, name,
+      OS_FILE_OPEN_RETRY
+      | OS_FILE_ON_ERROR_NO_EXIT
+      | OS_FILE_ON_ERROR_SILENT,
+      OS_FILE_NORMAL,
+      OS_DATA_FILE,
+      srv_read_only_mode,
+      &ret);
+
+    if (ret) {
+      os_file_close(fh);
+      ib::error()
+        << "undo tablespace '" << name << "' exists."
+        " Creating system tablespace with existing undo"
+        " tablespaces is not supported. Please delete"
+        " all undo tablespaces before creating new"
+        " system tablespace.";
+      return(DB_ERROR);
+    }
+  }
+
+  /* Check if any redo log files exist */
+  char	logfilename[OS_FILE_MAX_PATH];
+  size_t dirnamelen = strlen(srv_log_group_home_dir);
+  memcpy(logfilename, srv_log_group_home_dir, dirnamelen);
+
+  for (unsigned i = 0; i < srv_n_log_files; i++) {
+    sprintf(logfilename + dirnamelen,
+      "ib_logfile%u", i);
+
+    fh = os_file_create(
+      innodb_log_file_key, logfilename,
+      OS_FILE_OPEN_RETRY
+      | OS_FILE_ON_ERROR_NO_EXIT
+      | OS_FILE_ON_ERROR_SILENT,
+      OS_FILE_NORMAL,
+      OS_LOG_FILE,
+      srv_read_only_mode,
+      &ret);
+
+    if (ret) {
+      os_file_close(fh);
+      ib::error() << "redo log file '" << logfilename
+        << "' exists. Creating system tablespace with"
+        " existing redo log files is not recommended."
+        " Please delete all redo log files before"
+        " creating new system tablespace.";
+      return(DB_ERROR);
+    }
+  }
+
+  return(DB_SUCCESS);
 }
 
 /** Open the configured number of dedicated undo tablespaces.
@@ -795,188 +795,188 @@ srv_check_undo_redo_logs_exists()
 dberr_t
 srv_undo_tablespaces_init(bool create_new_db)
 {
-	ulint			i;
-	dberr_t			err = DB_SUCCESS;
-	ulint			prev_space_id = 0;
-	ulint			n_undo_tablespaces;
-	ulint			undo_tablespace_ids[TRX_SYS_N_RSEGS + 1];
-
-	srv_undo_tablespaces_open = 0;
-
-	ut_a(srv_undo_tablespaces <= TRX_SYS_N_RSEGS);
-	ut_a(!create_new_db || srv_operation == SRV_OPERATION_NORMAL);
-
-	if (srv_undo_tablespaces == 1) { /* 1 is not allowed, make it 0 */
-		srv_undo_tablespaces = 0;
-	}
-
-	memset(undo_tablespace_ids, 0x0, sizeof(undo_tablespace_ids));
-
-	/* Create the undo spaces only if we are creating a new
-	instance. We don't allow creating of new undo tablespaces
-	in an existing instance (yet).  This restriction exists because
-	we check in several places for SYSTEM tablespaces to be less than
-	the min of user defined tablespace ids. Once we implement saving
-	the location of the undo tablespaces and their space ids this
-	restriction will/should be lifted. */
-
-	for (i = 0; create_new_db && i < srv_undo_tablespaces; ++i) {
-		char	name[OS_FILE_MAX_PATH];
-		ulint	space_id  = i + 1;
-
-		DBUG_EXECUTE_IF("innodb_undo_upgrade",
-				space_id = i + 3;);
-
-		snprintf(
-			name, sizeof(name),
-			"%s%cundo%03zu",
-			srv_undo_dir, OS_PATH_SEPARATOR, space_id);
-
-		if (i == 0) {
-			srv_undo_space_id_start = space_id;
-			prev_space_id = srv_undo_space_id_start - 1;
-		}
-
-		undo_tablespace_ids[i] = space_id;
-
-		err = srv_undo_tablespace_create(
-			name, SRV_UNDO_TABLESPACE_SIZE_IN_PAGES);
-
-		if (err != DB_SUCCESS) {
-			ib::error() << "Could not create undo tablespace '"
-				<< name << "'.";
-			return(err);
-		}
-	}
-
-	/* Get the tablespace ids of all the undo segments excluding
-	the system tablespace (0). If we are creating a new instance then
-	we build the undo_tablespace_ids ourselves since they don't
-	already exist. */
-	n_undo_tablespaces = create_new_db
-		|| srv_operation == SRV_OPERATION_BACKUP
-		|| srv_operation == SRV_OPERATION_RESTORE_DELTA
-		? srv_undo_tablespaces
-		: trx_rseg_get_n_undo_tablespaces(undo_tablespace_ids);
-	srv_undo_tablespaces_active = srv_undo_tablespaces;
-
-	switch (srv_operation) {
-	case SRV_OPERATION_RESTORE_DELTA:
-	case SRV_OPERATION_BACKUP:
-		for (i = 0; i < n_undo_tablespaces; i++) {
-			undo_tablespace_ids[i] = i + srv_undo_space_id_start;
-		}
-
-		prev_space_id = srv_undo_space_id_start - 1;
-		break;
-	case SRV_OPERATION_NORMAL:
-	case SRV_OPERATION_RESTORE:
-	case SRV_OPERATION_RESTORE_EXPORT:
-		break;
-	}
-
-	/* Open all the undo tablespaces that are currently in use. If we
-	fail to open any of these it is a fatal error. The tablespace ids
-	should be contiguous. It is a fatal error because they are required
-	for recovery and are referenced by the UNDO logs (a.k.a RBS). */
-
-	for (i = 0; i < n_undo_tablespaces; ++i) {
-		char	name[OS_FILE_MAX_PATH];
-
-		snprintf(
-			name, sizeof(name),
-			"%s%cundo%03zu",
-			srv_undo_dir, OS_PATH_SEPARATOR,
-			undo_tablespace_ids[i]);
-
-		/* Should be no gaps in undo tablespace ids. */
-		ut_a(!i || prev_space_id + 1 == undo_tablespace_ids[i]);
-
-		/* The system space id should not be in this array. */
-		ut_a(undo_tablespace_ids[i] != 0);
-		ut_a(undo_tablespace_ids[i] != ULINT_UNDEFINED);
-
-		if (!srv_undo_tablespace_open(name, undo_tablespace_ids[i],
-					      create_new_db)) {
-			ib::error() << "Unable to open undo tablespace '"
-				<< name << "'.";
-			return DB_ERROR;
-		}
-
-		prev_space_id = undo_tablespace_ids[i];
-
-		/* Note the first undo tablespace id in case of
-		no active undo tablespace. */
-		if (0 == srv_undo_tablespaces_open++) {
-			srv_undo_space_id_start = undo_tablespace_ids[i];
-		}
-	}
-
-	/* Open any extra unused undo tablespaces. These must be contiguous.
-	We stop at the first failure. These are undo tablespaces that are
-	not in use and therefore not required by recovery. We only check
-	that there are no gaps. */
-
-	for (i = prev_space_id + 1;
-	     i < srv_undo_space_id_start + TRX_SYS_N_RSEGS; ++i) {
-		char	name[OS_FILE_MAX_PATH];
-
-		snprintf(
-			name, sizeof(name),
-			"%s%cundo%03zu", srv_undo_dir, OS_PATH_SEPARATOR, i);
-
-		if (!srv_undo_tablespace_open(name, i, create_new_db)) {
-			err = DB_ERROR;
-			break;
-		}
-
-		++n_undo_tablespaces;
-
-		++srv_undo_tablespaces_open;
-	}
-
-	/* Initialize srv_undo_space_id_start=0 when there are no
-	dedicated undo tablespaces. */
-	if (n_undo_tablespaces == 0) {
-		srv_undo_space_id_start = 0;
-	}
-
-	/* If the user says that there are fewer than what we find we
-	tolerate that discrepancy but not the inverse. Because there could
-	be unused undo tablespaces for future use. */
-
-	if (srv_undo_tablespaces > n_undo_tablespaces) {
-		ib::error() << "Expected to open innodb_undo_tablespaces="
-			<< srv_undo_tablespaces
-			<< " but was able to find only "
-			<< n_undo_tablespaces;
-
-		return(err != DB_SUCCESS ? err : DB_ERROR);
-
-	} else if (n_undo_tablespaces > 0) {
-
-		ib::info() << "Opened " << n_undo_tablespaces
-			<< " undo tablespaces";
-
-		if (srv_undo_tablespaces == 0) {
-			ib::warn() << "innodb_undo_tablespaces=0 disables"
-				" dedicated undo log tablespaces";
-		}
-	}
-
-	if (create_new_db) {
-		mtr_t	mtr;
-
-		for (i = 0; i < n_undo_tablespaces; ++i) {
-			mtr.start();
-			fsp_header_init(fil_space_get(undo_tablespace_ids[i]),
-					SRV_UNDO_TABLESPACE_SIZE_IN_PAGES,
-					&mtr);
-			mtr.commit();
-		}
-	}
-
-	return(DB_SUCCESS);
+  ulint			i;
+  dberr_t			err = DB_SUCCESS;
+  ulint			prev_space_id = 0;
+  ulint			n_undo_tablespaces;
+  ulint			undo_tablespace_ids[TRX_SYS_N_RSEGS + 1];
+
+  srv_undo_tablespaces_open = 0;
+
+  ut_a(srv_undo_tablespaces <= TRX_SYS_N_RSEGS);
+  ut_a(!create_new_db || srv_operation == SRV_OPERATION_NORMAL);
+
+  if (srv_undo_tablespaces == 1) { /* 1 is not allowed, make it 0 */
+    srv_undo_tablespaces = 0;
+  }
+
+  memset(undo_tablespace_ids, 0x0, sizeof(undo_tablespace_ids));
+
+  /* Create the undo spaces only if we are creating a new
+  instance. We don't allow creating of new undo tablespaces
+  in an existing instance (yet).  This restriction exists because
+  we check in several places for SYSTEM tablespaces to be less than
+  the min of user defined tablespace ids. Once we implement saving
+  the location of the undo tablespaces and their space ids this
+  restriction will/should be lifted. */
+
+  for (i = 0; create_new_db && i < srv_undo_tablespaces; ++i) {
+    char	name[OS_FILE_MAX_PATH];
+    ulint	space_id  = i + 1;
+
+    DBUG_EXECUTE_IF("innodb_undo_upgrade",
+        space_id = i + 3;);
+
+    snprintf(
+      name, sizeof(name),
+      "%s%cundo%03zu",
+      srv_undo_dir, OS_PATH_SEPARATOR, space_id);
+
+    if (i == 0) {
+      srv_undo_space_id_start = space_id;
+      prev_space_id = srv_undo_space_id_start - 1;
+    }
+
+    undo_tablespace_ids[i] = space_id;
+
+    err = srv_undo_tablespace_create(
+      name, SRV_UNDO_TABLESPACE_SIZE_IN_PAGES);
+
+    if (err != DB_SUCCESS) {
+      ib::error() << "Could not create undo tablespace '"
+        << name << "'.";
+      return(err);
+    }
+  }
+
+  /* Get the tablespace ids of all the undo segments excluding
+  the system tablespace (0). If we are creating a new instance then
+  we build the undo_tablespace_ids ourselves since they don't
+  already exist. */
+  n_undo_tablespaces = create_new_db
+    || srv_operation == SRV_OPERATION_BACKUP
+    || srv_operation == SRV_OPERATION_RESTORE_DELTA
+    ? srv_undo_tablespaces
+    : trx_rseg_get_n_undo_tablespaces(undo_tablespace_ids);
+  srv_undo_tablespaces_active = srv_undo_tablespaces;
+
+  switch (srv_operation) {
+  case SRV_OPERATION_RESTORE_DELTA:
+  case SRV_OPERATION_BACKUP:
+    for (i = 0; i < n_undo_tablespaces; i++) {
+      undo_tablespace_ids[i] = i + srv_undo_space_id_start;
+    }
+
+    prev_space_id = srv_undo_space_id_start - 1;
+    break;
+  case SRV_OPERATION_NORMAL:
+  case SRV_OPERATION_RESTORE:
+  case SRV_OPERATION_RESTORE_EXPORT:
+    break;
+  }
+
+  /* Open all the undo tablespaces that are currently in use. If we
+  fail to open any of these it is a fatal error. The tablespace ids
+  should be contiguous. It is a fatal error because they are required
+  for recovery and are referenced by the UNDO logs (a.k.a RBS). */
+
+  for (i = 0; i < n_undo_tablespaces; ++i) {
+    char	name[OS_FILE_MAX_PATH];
+
+    snprintf(
+      name, sizeof(name),
+      "%s%cundo%03zu",
+      srv_undo_dir, OS_PATH_SEPARATOR,
+      undo_tablespace_ids[i]);
+
+    /* Should be no gaps in undo tablespace ids. */
+    ut_a(!i || prev_space_id + 1 == undo_tablespace_ids[i]);
+
+    /* The system space id should not be in this array. */
+    ut_a(undo_tablespace_ids[i] != 0);
+    ut_a(undo_tablespace_ids[i] != ULINT_UNDEFINED);
+
+    if (!srv_undo_tablespace_open(name, undo_tablespace_ids[i],
+                create_new_db)) {
+      ib::error() << "Unable to open undo tablespace '"
+        << name << "'.";
+      return DB_ERROR;
+    }
+
+    prev_space_id = undo_tablespace_ids[i];
+
+    /* Note the first undo tablespace id in case of
+    no active undo tablespace. */
+    if (0 == srv_undo_tablespaces_open++) {
+      srv_undo_space_id_start = undo_tablespace_ids[i];
+    }
+  }
+
+  /* Open any extra unused undo tablespaces. These must be contiguous.
+  We stop at the first failure. These are undo tablespaces that are
+  not in use and therefore not required by recovery. We only check
+  that there are no gaps. */
+
+  for (i = prev_space_id + 1;
+       i < srv_undo_space_id_start + TRX_SYS_N_RSEGS; ++i) {
+    char	name[OS_FILE_MAX_PATH];
+
+    snprintf(
+      name, sizeof(name),
+      "%s%cundo%03zu", srv_undo_dir, OS_PATH_SEPARATOR, i);
+
+    if (!srv_undo_tablespace_open(name, i, create_new_db)) {
+      err = DB_ERROR;
+      break;
+    }
+
+    ++n_undo_tablespaces;
+
+    ++srv_undo_tablespaces_open;
+  }
+
+  /* Initialize srv_undo_space_id_start=0 when there are no
+  dedicated undo tablespaces. */
+  if (n_undo_tablespaces == 0) {
+    srv_undo_space_id_start = 0;
+  }
+
+  /* If the user says that there are fewer than what we find we
+  tolerate that discrepancy but not the inverse. Because there could
+  be unused undo tablespaces for future use. */
+
+  if (srv_undo_tablespaces > n_undo_tablespaces) {
+    ib::error() << "Expected to open innodb_undo_tablespaces="
+      << srv_undo_tablespaces
+      << " but was able to find only "
+      << n_undo_tablespaces;
+
+    return(err != DB_SUCCESS ? err : DB_ERROR);
+
+  } else if (n_undo_tablespaces > 0) {
+
+    ib::info() << "Opened " << n_undo_tablespaces
+      << " undo tablespaces";
+
+    if (srv_undo_tablespaces == 0) {
+      ib::warn() << "innodb_undo_tablespaces=0 disables"
+        " dedicated undo log tablespaces";
+    }
+  }
+
+  if (create_new_db) {
+    mtr_t	mtr;
+
+    for (i = 0; i < n_undo_tablespaces; ++i) {
+      mtr.start();
+      fsp_header_init(fil_space_get(undo_tablespace_ids[i]),
+          SRV_UNDO_TABLESPACE_SIZE_IN_PAGES,
+          &mtr);
+      mtr.commit();
+    }
+  }
+
+  return(DB_SUCCESS);
 }
 
 /** Create the temporary file tablespace.
@@ -986,51 +986,51 @@ static
 dberr_t
 srv_open_tmp_tablespace(bool create_new_db)
 {
-	ulint	sum_of_new_sizes;
-
-	/* Will try to remove if there is existing file left-over by last
-	unclean shutdown */
-	srv_tmp_space.set_sanity_check_status(true);
-	srv_tmp_space.delete_files();
-	srv_tmp_space.set_ignore_read_only(true);
-
-	ib::info() << "Creating shared tablespace for temporary tables";
-
-	bool	create_new_temp_space;
-
-	srv_tmp_space.set_space_id(SRV_TMP_SPACE_ID);
-
-	dberr_t	err = srv_tmp_space.check_file_spec(
-		&create_new_temp_space, 12 * 1024 * 1024);
-
-	if (err == DB_FAIL) {
-		ib::error() << "The innodb_temporary"
-			" data file must be writable!";
-		err = DB_ERROR;
-	} else if (err != DB_SUCCESS) {
-		ib::error() << "Could not create the shared innodb_temporary.";
-	} else if ((err = srv_tmp_space.open_or_create(
-			    true, create_new_db, &sum_of_new_sizes, NULL))
-		   != DB_SUCCESS) {
-		ib::error() << "Unable to create the shared innodb_temporary";
-	} else if (fil_system.temp_space->open()) {
-		/* Initialize the header page */
-		mtr_t mtr;
-		mtr.start();
-		mtr.set_log_mode(MTR_LOG_NO_REDO);
-		fsp_header_init(fil_system.temp_space,
-				srv_tmp_space.get_sum_of_sizes(),
-				&mtr);
-		mtr.commit();
-	} else {
-		/* This file was just opened in the code above! */
-		ib::error() << "The innodb_temporary"
-			" data file cannot be re-opened"
-			" after check_file_spec() succeeded!";
-		err = DB_ERROR;
-	}
-
-	return(err);
+  ulint	sum_of_new_sizes;
+
+  /* Will try to remove if there is existing file left-over by last
+  unclean shutdown */
+  srv_tmp_space.set_sanity_check_status(true);
+  srv_tmp_space.delete_files();
+  srv_tmp_space.set_ignore_read_only(true);
+
+  ib::info() << "Creating shared tablespace for temporary tables";
+
+  bool	create_new_temp_space;
+
+  srv_tmp_space.set_space_id(SRV_TMP_SPACE_ID);
+
+  dberr_t	err = srv_tmp_space.check_file_spec(
+    &create_new_temp_space, 12 * 1024 * 1024);
+
+  if (err == DB_FAIL) {
+    ib::error() << "The innodb_temporary"
+      " data file must be writable!";
+    err = DB_ERROR;
+  } else if (err != DB_SUCCESS) {
+    ib::error() << "Could not create the shared innodb_temporary.";
+  } else if ((err = srv_tmp_space.open_or_create(
+          true, create_new_db, &sum_of_new_sizes, NULL))
+       != DB_SUCCESS) {
+    ib::error() << "Unable to create the shared innodb_temporary";
+  } else if (fil_system.temp_space->open()) {
+    /* Initialize the header page */
+    mtr_t mtr;
+    mtr.start();
+    mtr.set_log_mode(MTR_LOG_NO_REDO);
+    fsp_header_init(fil_system.temp_space,
+        srv_tmp_space.get_sum_of_sizes(),
+        &mtr);
+    mtr.commit();
+  } else {
+    /* This file was just opened in the code above! */
+    ib::error() << "The innodb_temporary"
+      " data file cannot be re-opened"
+      " after check_file_spec() succeeded!";
+    err = DB_ERROR;
+  }
+
+  return(err);
 }
 
 /****************************************************************//**
@@ -1039,10 +1039,10 @@ UNIV_INLINE
 void
 srv_start_state_set(
 /*================*/
-	srv_start_state_t state)	/*!< in: indicate current state of
-					thread startup */
+  srv_start_state_t state)	/*!< in: indicate current state of
+          thread startup */
 {
-	srv_start_state |= ulint(state);
+  srv_start_state |= ulint(state);
 }
 
 /****************************************************************//**
@@ -1052,9 +1052,9 @@ UNIV_INLINE
 bool
 srv_start_state_is_set(
 /*===================*/
-	srv_start_state_t state)	/*!< in: state to check for */
+  srv_start_state_t state)	/*!< in: state to check for */
 {
-	return(srv_start_state & ulint(state));
+  return(srv_start_state & ulint(state));
 }
 
 /**
@@ -1063,91 +1063,91 @@ static
 void
 srv_shutdown_all_bg_threads()
 {
-	ut_ad(!srv_undo_sources);
-	srv_shutdown_state = SRV_SHUTDOWN_EXIT_THREADS;
-
-	/* All threads end up waiting for certain events. Put those events
-	to the signaled state. Then the threads will exit themselves after
-	os_event_wait(). */
-	for (uint i = 0; i < 1000; ++i) {
-		/* NOTE: IF YOU CREATE THREADS IN INNODB, YOU MUST EXIT THEM
-		HERE OR EARLIER */
-
-		if (srv_start_state_is_set(SRV_START_STATE_LOCK_SYS)) {
-			/* a. Let the lock timeout thread exit */
-			os_event_set(lock_sys.timeout_event);
-		}
-
-		if (!srv_read_only_mode) {
-			/* b. srv error monitor thread exits automatically,
-			no need to do anything here */
-
-			if (srv_start_state_is_set(SRV_START_STATE_MASTER)) {
-				/* c. We wake the master thread so that
-				it exits */
-				srv_wake_master_thread();
-			}
-
-			if (srv_start_state_is_set(SRV_START_STATE_PURGE)) {
-				/* d. Wakeup purge threads. */
-				srv_purge_wakeup();
-			}
-
-			if (srv_n_fil_crypt_threads_started) {
-				os_event_set(fil_crypt_threads_event);
-			}
-
-			if (log_scrub_thread_active) {
-				os_event_set(log_scrub_event);
-			}
-		}
-
-		if (srv_start_state_is_set(SRV_START_STATE_IO)) {
-			ut_ad(!srv_read_only_mode);
-
-			/* e. Exit the i/o threads */
-			if (recv_sys.flush_start != NULL) {
-				os_event_set(recv_sys.flush_start);
-			}
-			if (recv_sys.flush_end != NULL) {
-				os_event_set(recv_sys.flush_end);
-			}
-
-			os_event_set(buf_flush_event);
-		}
-
-		if (!os_thread_count) {
-			return;
-		}
-
-		switch (srv_operation) {
-		case SRV_OPERATION_BACKUP:
-		case SRV_OPERATION_RESTORE_DELTA:
-			break;
-		case SRV_OPERATION_NORMAL:
-		case SRV_OPERATION_RESTORE:
-		case SRV_OPERATION_RESTORE_EXPORT:
-			if (!buf_page_cleaner_is_active
-			    && os_aio_all_slots_free()) {
-				os_aio_wake_all_threads_at_shutdown();
-			}
-		}
-
-		os_thread_sleep(100000);
-	}
-
-	ib::warn() << os_thread_count << " threads created by InnoDB"
-		" had not exited at shutdown!";
-	ut_d(os_aio_print_pending_io(stderr));
-	ut_ad(0);
+  ut_ad(!srv_undo_sources);
+  srv_shutdown_state = SRV_SHUTDOWN_EXIT_THREADS;
+
+  /* All threads end up waiting for certain events. Put those events
+  to the signaled state. Then the threads will exit themselves after
+  os_event_wait(). */
+  for (uint i = 0; i < 1000; ++i) {
+    /* NOTE: IF YOU CREATE THREADS IN INNODB, YOU MUST EXIT THEM
+    HERE OR EARLIER */
+
+    if (srv_start_state_is_set(SRV_START_STATE_LOCK_SYS)) {
+      /* a. Let the lock timeout thread exit */
+      os_event_set(lock_sys.timeout_event);
+    }
+
+    if (!srv_read_only_mode) {
+      /* b. srv error monitor thread exits automatically,
+      no need to do anything here */
+
+      if (srv_start_state_is_set(SRV_START_STATE_MASTER)) {
+        /* c. We wake the master thread so that
+        it exits */
+        srv_wake_master_thread();
+      }
+
+      if (srv_start_state_is_set(SRV_START_STATE_PURGE)) {
+        /* d. Wakeup purge threads. */
+        srv_purge_wakeup();
+      }
+
+      if (srv_n_fil_crypt_threads_started) {
+        os_event_set(fil_crypt_threads_event);
+      }
+
+      if (log_scrub_thread_active) {
+        os_event_set(log_scrub_event);
+      }
+    }
+
+    if (srv_start_state_is_set(SRV_START_STATE_IO)) {
+      ut_ad(!srv_read_only_mode);
+
+      /* e. Exit the i/o threads */
+      if (recv_sys.flush_start != NULL) {
+        os_event_set(recv_sys.flush_start);
+      }
+      if (recv_sys.flush_end != NULL) {
+        os_event_set(recv_sys.flush_end);
+      }
+
+      os_event_set(buf_flush_event);
+    }
+
+    if (!os_thread_count) {
+      return;
+    }
+
+    switch (srv_operation) {
+    case SRV_OPERATION_BACKUP:
+    case SRV_OPERATION_RESTORE_DELTA:
+      break;
+    case SRV_OPERATION_NORMAL:
+    case SRV_OPERATION_RESTORE:
+    case SRV_OPERATION_RESTORE_EXPORT:
+      if (!buf_page_cleaner_is_active
+          && os_aio_all_slots_free()) {
+        os_aio_wake_all_threads_at_shutdown();
+      }
+    }
+
+    os_thread_sleep(100000);
+  }
+
+  ib::warn() << os_thread_count << " threads created by InnoDB"
+    " had not exited at shutdown!";
+  ut_d(os_aio_print_pending_io(stderr));
+  ut_ad(0);
 }
 
 #ifdef UNIV_DEBUG
 # define srv_init_abort(_db_err)	\
-	srv_init_abort_low(create_new_db, __FILE__, __LINE__, _db_err)
+  srv_init_abort_low(create_new_db, __FILE__, __LINE__, _db_err)
 #else
 # define srv_init_abort(_db_err)	\
-	srv_init_abort_low(create_new_db, _db_err)
+  srv_init_abort_low(create_new_db, _db_err)
 #endif /* UNIV_DEBUG */
 
 /** Innobase start-up aborted. Perform cleanup actions.
@@ -1160,32 +1160,32 @@ MY_ATTRIBUTE((warn_unused_result, nonnull))
 static
 dberr_t
 srv_init_abort_low(
-	bool		create_new_db,
+  bool		create_new_db,
 #ifdef UNIV_DEBUG
-	const char*	file,
-	unsigned	line,
+  const char*	file,
+  unsigned	line,
 #endif /* UNIV_DEBUG */
-	dberr_t		err)
+  dberr_t		err)
 {
-	if (create_new_db) {
-		ib::error() << "Database creation was aborted"
+  if (create_new_db) {
+    ib::error() << "Database creation was aborted"
 #ifdef UNIV_DEBUG
-			" at " << innobase_basename(file) << "[" << line << "]"
+      " at " << innobase_basename(file) << "[" << line << "]"
 #endif /* UNIV_DEBUG */
-			" with error " << ut_strerr(err) << ". You may need"
-			" to delete the ibdata1 file before trying to start"
-			" up again.";
-	} else {
-		ib::error() << "Plugin initialization aborted"
+      " with error " << ut_strerr(err) << ". You may need"
+      " to delete the ibdata1 file before trying to start"
+      " up again.";
+  } else {
+    ib::error() << "Plugin initialization aborted"
 #ifdef UNIV_DEBUG
-			" at " << innobase_basename(file) << "[" << line << "]"
+      " at " << innobase_basename(file) << "[" << line << "]"
 #endif /* UNIV_DEBUG */
-			" with error " << ut_strerr(err);
-	}
+      " with error " << ut_strerr(err);
+  }
 
-	srv_shutdown_bg_undo_sources();
-	srv_shutdown_all_bg_threads();
-	return(err);
+  srv_shutdown_bg_undo_sources();
+  srv_shutdown_all_bg_threads();
+  return(err);
 }
 
 /** Prepare to delete the redo log files. Flush the dirty pages from all the
@@ -1195,97 +1195,97 @@ buffer pools.  Flush the redo log buffer to the redo log file.
 static
 lsn_t
 srv_prepare_to_delete_redo_log_files(
-	ulint	n_files)
+  ulint	n_files)
 {
-	DBUG_ENTER("srv_prepare_to_delete_redo_log_files");
-
-	lsn_t	flushed_lsn;
-	ulint	pending_io = 0;
-	ulint	count = 0;
-
-	if (log_sys.log.subformat != 2) {
-		srv_log_file_size = 0;
-	}
-
-	do {
-		/* Clean the buffer pool. */
-		buf_flush_sync_all_buf_pools();
-
-		DBUG_EXECUTE_IF("innodb_log_abort_1", DBUG_RETURN(0););
-		DBUG_PRINT("ib_log", ("After innodb_log_abort_1"));
-
-		log_mutex_enter();
-
-		fil_names_clear(log_sys.lsn, false);
-
-		flushed_lsn = log_sys.lsn;
-
-		{
-			ib::info	info;
-			if (srv_log_file_size == 0
-			    || (log_sys.log.format & ~log_t::FORMAT_ENCRYPTED)
-			    != log_t::FORMAT_10_4) {
-				info << "Upgrading redo log: ";
-			} else if (n_files != srv_n_log_files
-				   || srv_log_file_size
-				   != srv_log_file_size_requested) {
-				if (srv_encrypt_log
-				    == (my_bool)log_sys.is_encrypted()) {
-					info << (srv_encrypt_log
-						 ? "Resizing encrypted"
-						 : "Resizing");
-				} else if (srv_encrypt_log) {
-					info << "Encrypting and resizing";
-				} else {
-					info << "Removing encryption"
-						" and resizing";
-				}
-
-				info << " redo log from " << n_files
-				     << "*" << srv_log_file_size << " to ";
-			} else if (srv_encrypt_log) {
-				info << "Encrypting redo log: ";
-			} else {
-				info << "Removing redo log encryption: ";
-			}
-
-			info << srv_n_log_files << "*"
-			     << srv_log_file_size_requested
-			     << " bytes; LSN=" << flushed_lsn;
-		}
-
-		srv_start_lsn = flushed_lsn;
-		/* Flush the old log files. */
-		log_mutex_exit();
-
-		log_write_up_to(flushed_lsn, true);
-
-		/* If innodb_flush_method=O_DSYNC,
-		we need to explicitly flush the log buffers. */
-		fil_flush(SRV_LOG_SPACE_FIRST_ID);
-
-		ut_ad(flushed_lsn == log_get_lsn());
-
-		/* Check if the buffer pools are clean.  If not
-		retry till it is clean. */
-		pending_io = buf_pool_check_no_pending_io();
-
-		if (pending_io > 0) {
-			count++;
-			/* Print a message every 60 seconds if we
-			are waiting to clean the buffer pools */
-			if (srv_print_verbose_log && count > 600) {
-				ib::info() << "Waiting for "
-					<< pending_io << " buffer "
-					<< "page I/Os to complete";
-				count = 0;
-			}
-		}
-		os_thread_sleep(100000);
-
-	} while (buf_pool_check_no_pending_io());
-
-	DBUG_RETURN(flushed_lsn);
+  DBUG_ENTER("srv_prepare_to_delete_redo_log_files");
+
+  lsn_t	flushed_lsn;
+  ulint	pending_io = 0;
+  ulint	count = 0;
+
+  if (log_sys.log.subformat != 2) {
+    srv_log_file_size = 0;
+  }
+
+  do {
+    /* Clean the buffer pool. */
+    buf_flush_sync_all_buf_pools();
+
+    DBUG_EXECUTE_IF("innodb_log_abort_1", DBUG_RETURN(0););
+    DBUG_PRINT("ib_log", ("After innodb_log_abort_1"));
+
+    log_mutex_enter();
+
+    fil_names_clear(log_sys.lsn, false);
+
+    flushed_lsn = log_sys.lsn;
+
+    {
+      ib::info	info;
+      if (srv_log_file_size == 0
+          || (log_sys.log.format & ~log_t::FORMAT_ENCRYPTED)
+          != log_t::FORMAT_10_4) {
+        info << "Upgrading redo log: ";
+      } else if (n_files != srv_n_log_files
+           || srv_log_file_size
+           != srv_log_file_size_requested) {
+        if (srv_encrypt_log
+            == (my_bool)log_sys.is_encrypted()) {
+          info << (srv_encrypt_log
+             ? "Resizing encrypted"
+             : "Resizing");
+        } else if (srv_encrypt_log) {
+          info << "Encrypting and resizing";
+        } else {
+          info << "Removing encryption"
+            " and resizing";
+        }
+
+        info << " redo log from " << n_files
+             << "*" << srv_log_file_size << " to ";
+      } else if (srv_encrypt_log) {
+        info << "Encrypting redo log: ";
+      } else {
+        info << "Removing redo log encryption: ";
+      }
+
+      info << srv_n_log_files << "*"
+           << srv_log_file_size_requested
+           << " bytes; LSN=" << flushed_lsn;
+    }
+
+    srv_start_lsn = flushed_lsn;
+    /* Flush the old log files. */
+    log_mutex_exit();
+
+    log_write_up_to(flushed_lsn, true);
+
+    /* If innodb_flush_method=O_DSYNC,
+    we need to explicitly flush the log buffers. */
+    fil_flush(SRV_LOG_SPACE_FIRST_ID);
+
+    ut_ad(flushed_lsn == log_get_lsn());
+
+    /* Check if the buffer pools are clean.  If not
+    retry till it is clean. */
+    pending_io = buf_pool_check_no_pending_io();
+
+    if (pending_io > 0) {
+      count++;
+      /* Print a message every 60 seconds if we
+      are waiting to clean the buffer pools */
+      if (srv_print_verbose_log && count > 600) {
+        ib::info() << "Waiting for "
+          << pending_io << " buffer "
+          << "page I/Os to complete";
+        count = 0;
+      }
+    }
+    os_thread_sleep(100000);
+
+  } while (buf_pool_check_no_pending_io());
+
+  DBUG_RETURN(flushed_lsn);
 }
 
 /** Start InnoDB.
@@ -1293,1282 +1293,1283 @@ srv_prepare_to_delete_redo_log_files(
 @return DB_SUCCESS or error code */
 dberr_t srv_start(bool create_new_db)
 {
-	lsn_t		flushed_lsn;
-	dberr_t		err		= DB_SUCCESS;
-	ulint		srv_n_log_files_found = srv_n_log_files;
-	mtr_t		mtr;
-	char		logfilename[10000];
-	char*		logfile0	= NULL;
-	size_t		dirnamelen;
-	unsigned	i = 0;
+  lsn_t    flushed_lsn;
+  dberr_t  err                   = DB_SUCCESS;
+  ulint    srv_n_log_files_found = srv_n_log_files;
+  mtr_t    mtr;
+  char     logfilename[10000];
+  char*    logfile0	             = NULL;
+  size_t   dirnamelen;
+  unsigned i                     = 0;
 
-	ut_ad(srv_operation == SRV_OPERATION_NORMAL
-	      || srv_operation == SRV_OPERATION_RESTORE
-	      || srv_operation == SRV_OPERATION_RESTORE_EXPORT);
+  ut_ad(srv_operation == SRV_OPERATION_NORMAL
+        || srv_operation == SRV_OPERATION_RESTORE
+        || srv_operation == SRV_OPERATION_RESTORE_EXPORT);
 
-	if (srv_force_recovery == SRV_FORCE_NO_LOG_REDO) {
-		srv_read_only_mode = true;
-	}
+  if (srv_force_recovery == SRV_FORCE_NO_LOG_REDO) {
+    srv_read_only_mode = true;
+  }
 
-	high_level_read_only = srv_read_only_mode
-		|| srv_force_recovery > SRV_FORCE_NO_IBUF_MERGE
-		|| srv_sys_space.created_new_raw();
+  high_level_read_only = srv_read_only_mode
+    || srv_force_recovery > SRV_FORCE_NO_IBUF_MERGE
+    || srv_sys_space.created_new_raw();
 
-	/* Reset the start state. */
-	srv_start_state = SRV_START_STATE_NONE;
+  /* Reset the start state. */
+  srv_start_state = SRV_START_STATE_NONE;
 
-	compile_time_assert(sizeof(ulint) == sizeof(void*));
+  compile_time_assert(sizeof(ulint) == sizeof(void*));
 
 #ifdef UNIV_DEBUG
-	ib::info() << "!!!!!!!! UNIV_DEBUG switched on !!!!!!!!!";
+  ib::info() << "!!!!!!!! UNIV_DEBUG switched on !!!!!!!!!";
 #endif
 
 #ifdef UNIV_IBUF_DEBUG
-	ib::info() << "!!!!!!!! UNIV_IBUF_DEBUG switched on !!!!!!!!!";
+  ib::info() << "!!!!!!!! UNIV_IBUF_DEBUG switched on !!!!!!!!!";
 #endif
 
 #ifdef UNIV_LOG_LSN_DEBUG
-	ib::info() << "!!!!!!!! UNIV_LOG_LSN_DEBUG switched on !!!!!!!!!";
+  ib::info() << "!!!!!!!! UNIV_LOG_LSN_DEBUG switched on !!!!!!!!!";
 #endif /* UNIV_LOG_LSN_DEBUG */
 
 #if defined(COMPILER_HINTS_ENABLED)
-	ib::info() << "Compiler hints enabled.";
+  ib::info() << "Compiler hints enabled.";
 #endif /* defined(COMPILER_HINTS_ENABLED) */
 
 #ifdef _WIN32
-	ib::info() << "Mutexes and rw_locks use Windows interlocked functions";
+  ib::info() << "Mutexes and rw_locks use Windows interlocked functions";
 #else
-	ib::info() << "Mutexes and rw_locks use GCC atomic builtins";
+  ib::info() << "Mutexes and rw_locks use GCC atomic builtins";
 #endif
-	ib::info() << MUTEX_TYPE;
+  ib::info() << MUTEX_TYPE;
 
-	ib::info() << "Compressed tables use zlib " ZLIB_VERSION
+  ib::info() << "Compressed tables use zlib " ZLIB_VERSION
 #ifdef UNIV_ZIP_DEBUG
-	      " with validation"
+        " with validation"
 #endif /* UNIV_ZIP_DEBUG */
-	      ;
+        ;
 #ifdef UNIV_ZIP_COPY
-	ib::info() << "and extra copying";
+  ib::info() << "and extra copying";
 #endif /* UNIV_ZIP_COPY */
 
-	/* Since InnoDB does not currently clean up all its internal data
-	structures in MySQL Embedded Server Library server_end(), we
-	print an error message if someone tries to start up InnoDB a
-	second time during the process lifetime. */
-
-	if (srv_start_has_been_called) {
-		ib::error() << "Startup called second time"
-			" during the process lifetime."
-			" In the MySQL Embedded Server Library"
-			" you cannot call server_init() more than"
-			" once during the process lifetime.";
-	}
-
-	srv_start_has_been_called = true;
-
-	srv_is_being_started = true;
-
-	/* Register performance schema stages before any real work has been
-	started which may need to be instrumented. */
-	mysql_stage_register("innodb", srv_stages, UT_ARR_SIZE(srv_stages));
-
-	/* Set the maximum number of threads which can wait for a semaphore
-	inside InnoDB: this is the 'sync wait array' size, as well as the
-	maximum number of threads that can wait in the 'srv_conc array' for
-	their time to enter InnoDB. */
-
-	srv_max_n_threads = 1   /* io_ibuf_thread */
-			    + 1 /* io_log_thread */
-			    + 1 /* lock_wait_timeout_thread */
-			    + 1 /* srv_error_monitor_thread */
-			    + 1 /* srv_monitor_thread */
-			    + 1 /* srv_master_thread */
-			    + 1 /* srv_purge_coordinator_thread */
-			    + 1 /* buf_dump_thread */
-			    + 1 /* dict_stats_thread */
-			    + 1 /* fts_optimize_thread */
-			    + 1 /* recv_writer_thread */
-			    + 1 /* trx_rollback_all_recovered */
-			    + 128 /* added as margin, for use of
-				  InnoDB Memcached etc. */
-			    + max_connections
-			    + srv_n_read_io_threads
-			    + srv_n_write_io_threads
-			    + srv_n_purge_threads
-			    + srv_n_page_cleaners
-			    /* FTS Parallel Sort */
-			    + fts_sort_pll_degree * FTS_NUM_AUX_INDEX
-			      * max_connections;
-
-	srv_boot();
-
-	ib::info() << ut_crc32_implementation;
-
-	if (!srv_read_only_mode) {
-
-		mutex_create(LATCH_ID_SRV_MONITOR_FILE,
-			     &srv_monitor_file_mutex);
-
-		if (srv_innodb_status) {
-
-			srv_monitor_file_name = static_cast<char*>(
-				ut_malloc_nokey(
-					strlen(fil_path_to_mysql_datadir)
-					+ 20 + sizeof "/innodb_status."));
-
-			sprintf(srv_monitor_file_name,
-				"%s/innodb_status." ULINTPF,
-				fil_path_to_mysql_datadir,
-				os_proc_get_number());
-
-			srv_monitor_file = my_fopen(srv_monitor_file_name,
-						    O_RDWR|O_TRUNC|O_CREAT,
-						    MYF(MY_WME));
-
-			if (!srv_monitor_file) {
-				ib::error() << "Unable to create "
-					<< srv_monitor_file_name << ": "
-					<< strerror(errno);
-				if (err == DB_SUCCESS) {
-					err = DB_ERROR;
-				}
-			}
-		} else {
-
-			srv_monitor_file_name = NULL;
-			srv_monitor_file = os_file_create_tmpfile();
-
-			if (!srv_monitor_file && err == DB_SUCCESS) {
-				err = DB_ERROR;
-			}
-		}
-
-		mutex_create(LATCH_ID_SRV_MISC_TMPFILE,
-			     &srv_misc_tmpfile_mutex);
-
-		srv_misc_tmpfile = os_file_create_tmpfile();
-
-		if (!srv_misc_tmpfile && err == DB_SUCCESS) {
-			err = DB_ERROR;
-		}
-	}
-
-	if (err != DB_SUCCESS) {
-		return(srv_init_abort(err));
-	}
-
-	srv_n_file_io_threads = srv_n_read_io_threads;
-
-	srv_n_file_io_threads += srv_n_write_io_threads;
-
-	if (!srv_read_only_mode) {
-		/* Add the log and ibuf IO threads. */
-		srv_n_file_io_threads += 2;
-	} else {
-		ib::info() << "Disabling background log and ibuf IO write"
-			<< " threads.";
-	}
-
-	ut_a(srv_n_file_io_threads <= SRV_MAX_N_IO_THREADS);
-
-	if (!os_aio_init(srv_n_read_io_threads,
-			 srv_n_write_io_threads,
-			 SRV_MAX_N_PENDING_SYNC_IOS)) {
-
-		ib::error() << "Cannot initialize AIO sub-system";
-
-		return(srv_init_abort(DB_ERROR));
-	}
-
-	fil_system.create(srv_file_per_table ? 50000 : 5000);
-
-	double	size;
-	char	unit;
+  /* Since InnoDB does not currently clean up all its internal data
+  structures in MySQL Embedded Server Library server_end(), we
+  print an error message if someone tries to start up InnoDB a
+  second time during the process lifetime. */
+
+  if (srv_start_has_been_called) {
+    ib::error() << "Startup called second time"
+      " during the process lifetime."
+      " In the MySQL Embedded Server Library"
+      " you cannot call server_init() more than"
+      " once during the process lifetime.";
+  }
+
+  srv_start_has_been_called = true;
+
+  srv_is_being_started = true;
+
+  /* Register performance schema stages before any real work has been
+  started which may need to be instrumented. */
+  mysql_stage_register("innodb", srv_stages, UT_ARR_SIZE(srv_stages));
+
+  /* Set the maximum number of threads which can wait for a semaphore
+  inside InnoDB: this is the 'sync wait array' size, as well as the
+  maximum number of threads that can wait in the 'srv_conc array' for
+  their time to enter InnoDB. */
+
+  srv_max_n_threads = 1   /* io_ibuf_thread */
+          + 1 /* io_log_thread */
+          + 1 /* lock_wait_timeout_thread */
+          + 1 /* srv_error_monitor_thread */
+          + 1 /* srv_monitor_thread */
+          + 1 /* srv_master_thread */
+          + 1 /* srv_purge_coordinator_thread */
+          + 1 /* buf_dump_thread */
+          + 1 /* dict_stats_thread */
+          + 1 /* fts_optimize_thread */
+          + 1 /* recv_writer_thread */
+          + 1 /* trx_rollback_all_recovered */
+          + 128 /* added as margin, for use of
+          InnoDB Memcached etc. */
+          + max_connections
+          + srv_n_read_io_threads
+          + srv_n_write_io_threads
+          + srv_n_purge_threads
+          + srv_n_page_cleaners
+          /* FTS Parallel Sort */
+          + fts_sort_pll_degree * FTS_NUM_AUX_INDEX
+            * max_connections;
+
+  srv_boot();
+
+  ib::info() << ut_crc32_implementation;
+
+  if (!srv_read_only_mode) {
+
+    mutex_create(LATCH_ID_SRV_MONITOR_FILE,
+           &srv_monitor_file_mutex);
+
+    if (srv_innodb_status) {
+
+      srv_monitor_file_name = static_cast<char*>(
+        ut_malloc_nokey(
+          strlen(fil_path_to_mysql_datadir)
+          + 20 + sizeof "/innodb_status."));
+
+      sprintf(srv_monitor_file_name,
+        "%s/innodb_status." ULINTPF,
+        fil_path_to_mysql_datadir,
+        os_proc_get_number());
+
+      srv_monitor_file = my_fopen(srv_monitor_file_name,
+                O_RDWR|O_TRUNC|O_CREAT,
+                MYF(MY_WME));
+
+      if (!srv_monitor_file) {
+        ib::error() << "Unable to create "
+          << srv_monitor_file_name << ": "
+          << strerror(errno);
+        if (err == DB_SUCCESS) {
+          err = DB_ERROR;
+        }
+      }
+    } else {
+
+      srv_monitor_file_name = NULL;
+      srv_monitor_file = os_file_create_tmpfile();
+
+      if (!srv_monitor_file && err == DB_SUCCESS) {
+        err = DB_ERROR;
+      }
+    }
+
+    mutex_create(LATCH_ID_SRV_MISC_TMPFILE,
+           &srv_misc_tmpfile_mutex);
+
+    srv_misc_tmpfile = os_file_create_tmpfile();
+
+    if (!srv_misc_tmpfile && err == DB_SUCCESS) {
+      err = DB_ERROR;
+    }
+  }
+
+  if (err != DB_SUCCESS) {
+    return(srv_init_abort(err));
+  }
+
+  srv_n_file_io_threads = srv_n_read_io_threads;
+
+  srv_n_file_io_threads += srv_n_write_io_threads;
+
+  if (!srv_read_only_mode) {
+    /* Add the log and ibuf IO threads. */
+    srv_n_file_io_threads += 2;
+  } else {
+    ib::info() << "Disabling background log and ibuf IO write"
+      << " threads.";
+  }
+
+  ut_a(srv_n_file_io_threads <= SRV_MAX_N_IO_THREADS);
+
+  if (!os_aio_init(srv_n_read_io_threads,
+       srv_n_write_io_threads,
+       SRV_MAX_N_PENDING_SYNC_IOS)) {
+
+    ib::error() << "Cannot initialize AIO sub-system";
+
+    return(srv_init_abort(DB_ERROR));
+  }
+
+  fil_system.create(srv_file_per_table ? 50000 : 5000);
+
+  double size;
+  char   unit;
 
-	if (srv_buf_pool_size >= 1024 * 1024 * 1024) {
-		size = ((double) srv_buf_pool_size) / (1024 * 1024 * 1024);
-		unit = 'G';
-	} else {
-		size = ((double) srv_buf_pool_size) / (1024 * 1024);
-		unit = 'M';
-	}
+  if (srv_buf_pool_size >= 1024 * 1024 * 1024) {
+    size = ((double) srv_buf_pool_size) / (1024 * 1024 * 1024);
+    unit = 'G';
+  } else {
+    size = ((double) srv_buf_pool_size) / (1024 * 1024);
+    unit = 'M';
+  }
 
-	double	chunk_size;
-	char	chunk_unit;
+  double chunk_size;
+  char   chunk_unit;
 
-	if (srv_buf_pool_chunk_unit >= 1024 * 1024 * 1024) {
-		chunk_size = srv_buf_pool_chunk_unit / 1024.0 / 1024 / 1024;
-		chunk_unit = 'G';
-	} else {
-		chunk_size = srv_buf_pool_chunk_unit / 1024.0 / 1024;
-		chunk_unit = 'M';
-	}
+  if (srv_buf_pool_chunk_unit >= 1024 * 1024 * 1024) {
+    chunk_size = srv_buf_pool_chunk_unit / 1024.0 / 1024 / 1024;
+    chunk_unit = 'G';
+  } else {
+    chunk_size = srv_buf_pool_chunk_unit / 1024.0 / 1024;
+    chunk_unit = 'M';
+  }
 
-	ib::info() << "Initializing buffer pool, total size = "
-		<< size << unit << ", instances = " << srv_buf_pool_instances
-		<< ", chunk size = " << chunk_size << chunk_unit;
+  ib::info() << "Initializing buffer pool, total size = "
+    << size << unit << ", instances = " << srv_buf_pool_instances
+    << ", chunk size = " << chunk_size << chunk_unit
+    << ", with " << sysconf(_SC_NPROCESSORS_ONLN) << " threads";
 
-	err = buf_pool_init(srv_buf_pool_size, srv_buf_pool_instances);
+  err = buf_pool_init(srv_buf_pool_size, srv_buf_pool_instances);
 
-	if (err != DB_SUCCESS) {
-		ib::error() << "Cannot allocate memory for the buffer pool";
+  if (err != DB_SUCCESS) {
+    ib::error() << "Cannot allocate memory for the buffer pool";
 
-		return(srv_init_abort(DB_ERROR));
-	}
+    return(srv_init_abort(DB_ERROR));
+  }
 
-	ib::info() << "Completed initialization of buffer pool";
+  ib::info() << "Completed initialization of buffer pool";
 
 #ifdef UNIV_DEBUG
-	/* We have observed deadlocks with a 5MB buffer pool but
-	the actual lower limit could very well be a little higher. */
+  /* We have observed deadlocks with a 5MB buffer pool but
+  the actual lower limit could very well be a little higher. */
 
-	if (srv_buf_pool_size <= 5 * 1024 * 1024) {
+  if (srv_buf_pool_size <= 5 * 1024 * 1024) {
 
-		ib::info() << "Small buffer pool size ("
-			<< srv_buf_pool_size / 1024 / 1024
-			<< "M), the flst_validate() debug function can cause a"
-			<< " deadlock if the buffer pool fills up.";
-	}
+    ib::info() << "Small buffer pool size ("
+      << srv_buf_pool_size / 1024 / 1024
+      << "M), the flst_validate() debug function can cause a"
+      << " deadlock if the buffer pool fills up.";
+  }
 #endif /* UNIV_DEBUG */
 
-	log_sys.create();
-	recv_sys.create();
-	lock_sys.create(srv_lock_table_size);
+  log_sys.create();
+  recv_sys.create();
+  lock_sys.create(srv_lock_table_size);
 
-	/* Create i/o-handler threads: */
+  /* Create i/o-handler threads: */
 
-	for (ulint t = 0; t < srv_n_file_io_threads; ++t) {
+  for (ulint t = 0; t < srv_n_file_io_threads; ++t) {
 
-		n[t] = t;
+    n[t] = t;
 
-		thread_handles[t] = os_thread_create(io_handler_thread, n + t, thread_ids + t);
-		thread_started[t] = true;
-	}
+    thread_handles[t] = os_thread_create(io_handler_thread, n + t, thread_ids + t);
+    thread_started[t] = true;
+  }
 
-	if (!srv_read_only_mode) {
-		buf_flush_page_cleaner_init();
+  if (!srv_read_only_mode) {
+    buf_flush_page_cleaner_init();
 
-		buf_page_cleaner_is_active = true;
-		os_thread_create(buf_flush_page_cleaner_coordinator,
-				 NULL, NULL);
+    buf_page_cleaner_is_active = true;
+    os_thread_create(buf_flush_page_cleaner_coordinator,
+         NULL, NULL);
 
-		/* Create page cleaner workers if needed. For example
-		mariabackup could set srv_n_page_cleaners = 0. */
-		if (srv_n_page_cleaners > 1) {
-			buf_flush_set_page_cleaner_thread_cnt(srv_n_page_cleaners);
-		}
+    /* Create page cleaner workers if needed. For example
+    mariabackup could set srv_n_page_cleaners = 0. */
+    if (srv_n_page_cleaners > 1) {
+      buf_flush_set_page_cleaner_thread_cnt(srv_n_page_cleaners);
+    }
 
 #ifdef UNIV_LINUX
-		/* Wait for the setpriority() call to finish. */
-		os_event_wait(recv_sys.flush_end);
+    /* Wait for the setpriority() call to finish. */
+    os_event_wait(recv_sys.flush_end);
 #endif /* UNIV_LINUX */
-		srv_start_state_set(SRV_START_STATE_IO);
-	}
-
-	srv_startup_is_before_trx_rollback_phase = !create_new_db;
-
-	/* Check if undo tablespaces and redo log files exist before creating
-	a new system tablespace */
-	if (create_new_db) {
-		err = srv_check_undo_redo_logs_exists();
-		if (err != DB_SUCCESS) {
-			return(srv_init_abort(DB_ERROR));
-		}
-		recv_sys.debug_free();
-	}
-
-	/* Open or create the data files. */
-	ulint	sum_of_new_sizes;
-
-	err = srv_sys_space.open_or_create(
-		false, create_new_db, &sum_of_new_sizes, &flushed_lsn);
-
-	switch (err) {
-	case DB_SUCCESS:
-		break;
-	case DB_CANNOT_OPEN_FILE:
-		ib::error()
-			<< "Could not open or create the system tablespace. If"
-			" you tried to add new data files to the system"
-			" tablespace, and it failed here, you should now"
-			" edit innodb_data_file_path in my.cnf back to what"
-			" it was, and remove the new ibdata files InnoDB"
-			" created in this failed attempt. InnoDB only wrote"
-			" those files full of zeros, but did not yet use"
-			" them in any way. But be careful: do not remove"
-			" old data files which contain your precious data!";
-		/* fall through */
-	default:
-		/* Other errors might come from Datafile::validate_first_page() */
-		return(srv_init_abort(err));
-	}
-
-	dirnamelen = strlen(srv_log_group_home_dir);
-	ut_a(dirnamelen < (sizeof logfilename) - 10 - sizeof "ib_logfile");
-	memcpy(logfilename, srv_log_group_home_dir, dirnamelen);
-
-	/* Add a path separator if needed. */
-	if (dirnamelen && logfilename[dirnamelen - 1] != OS_PATH_SEPARATOR) {
-		logfilename[dirnamelen++] = OS_PATH_SEPARATOR;
-	}
-
-	srv_log_file_size_requested = srv_log_file_size;
-
-	if (innodb_encrypt_temporary_tables && !log_crypt_init()) {
-		return srv_init_abort(DB_ERROR);
-	}
-
-	if (create_new_db) {
-
-		buf_flush_sync_all_buf_pools();
-
-		flushed_lsn = log_get_lsn();
-
-		err = create_log_files(
-			logfilename, dirnamelen, flushed_lsn, logfile0);
-
-		if (err != DB_SUCCESS) {
-			return(srv_init_abort(err));
-		}
-	} else {
-		srv_log_file_size = 0;
-
-		for (i = 0; i < SRV_N_LOG_FILES_MAX; i++) {
-			os_file_stat_t	stat_info;
-
-			sprintf(logfilename + dirnamelen,
-				"ib_logfile%u", i);
-
-			err = os_file_get_status(
-				logfilename, &stat_info, false,
-				srv_read_only_mode);
-
-			if (err == DB_NOT_FOUND) {
-				if (i == 0) {
-					if (srv_operation
-					    == SRV_OPERATION_RESTORE
-					    || srv_operation
-					    == SRV_OPERATION_RESTORE_EXPORT) {
-						return(DB_SUCCESS);
-					}
-				}
-
-				/* opened all files */
-				break;
-			}
-
-			if (stat_info.type != OS_FILE_TYPE_FILE) {
-				break;
-			}
-
-			if (!srv_file_check_mode(logfilename)) {
-				return(srv_init_abort(DB_ERROR));
-			}
-
-			const os_offset_t size = stat_info.size;
-			ut_a(size != (os_offset_t) -1);
-
-			if (size & (OS_FILE_LOG_BLOCK_SIZE - 1)) {
-
-				ib::error() << "Log file " << logfilename
-					<< " size " << size << " is not a"
-					" multiple of 512 bytes";
-				return(srv_init_abort(DB_ERROR));
-			}
-
-			if (i == 0) {
-				if (size == 0
-				    && (srv_operation
-					== SRV_OPERATION_RESTORE
-					|| srv_operation
-					== SRV_OPERATION_RESTORE_EXPORT)) {
-					/* Tolerate an empty ib_logfile0
-					from a previous run of
-					mariabackup --prepare. */
-					return(DB_SUCCESS);
-				}
-				/* The first log file must consist of
-				at least the following 512-byte pages:
-				header, checkpoint page 1, empty,
-				checkpoint page 2, redo log page(s).
-
-				Mariabackup --prepare would create an
-				empty ib_logfile0. Tolerate it if there
-				are no other ib_logfile* files. */
-				if ((size != 0 || i != 0)
-				    && size <= OS_FILE_LOG_BLOCK_SIZE * 4) {
-					ib::error() << "Log file "
-						<< logfilename << " size "
-						<< size << " is too small";
-					return(srv_init_abort(DB_ERROR));
-				}
-				srv_log_file_size = size;
-			} else if (size != srv_log_file_size) {
-
-				ib::error() << "Log file " << logfilename
-					<< " is of different size " << size
-					<< " bytes than other log files "
-					<< srv_log_file_size << " bytes!";
-				return(srv_init_abort(DB_ERROR));
-			}
-		}
-
-		if (srv_log_file_size == 0) {
-			if (flushed_lsn < lsn_t(1000)) {
-				ib::error()
-					<< "Cannot create log files because"
-					" data files are corrupt or the"
-					" database was not shut down cleanly"
-					" after creating the data files.";
-				return srv_init_abort(DB_ERROR);
-			}
-
-			strcpy(logfilename + dirnamelen, "ib_logfile0");
-			srv_log_file_size = srv_log_file_size_requested;
-
-			err = create_log_files(
-				logfilename, dirnamelen,
-				flushed_lsn, logfile0);
-
-			if (err == DB_SUCCESS) {
-				err = create_log_files_rename(
-					logfilename, dirnamelen,
-					flushed_lsn, logfile0);
-			}
-
-			if (err != DB_SUCCESS) {
-				return(srv_init_abort(err));
-			}
-
-			/* Suppress the message about
-			crash recovery. */
-			flushed_lsn = log_get_lsn();
-			goto files_checked;
-		}
-
-		srv_n_log_files_found = i;
-
-		/* Create the in-memory file space objects. */
-
-		sprintf(logfilename + dirnamelen, "ib_logfile%u", 0);
-
-		/* Disable the doublewrite buffer for log files. */
-		fil_space_t*	log_space = fil_space_create(
-			"innodb_redo_log",
-			SRV_LOG_SPACE_FIRST_ID, 0,
-			FIL_TYPE_LOG,
-			NULL /* no encryption yet */);
-
-		ut_a(fil_validate());
-		ut_a(log_space);
-
-		ut_a(srv_log_file_size <= log_group_max_size);
-
-		const ulint size = 1 + ulint((srv_log_file_size - 1)
-					     >> srv_page_size_shift);
-
-		for (unsigned j = 0; j < srv_n_log_files_found; j++) {
-			sprintf(logfilename + dirnamelen, "ib_logfile%u", j);
-
-			log_space->add(logfilename, OS_FILE_CLOSED, size,
-				       false, false);
-		}
-
-		log_sys.log.create(srv_n_log_files_found);
-
-		if (!log_set_capacity(srv_log_file_size_requested)) {
-			return(srv_init_abort(DB_ERROR));
-		}
-	}
+    srv_start_state_set(SRV_START_STATE_IO);
+  }
+
+  srv_startup_is_before_trx_rollback_phase = !create_new_db;
+
+  /* Check if undo tablespaces and redo log files exist before creating
+  a new system tablespace */
+  if (create_new_db) {
+    err = srv_check_undo_redo_logs_exists();
+    if (err != DB_SUCCESS) {
+      return(srv_init_abort(DB_ERROR));
+    }
+    recv_sys.debug_free();
+  }
+
+  /* Open or create the data files. */
+  ulint	sum_of_new_sizes;
+
+  err = srv_sys_space.open_or_create(
+    false, create_new_db, &sum_of_new_sizes, &flushed_lsn);
+
+  switch (err) {
+  case DB_SUCCESS:
+    break;
+  case DB_CANNOT_OPEN_FILE:
+    ib::error()
+      << "Could not open or create the system tablespace. If"
+      " you tried to add new data files to the system"
+      " tablespace, and it failed here, you should now"
+      " edit innodb_data_file_path in my.cnf back to what"
+      " it was, and remove the new ibdata files InnoDB"
+      " created in this failed attempt. InnoDB only wrote"
+      " those files full of zeros, but did not yet use"
+      " them in any way. But be careful: do not remove"
+      " old data files which contain your precious data!";
+    /* fall through */
+  default:
+    /* Other errors might come from Datafile::validate_first_page() */
+    return(srv_init_abort(err));
+  }
+
+  dirnamelen = strlen(srv_log_group_home_dir);
+  ut_a(dirnamelen < (sizeof logfilename) - 10 - sizeof "ib_logfile");
+  memcpy(logfilename, srv_log_group_home_dir, dirnamelen);
+
+  /* Add a path separator if needed. */
+  if (dirnamelen && logfilename[dirnamelen - 1] != OS_PATH_SEPARATOR) {
+    logfilename[dirnamelen++] = OS_PATH_SEPARATOR;
+  }
+
+  srv_log_file_size_requested = srv_log_file_size;
+
+  if (innodb_encrypt_temporary_tables && !log_crypt_init()) {
+    return srv_init_abort(DB_ERROR);
+  }
+
+  if (create_new_db) {
+
+    buf_flush_sync_all_buf_pools();
+
+    flushed_lsn = log_get_lsn();
+
+    err = create_log_files(
+      logfilename, dirnamelen, flushed_lsn, logfile0);
+
+    if (err != DB_SUCCESS) {
+      return(srv_init_abort(err));
+    }
+  } else {
+    srv_log_file_size = 0;
+
+    for (i = 0; i < SRV_N_LOG_FILES_MAX; i++) {
+      os_file_stat_t	stat_info;
+
+      sprintf(logfilename + dirnamelen,
+        "ib_logfile%u", i);
+
+      err = os_file_get_status(
+        logfilename, &stat_info, false,
+        srv_read_only_mode);
+
+      if (err == DB_NOT_FOUND) {
+        if (i == 0) {
+          if (srv_operation
+              == SRV_OPERATION_RESTORE
+              || srv_operation
+              == SRV_OPERATION_RESTORE_EXPORT) {
+            return(DB_SUCCESS);
+          }
+        }
+
+        /* opened all files */
+        break;
+      }
+
+      if (stat_info.type != OS_FILE_TYPE_FILE) {
+        break;
+      }
+
+      if (!srv_file_check_mode(logfilename)) {
+        return(srv_init_abort(DB_ERROR));
+      }
+
+      const os_offset_t size = stat_info.size;
+      ut_a(size != (os_offset_t) -1);
+
+      if (size & (OS_FILE_LOG_BLOCK_SIZE - 1)) {
+
+        ib::error() << "Log file " << logfilename
+          << " size " << size << " is not a"
+          " multiple of 512 bytes";
+        return(srv_init_abort(DB_ERROR));
+      }
+
+      if (i == 0) {
+        if (size == 0
+            && (srv_operation
+          == SRV_OPERATION_RESTORE
+          || srv_operation
+          == SRV_OPERATION_RESTORE_EXPORT)) {
+          /* Tolerate an empty ib_logfile0
+          from a previous run of
+          mariabackup --prepare. */
+          return(DB_SUCCESS);
+        }
+        /* The first log file must consist of
+        at least the following 512-byte pages:
+        header, checkpoint page 1, empty,
+        checkpoint page 2, redo log page(s).
+
+        Mariabackup --prepare would create an
+        empty ib_logfile0. Tolerate it if there
+        are no other ib_logfile* files. */
+        if ((size != 0 || i != 0)
+            && size <= OS_FILE_LOG_BLOCK_SIZE * 4) {
+          ib::error() << "Log file "
+            << logfilename << " size "
+            << size << " is too small";
+          return(srv_init_abort(DB_ERROR));
+        }
+        srv_log_file_size = size;
+      } else if (size != srv_log_file_size) {
+
+        ib::error() << "Log file " << logfilename
+          << " is of different size " << size
+          << " bytes than other log files "
+          << srv_log_file_size << " bytes!";
+        return(srv_init_abort(DB_ERROR));
+      }
+    }
+
+    if (srv_log_file_size == 0) {
+      if (flushed_lsn < lsn_t(1000)) {
+        ib::error()
+          << "Cannot create log files because"
+          " data files are corrupt or the"
+          " database was not shut down cleanly"
+          " after creating the data files.";
+        return srv_init_abort(DB_ERROR);
+      }
+
+      strcpy(logfilename + dirnamelen, "ib_logfile0");
+      srv_log_file_size = srv_log_file_size_requested;
+
+      err = create_log_files(
+        logfilename, dirnamelen,
+        flushed_lsn, logfile0);
+
+      if (err == DB_SUCCESS) {
+        err = create_log_files_rename(
+          logfilename, dirnamelen,
+          flushed_lsn, logfile0);
+      }
+
+      if (err != DB_SUCCESS) {
+        return(srv_init_abort(err));
+      }
+
+      /* Suppress the message about
+      crash recovery. */
+      flushed_lsn = log_get_lsn();
+      goto files_checked;
+    }
+
+    srv_n_log_files_found = i;
+
+    /* Create the in-memory file space objects. */
+
+    sprintf(logfilename + dirnamelen, "ib_logfile%u", 0);
+
+    /* Disable the doublewrite buffer for log files. */
+    fil_space_t*	log_space = fil_space_create(
+      "innodb_redo_log",
+      SRV_LOG_SPACE_FIRST_ID, 0,
+      FIL_TYPE_LOG,
+      NULL /* no encryption yet */);
+
+    ut_a(fil_validate());
+    ut_a(log_space);
+
+    ut_a(srv_log_file_size <= log_group_max_size);
+
+    const ulint size = 1 + ulint((srv_log_file_size - 1)
+               >> srv_page_size_shift);
+
+    for (unsigned j = 0; j < srv_n_log_files_found; j++) {
+      sprintf(logfilename + dirnamelen, "ib_logfile%u", j);
+
+      log_space->add(logfilename, OS_FILE_CLOSED, size,
+               false, false);
+    }
+
+    log_sys.log.create(srv_n_log_files_found);
+
+    if (!log_set_capacity(srv_log_file_size_requested)) {
+      return(srv_init_abort(DB_ERROR));
+    }
+  }
 
 files_checked:
-	/* Open all log files and data files in the system
-	tablespace: we keep them open until database
-	shutdown */
+  /* Open all log files and data files in the system
+  tablespace: we keep them open until database
+  shutdown */
 
-	fil_open_log_and_system_tablespace_files();
-	ut_d(fil_system.sys_space->recv_size = srv_sys_space_size_debug);
+  fil_open_log_and_system_tablespace_files();
+  ut_d(fil_system.sys_space->recv_size = srv_sys_space_size_debug);
 
-	err = srv_undo_tablespaces_init(create_new_db);
+  err = srv_undo_tablespaces_init(create_new_db);
 
-	/* If the force recovery is set very high then we carry on regardless
-	of all errors. Basically this is fingers crossed mode. */
-
-	if (err != DB_SUCCESS
-	    && srv_force_recovery < SRV_FORCE_NO_UNDO_LOG_SCAN) {
+  /* If the force recovery is set very high then we carry on regardless
+  of all errors. Basically this is fingers crossed mode. */
+
+  if (err != DB_SUCCESS
+      && srv_force_recovery < SRV_FORCE_NO_UNDO_LOG_SCAN) {
 
-		return(srv_init_abort(err));
-	}
-
-	/* Initialize objects used by dict stats gathering thread, which
-	can also be used by recovery if it tries to drop some table */
-	if (!srv_read_only_mode) {
-		dict_stats_thread_init();
-	}
-
-	trx_sys.create();
+    return(srv_init_abort(err));
+  }
+
+  /* Initialize objects used by dict stats gathering thread, which
+  can also be used by recovery if it tries to drop some table */
+  if (!srv_read_only_mode) {
+    dict_stats_thread_init();
+  }
+
+  trx_sys.create();
 
-	if (create_new_db) {
-		ut_a(!srv_read_only_mode);
+  if (create_new_db) {
+    ut_a(!srv_read_only_mode);
 
-		mtr_start(&mtr);
-		ut_ad(fil_system.sys_space->id == 0);
-		compile_time_assert(TRX_SYS_SPACE == 0);
-		compile_time_assert(IBUF_SPACE_ID == 0);
-		fsp_header_init(fil_system.sys_space, sum_of_new_sizes, &mtr);
+    mtr_start(&mtr);
+    ut_ad(fil_system.sys_space->id == 0);
+    compile_time_assert(TRX_SYS_SPACE == 0);
+    compile_time_assert(IBUF_SPACE_ID == 0);
+    fsp_header_init(fil_system.sys_space, sum_of_new_sizes, &mtr);
 
-		ulint ibuf_root = btr_create(
-			DICT_CLUSTERED | DICT_IBUF, fil_system.sys_space,
-			DICT_IBUF_ID_MIN, dict_ind_redundant, &mtr);
-
-		mtr_commit(&mtr);
-
-		if (ibuf_root == FIL_NULL) {
-			return(srv_init_abort(DB_ERROR));
-		}
-
-		ut_ad(ibuf_root == IBUF_TREE_ROOT_PAGE_NO);
-
-		/* To maintain backward compatibility we create only
-		the first rollback segment before the double write buffer.
-		All the remaining rollback segments will be created later,
-		after the double write buffer has been created. */
-		trx_sys_create_sys_pages();
-		trx_lists_init_at_db_start();
-
-		err = dict_create();
-
-		if (err != DB_SUCCESS) {
-			return(srv_init_abort(err));
-		}
-
-		buf_flush_sync_all_buf_pools();
-
-		flushed_lsn = log_get_lsn();
-
-		err = fil_write_flushed_lsn(flushed_lsn);
-
-		if (err == DB_SUCCESS) {
-			err = create_log_files_rename(
-				logfilename, dirnamelen,
-				flushed_lsn, logfile0);
-		}
-
-		if (err != DB_SUCCESS) {
-			return(srv_init_abort(err));
-		}
-	} else {
-		/* Work around the bug that we were performing a dirty read of
-		at least the TRX_SYS page into the buffer pool above, without
-		reading or applying any redo logs.
-
-		MDEV-19229 FIXME: Remove the dirty reads and this call.
-		Add an assertion that the buffer pool is empty. */
-		buf_pool_invalidate();
-
-		/* We always try to do a recovery, even if the database had
-		been shut down normally: this is the normal startup path */
-
-		err = recv_recovery_from_checkpoint_start(flushed_lsn);
-
-		recv_sys.dblwr.pages.clear();
-
-		if (err != DB_SUCCESS) {
-			return(srv_init_abort(err));
-		}
-
-		switch (srv_operation) {
-		case SRV_OPERATION_NORMAL:
-		case SRV_OPERATION_RESTORE_EXPORT:
-			/* Initialize the change buffer. */
-			err = dict_boot();
-			if (err != DB_SUCCESS) {
-				return(srv_init_abort(err));
-			}
-			/* fall through */
-		case SRV_OPERATION_RESTORE:
-			/* This must precede
-			recv_apply_hashed_log_recs(true). */
-			trx_lists_init_at_db_start();
-			break;
-		case SRV_OPERATION_RESTORE_DELTA:
-		case SRV_OPERATION_BACKUP:
-			ut_ad(!"wrong mariabackup mode");
-		}
-
-		if (srv_force_recovery < SRV_FORCE_NO_LOG_REDO) {
-			/* Apply the hashed log records to the
-			respective file pages, for the last batch of
-			recv_group_scan_log_recs(). */
-
-			recv_apply_hashed_log_recs(true);
-
-			if (recv_sys.found_corrupt_log
-			    || recv_sys.found_corrupt_fs) {
-				return(srv_init_abort(DB_CORRUPTION));
-			}
-
-			DBUG_PRINT("ib_log", ("apply completed"));
-
-			if (recv_needed_recovery) {
-				trx_sys_print_mysql_binlog_offset();
-			}
-		}
-
-		if (!srv_read_only_mode) {
-			const ulint flags = FSP_FLAGS_PAGE_SSIZE();
-			for (ulint id = 0; id <= srv_undo_tablespaces; id++) {
-				if (fil_space_t* space = fil_space_get(id)) {
-					fsp_flags_try_adjust(space, flags);
-				}
-			}
-
-			if (sum_of_new_sizes > 0) {
-				/* New data file(s) were added */
-				mtr.start();
-				buf_block_t* block = buf_page_get(
-					page_id_t(0, 0), 0,
-					RW_SX_LATCH, &mtr);
-				ulint size = mach_read_from_4(
-					FSP_HEADER_OFFSET + FSP_SIZE
-					+ block->frame);
-				ut_ad(size == fil_system.sys_space
-				      ->size_in_header);
-				size += sum_of_new_sizes;
-				mlog_write_ulint(FSP_HEADER_OFFSET + FSP_SIZE
-						 + block->frame, size,
-						 MLOG_4BYTES, &mtr);
-				fil_system.sys_space->size_in_header = size;
-				mtr.commit();
-				/* Immediately write the log record about
-				increased tablespace size to disk, so that it
-				is durable even if mysqld would crash
-				quickly */
-				log_buffer_flush_to_disk();
-			}
-		}
+    ulint ibuf_root = btr_create(
+      DICT_CLUSTERED | DICT_IBUF, fil_system.sys_space,
+      DICT_IBUF_ID_MIN, dict_ind_redundant, &mtr);
+
+    mtr_commit(&mtr);
+
+    if (ibuf_root == FIL_NULL) {
+      return(srv_init_abort(DB_ERROR));
+    }
+
+    ut_ad(ibuf_root == IBUF_TREE_ROOT_PAGE_NO);
+
+    /* To maintain backward compatibility we create only
+    the first rollback segment before the double write buffer.
+    All the remaining rollback segments will be created later,
+    after the double write buffer has been created. */
+    trx_sys_create_sys_pages();
+    trx_lists_init_at_db_start();
+
+    err = dict_create();
+
+    if (err != DB_SUCCESS) {
+      return(srv_init_abort(err));
+    }
+
+    buf_flush_sync_all_buf_pools();
+
+    flushed_lsn = log_get_lsn();
+
+    err = fil_write_flushed_lsn(flushed_lsn);
+
+    if (err == DB_SUCCESS) {
+      err = create_log_files_rename(
+        logfilename, dirnamelen,
+        flushed_lsn, logfile0);
+    }
+
+    if (err != DB_SUCCESS) {
+      return(srv_init_abort(err));
+    }
+  } else {
+    /* Work around the bug that we were performing a dirty read of
+    at least the TRX_SYS page into the buffer pool above, without
+    reading or applying any redo logs.
+
+    MDEV-19229 FIXME: Remove the dirty reads and this call.
+    Add an assertion that the buffer pool is empty. */
+    buf_pool_invalidate();
+
+    /* We always try to do a recovery, even if the database had
+    been shut down normally: this is the normal startup path */
+
+    err = recv_recovery_from_checkpoint_start(flushed_lsn);
+
+    recv_sys.dblwr.pages.clear();
+
+    if (err != DB_SUCCESS) {
+      return(srv_init_abort(err));
+    }
+
+    switch (srv_operation) {
+    case SRV_OPERATION_NORMAL:
+    case SRV_OPERATION_RESTORE_EXPORT:
+      /* Initialize the change buffer. */
+      err = dict_boot();
+      if (err != DB_SUCCESS) {
+        return(srv_init_abort(err));
+      }
+      /* fall through */
+    case SRV_OPERATION_RESTORE:
+      /* This must precede
+      recv_apply_hashed_log_recs(true). */
+      trx_lists_init_at_db_start();
+      break;
+    case SRV_OPERATION_RESTORE_DELTA:
+    case SRV_OPERATION_BACKUP:
+      ut_ad(!"wrong mariabackup mode");
+    }
+
+    if (srv_force_recovery < SRV_FORCE_NO_LOG_REDO) {
+      /* Apply the hashed log records to the
+      respective file pages, for the last batch of
+      recv_group_scan_log_recs(). */
+
+      recv_apply_hashed_log_recs(true);
+
+      if (recv_sys.found_corrupt_log
+          || recv_sys.found_corrupt_fs) {
+        return(srv_init_abort(DB_CORRUPTION));
+      }
+
+      DBUG_PRINT("ib_log", ("apply completed"));
+
+      if (recv_needed_recovery) {
+        trx_sys_print_mysql_binlog_offset();
+      }
+    }
+
+    if (!srv_read_only_mode) {
+      const ulint flags = FSP_FLAGS_PAGE_SSIZE();
+      for (ulint id = 0; id <= srv_undo_tablespaces; id++) {
+        if (fil_space_t* space = fil_space_get(id)) {
+          fsp_flags_try_adjust(space, flags);
+        }
+      }
+
+      if (sum_of_new_sizes > 0) {
+        /* New data file(s) were added */
+        mtr.start();
+        buf_block_t* block = buf_page_get(
+          page_id_t(0, 0), 0,
+          RW_SX_LATCH, &mtr);
+        ulint size = mach_read_from_4(
+          FSP_HEADER_OFFSET + FSP_SIZE
+          + block->frame);
+        ut_ad(size == fil_system.sys_space
+              ->size_in_header);
+        size += sum_of_new_sizes;
+        mlog_write_ulint(FSP_HEADER_OFFSET + FSP_SIZE
+             + block->frame, size,
+             MLOG_4BYTES, &mtr);
+        fil_system.sys_space->size_in_header = size;
+        mtr.commit();
+        /* Immediately write the log record about
+        increased tablespace size to disk, so that it
+        is durable even if mysqld would crash
+        quickly */
+        log_buffer_flush_to_disk();
+      }
+    }
 
 #ifdef UNIV_DEBUG
-		{
-			mtr.start();
-			buf_block_t* block = buf_page_get(page_id_t(0, 0), 0,
-							  RW_S_LATCH, &mtr);
-			ut_ad(mach_read_from_4(FSP_SIZE + FSP_HEADER_OFFSET
-					       + block->frame)
-			      == fil_system.sys_space->size_in_header);
-			mtr.commit();
-		}
+    {
+      mtr.start();
+      buf_block_t* block = buf_page_get(page_id_t(0, 0), 0,
+                RW_S_LATCH, &mtr);
+      ut_ad(mach_read_from_4(FSP_SIZE + FSP_HEADER_OFFSET
+                 + block->frame)
+            == fil_system.sys_space->size_in_header);
+      mtr.commit();
+    }
 #endif
-		const ulint	tablespace_size_in_header
-			= fil_system.sys_space->size_in_header;
-		const ulint	sum_of_data_file_sizes
-			= srv_sys_space.get_sum_of_sizes();
-		/* Compare the system tablespace file size to what is
-		stored in FSP_SIZE. In srv_sys_space.open_or_create()
-		we already checked that the file sizes match the
-		innodb_data_file_path specification. */
-		if (srv_read_only_mode
-		    || sum_of_data_file_sizes == tablespace_size_in_header) {
-			/* Do not complain about the size. */
-		} else if (!srv_sys_space.can_auto_extend_last_file()
-			   || sum_of_data_file_sizes
-			   < tablespace_size_in_header) {
-			ib::error() << "Tablespace size stored in header is "
-				<< tablespace_size_in_header
-				<< " pages, but the sum of data file sizes is "
-				<< sum_of_data_file_sizes << " pages";
-
-			if (srv_force_recovery == 0
-			    && sum_of_data_file_sizes
-			    < tablespace_size_in_header) {
-				ib::error() <<
-					"Cannot start InnoDB. The tail of"
-					" the system tablespace is"
-					" missing. Have you edited"
-					" innodb_data_file_path in my.cnf"
-					" in an inappropriate way, removing"
-					" data files from there?"
-					" You can set innodb_force_recovery=1"
-					" in my.cnf to force"
-					" a startup if you are trying to"
-					" recover a badly corrupt database.";
-
-				return(srv_init_abort(DB_ERROR));
-			}
-		}
-
-		/* recv_recovery_from_checkpoint_finish needs trx lists which
-		are initialized in trx_lists_init_at_db_start(). */
-
-		recv_recovery_from_checkpoint_finish();
-
-		if (srv_operation == SRV_OPERATION_RESTORE
-		    || srv_operation == SRV_OPERATION_RESTORE_EXPORT) {
-			/* After applying the redo log from
-			SRV_OPERATION_BACKUP, flush the changes
-			to the data files and truncate or delete the log.
-			Unless --export is specified, no further change to
-			InnoDB files is needed. */
-			ut_ad(!srv_force_recovery);
-			ut_ad(srv_n_log_files_found <= 1);
-			ut_ad(recv_no_log_write);
-			buf_flush_sync_all_buf_pools();
-			err = fil_write_flushed_lsn(log_get_lsn());
-			ut_ad(!buf_pool_check_no_pending_io());
-			fil_close_log_files(true);
-			if (err == DB_SUCCESS) {
-				bool trunc = srv_operation
-					== SRV_OPERATION_RESTORE;
-				/* Delete subsequent log files. */
-				delete_log_files(logfilename, dirnamelen,
-						 (uint)srv_n_log_files_found, trunc);
-				if (trunc) {
-					/* Truncate the first log file. */
-					strcpy(logfilename + dirnamelen,
-					       "ib_logfile0");
-					FILE* f = fopen(logfilename, "w");
-					fclose(f);
-				}
-			}
-			return(err);
-		}
-
-		/* Upgrade or resize or rebuild the redo logs before
-		generating any dirty pages, so that the old redo log
-		files will not be written to. */
-
-		if (srv_force_recovery == SRV_FORCE_NO_LOG_REDO) {
-			/* Completely ignore the redo log. */
-		} else if (srv_read_only_mode) {
-			/* Leave the redo log alone. */
-		} else if (srv_log_file_size_requested == srv_log_file_size
-			   && srv_n_log_files_found == srv_n_log_files
-			   && log_sys.log.format
-			   == (srv_encrypt_log
-			       ? log_t::FORMAT_ENC_10_4
-			       : log_t::FORMAT_10_4)
-			   && log_sys.log.subformat == 2) {
-			/* No need to add or remove encryption,
-			upgrade, downgrade, or resize. */
-		} else {
-			/* Prepare to delete the old redo log files */
-			flushed_lsn = srv_prepare_to_delete_redo_log_files(i);
-
-			DBUG_EXECUTE_IF("innodb_log_abort_1",
-					return(srv_init_abort(DB_ERROR)););
-			/* Prohibit redo log writes from any other
-			threads until creating a log checkpoint at the
-			end of create_log_files(). */
-			ut_d(recv_no_log_write = true);
-			ut_ad(!buf_pool_check_no_pending_io());
-
-			DBUG_EXECUTE_IF("innodb_log_abort_3",
-					return(srv_init_abort(DB_ERROR)););
-			DBUG_PRINT("ib_log", ("After innodb_log_abort_3"));
-
-			/* Stamp the LSN to the data files. */
-			err = fil_write_flushed_lsn(flushed_lsn);
-
-			DBUG_EXECUTE_IF("innodb_log_abort_4", err = DB_ERROR;);
-			DBUG_PRINT("ib_log", ("After innodb_log_abort_4"));
-
-			if (err != DB_SUCCESS) {
-				return(srv_init_abort(err));
-			}
-
-			/* Close and free the redo log files, so that
-			we can replace them. */
-			fil_close_log_files(true);
-
-			DBUG_EXECUTE_IF("innodb_log_abort_5",
-					return(srv_init_abort(DB_ERROR)););
-			DBUG_PRINT("ib_log", ("After innodb_log_abort_5"));
-
-			ib::info() << "Starting to delete and rewrite log"
-				" files.";
-
-			srv_log_file_size = srv_log_file_size_requested;
-
-			err = create_log_files(
-				logfilename, dirnamelen, flushed_lsn,
-				logfile0);
-
-			if (err == DB_SUCCESS) {
-				err = create_log_files_rename(
-					logfilename, dirnamelen, flushed_lsn,
-					logfile0);
-			}
-
-			if (err != DB_SUCCESS) {
-				return(srv_init_abort(err));
-			}
-		}
-	}
-
-	ut_ad(err == DB_SUCCESS);
-	ut_a(sum_of_new_sizes != ULINT_UNDEFINED);
-
-	/* Create the doublewrite buffer to a new tablespace */
-	if (!srv_read_only_mode && srv_force_recovery < SRV_FORCE_NO_TRX_UNDO
-	    && !buf_dblwr_create()) {
-		return(srv_init_abort(DB_ERROR));
-	}
-
-	/* Here the double write buffer has already been created and so
-	any new rollback segments will be allocated after the double
-	write buffer. The default segment should already exist.
-	We create the new segments only if it's a new database or
-	the database was shutdown cleanly. */
-
-	/* Note: When creating the extra rollback segments during an upgrade
-	we violate the latching order, even if the change buffer is empty.
-	We make an exception in sync0sync.cc and check srv_is_being_started
-	for that violation. It cannot create a deadlock because we are still
-	running in single threaded mode essentially. Only the IO threads
-	should be running at this stage. */
-
-	if (!trx_sys_create_rsegs()) {
-		return(srv_init_abort(DB_ERROR));
-	}
-
-	if (!create_new_db) {
-		/* Validate a few system page types that were left
-		uninitialized before MySQL or MariaDB 5.5. */
-		if (!high_level_read_only) {
-			ut_ad(srv_force_recovery <= SRV_FORCE_NO_IBUF_MERGE);
-			buf_block_t*	block;
-			mtr.start();
-			/* Bitmap page types will be reset in
-			buf_dblwr_check_block() without redo logging. */
-			block = buf_page_get(
-				page_id_t(IBUF_SPACE_ID,
-					  FSP_IBUF_HEADER_PAGE_NO),
-				0, RW_X_LATCH, &mtr);
-			fil_block_check_type(*block, FIL_PAGE_TYPE_SYS, &mtr);
-			/* Already MySQL 3.23.53 initialized
-			FSP_IBUF_TREE_ROOT_PAGE_NO to
-			FIL_PAGE_INDEX. No need to reset that one. */
-			block = buf_page_get(
-				page_id_t(TRX_SYS_SPACE, TRX_SYS_PAGE_NO),
-				0, RW_X_LATCH, &mtr);
-			fil_block_check_type(*block, FIL_PAGE_TYPE_TRX_SYS,
-					     &mtr);
-			block = buf_page_get(
-				page_id_t(TRX_SYS_SPACE,
-					  FSP_FIRST_RSEG_PAGE_NO),
-				0, RW_X_LATCH, &mtr);
-			fil_block_check_type(*block, FIL_PAGE_TYPE_SYS, &mtr);
-			block = buf_page_get(
-				page_id_t(TRX_SYS_SPACE, FSP_DICT_HDR_PAGE_NO),
-				0, RW_X_LATCH, &mtr);
-			fil_block_check_type(*block, FIL_PAGE_TYPE_SYS, &mtr);
-			mtr.commit();
-
-			/* Roll back any recovered data dictionary
-			transactions, so that the data dictionary
-			tables will be free of any locks.  The data
-			dictionary latch should guarantee that there
-			is at most one data dictionary transaction
-			active at a time. */
-			if (srv_force_recovery < SRV_FORCE_NO_TRX_UNDO) {
-				/* If the following call is ever
-				removed, the first-time
-				ha_innobase::open() must hold (or
-				acquire and release) a table lock that
-				conflicts with
-				trx_resurrect_table_locks(), to ensure
-				that any recovered incomplete ALTER
-				TABLE will have been rolled
-				back. Otherwise, dict_table_t::instant
-				could be cleared by rollback invoking
-				dict_index_t::clear_instant_alter()
-				while open table handles exist in
-				client connections. */
-				trx_rollback_recovered(false);
-			}
-		}
-
-		/* FIXME: Skip the following if srv_read_only_mode,
-		while avoiding "Allocated tablespace ID" warnings. */
-		if (srv_force_recovery <= SRV_FORCE_NO_IBUF_MERGE) {
-			/* Open or Create SYS_TABLESPACES and SYS_DATAFILES
-			so that tablespace names and other metadata can be
-			found. */
-			err = dict_create_or_check_sys_tablespace();
-			if (err != DB_SUCCESS) {
-				return(srv_init_abort(err));
-			}
-
-			/* The following call is necessary for the insert
-			buffer to work with multiple tablespaces. We must
-			know the mapping between space id's and .ibd file
-			names.
-
-			In a crash recovery, we check that the info in data
-			dictionary is consistent with what we already know
-			about space id's from the calls to fil_ibd_load().
-
-			In a normal startup, we create the space objects for
-			every table in the InnoDB data dictionary that has
-			an .ibd file.
-
-			We also determine the maximum tablespace id used. */
-			dict_check_tablespaces_and_store_max_id();
-		}
-
-		if (srv_force_recovery < SRV_FORCE_NO_TRX_UNDO
-		    && !srv_read_only_mode) {
-			/* Drop partially created indexes. */
-			row_merge_drop_temp_indexes();
-			/* Drop garbage tables. */
-			row_mysql_drop_garbage_tables();
-
-			/* Drop any auxiliary tables that were not
-			dropped when the parent table was
-			dropped. This can happen if the parent table
-			was dropped but the server crashed before the
-			auxiliary tables were dropped. */
-			fts_drop_orphaned_tables();
-
-			/* Rollback incomplete non-DDL transactions */
-			trx_rollback_is_active = true;
-			os_thread_create(trx_rollback_all_recovered, 0, 0);
-		}
-	}
-
-	srv_startup_is_before_trx_rollback_phase = false;
-
-	if (!srv_read_only_mode) {
-		/* Create the thread which watches the timeouts
-		for lock waits */
-		thread_handles[2 + SRV_MAX_N_IO_THREADS] = os_thread_create(
-			lock_wait_timeout_thread,
-			NULL, thread_ids + 2 + SRV_MAX_N_IO_THREADS);
-		thread_started[2 + SRV_MAX_N_IO_THREADS] = true;
-		lock_sys.timeout_thread_active = true;
-
-		DBUG_EXECUTE_IF("innodb_skip_monitors", goto skip_monitors;);
-		/* Create the thread which warns of long semaphore waits */
-		srv_error_monitor_active = true;
-		thread_handles[3 + SRV_MAX_N_IO_THREADS] = os_thread_create(
-			srv_error_monitor_thread,
-			NULL, thread_ids + 3 + SRV_MAX_N_IO_THREADS);
-		thread_started[3 + SRV_MAX_N_IO_THREADS] = true;
-
-		/* Create the thread which prints InnoDB monitor info */
-		srv_monitor_active = true;
-		thread_handles[4 + SRV_MAX_N_IO_THREADS] = os_thread_create(
-			srv_monitor_thread,
-			NULL, thread_ids + 4 + SRV_MAX_N_IO_THREADS);
-		thread_started[4 + SRV_MAX_N_IO_THREADS] = true;
-		srv_start_state |= SRV_START_STATE_LOCK_SYS
-			| SRV_START_STATE_MONITOR;
+    const ulint	tablespace_size_in_header
+      = fil_system.sys_space->size_in_header;
+    const ulint	sum_of_data_file_sizes
+      = srv_sys_space.get_sum_of_sizes();
+    /* Compare the system tablespace file size to what is
+    stored in FSP_SIZE. In srv_sys_space.open_or_create()
+    we already checked that the file sizes match the
+    innodb_data_file_path specification. */
+    if (srv_read_only_mode
+        || sum_of_data_file_sizes == tablespace_size_in_header) {
+      /* Do not complain about the size. */
+    } else if (!srv_sys_space.can_auto_extend_last_file()
+         || sum_of_data_file_sizes
+         < tablespace_size_in_header) {
+      ib::error() << "Tablespace size stored in header is "
+        << tablespace_size_in_header
+        << " pages, but the sum of data file sizes is "
+        << sum_of_data_file_sizes << " pages";
+
+      if (srv_force_recovery == 0
+          && sum_of_data_file_sizes
+          < tablespace_size_in_header) {
+        ib::error() <<
+          "Cannot start InnoDB. The tail of"
+          " the system tablespace is"
+          " missing. Have you edited"
+          " innodb_data_file_path in my.cnf"
+          " in an inappropriate way, removing"
+          " data files from there?"
+          " You can set innodb_force_recovery=1"
+          " in my.cnf to force"
+          " a startup if you are trying to"
+          " recover a badly corrupt database.";
+
+        return(srv_init_abort(DB_ERROR));
+      }
+    }
+
+    /* recv_recovery_from_checkpoint_finish needs trx lists which
+    are initialized in trx_lists_init_at_db_start(). */
+
+    recv_recovery_from_checkpoint_finish();
+
+    if (srv_operation == SRV_OPERATION_RESTORE
+        || srv_operation == SRV_OPERATION_RESTORE_EXPORT) {
+      /* After applying the redo log from
+      SRV_OPERATION_BACKUP, flush the changes
+      to the data files and truncate or delete the log.
+      Unless --export is specified, no further change to
+      InnoDB files is needed. */
+      ut_ad(!srv_force_recovery);
+      ut_ad(srv_n_log_files_found <= 1);
+      ut_ad(recv_no_log_write);
+      buf_flush_sync_all_buf_pools();
+      err = fil_write_flushed_lsn(log_get_lsn());
+      ut_ad(!buf_pool_check_no_pending_io());
+      fil_close_log_files(true);
+      if (err == DB_SUCCESS) {
+        bool trunc = srv_operation
+          == SRV_OPERATION_RESTORE;
+        /* Delete subsequent log files. */
+        delete_log_files(logfilename, dirnamelen,
+             (uint)srv_n_log_files_found, trunc);
+        if (trunc) {
+          /* Truncate the first log file. */
+          strcpy(logfilename + dirnamelen,
+                 "ib_logfile0");
+          FILE* f = fopen(logfilename, "w");
+          fclose(f);
+        }
+      }
+      return(err);
+    }
+
+    /* Upgrade or resize or rebuild the redo logs before
+    generating any dirty pages, so that the old redo log
+    files will not be written to. */
+
+    if (srv_force_recovery == SRV_FORCE_NO_LOG_REDO) {
+      /* Completely ignore the redo log. */
+    } else if (srv_read_only_mode) {
+      /* Leave the redo log alone. */
+    } else if (srv_log_file_size_requested == srv_log_file_size
+         && srv_n_log_files_found == srv_n_log_files
+         && log_sys.log.format
+         == (srv_encrypt_log
+             ? log_t::FORMAT_ENC_10_4
+             : log_t::FORMAT_10_4)
+         && log_sys.log.subformat == 2) {
+      /* No need to add or remove encryption,
+      upgrade, downgrade, or resize. */
+    } else {
+      /* Prepare to delete the old redo log files */
+      flushed_lsn = srv_prepare_to_delete_redo_log_files(i);
+
+      DBUG_EXECUTE_IF("innodb_log_abort_1",
+          return(srv_init_abort(DB_ERROR)););
+      /* Prohibit redo log writes from any other
+      threads until creating a log checkpoint at the
+      end of create_log_files(). */
+      ut_d(recv_no_log_write = true);
+      ut_ad(!buf_pool_check_no_pending_io());
+
+      DBUG_EXECUTE_IF("innodb_log_abort_3",
+          return(srv_init_abort(DB_ERROR)););
+      DBUG_PRINT("ib_log", ("After innodb_log_abort_3"));
+
+      /* Stamp the LSN to the data files. */
+      err = fil_write_flushed_lsn(flushed_lsn);
+
+      DBUG_EXECUTE_IF("innodb_log_abort_4", err = DB_ERROR;);
+      DBUG_PRINT("ib_log", ("After innodb_log_abort_4"));
+
+      if (err != DB_SUCCESS) {
+        return(srv_init_abort(err));
+      }
+
+      /* Close and free the redo log files, so that
+      we can replace them. */
+      fil_close_log_files(true);
+
+      DBUG_EXECUTE_IF("innodb_log_abort_5",
+          return(srv_init_abort(DB_ERROR)););
+      DBUG_PRINT("ib_log", ("After innodb_log_abort_5"));
+
+      ib::info() << "Starting to delete and rewrite log"
+        " files.";
+
+      srv_log_file_size = srv_log_file_size_requested;
+
+      err = create_log_files(
+        logfilename, dirnamelen, flushed_lsn,
+        logfile0);
+
+      if (err == DB_SUCCESS) {
+        err = create_log_files_rename(
+          logfilename, dirnamelen, flushed_lsn,
+          logfile0);
+      }
+
+      if (err != DB_SUCCESS) {
+        return(srv_init_abort(err));
+      }
+    }
+  }
+
+  ut_ad(err == DB_SUCCESS);
+  ut_a(sum_of_new_sizes != ULINT_UNDEFINED);
+
+  /* Create the doublewrite buffer to a new tablespace */
+  if (!srv_read_only_mode && srv_force_recovery < SRV_FORCE_NO_TRX_UNDO
+      && !buf_dblwr_create()) {
+    return(srv_init_abort(DB_ERROR));
+  }
+
+  /* Here the double write buffer has already been created and so
+  any new rollback segments will be allocated after the double
+  write buffer. The default segment should already exist.
+  We create the new segments only if it's a new database or
+  the database was shutdown cleanly. */
+
+  /* Note: When creating the extra rollback segments during an upgrade
+  we violate the latching order, even if the change buffer is empty.
+  We make an exception in sync0sync.cc and check srv_is_being_started
+  for that violation. It cannot create a deadlock because we are still
+  running in single threaded mode essentially. Only the IO threads
+  should be running at this stage. */
+
+  if (!trx_sys_create_rsegs()) {
+    return(srv_init_abort(DB_ERROR));
+  }
+
+  if (!create_new_db) {
+    /* Validate a few system page types that were left
+    uninitialized before MySQL or MariaDB 5.5. */
+    if (!high_level_read_only) {
+      ut_ad(srv_force_recovery <= SRV_FORCE_NO_IBUF_MERGE);
+      buf_block_t*	block;
+      mtr.start();
+      /* Bitmap page types will be reset in
+      buf_dblwr_check_block() without redo logging. */
+      block = buf_page_get(
+        page_id_t(IBUF_SPACE_ID,
+            FSP_IBUF_HEADER_PAGE_NO),
+        0, RW_X_LATCH, &mtr);
+      fil_block_check_type(*block, FIL_PAGE_TYPE_SYS, &mtr);
+      /* Already MySQL 3.23.53 initialized
+      FSP_IBUF_TREE_ROOT_PAGE_NO to
+      FIL_PAGE_INDEX. No need to reset that one. */
+      block = buf_page_get(
+        page_id_t(TRX_SYS_SPACE, TRX_SYS_PAGE_NO),
+        0, RW_X_LATCH, &mtr);
+      fil_block_check_type(*block, FIL_PAGE_TYPE_TRX_SYS,
+               &mtr);
+      block = buf_page_get(
+        page_id_t(TRX_SYS_SPACE,
+            FSP_FIRST_RSEG_PAGE_NO),
+        0, RW_X_LATCH, &mtr);
+      fil_block_check_type(*block, FIL_PAGE_TYPE_SYS, &mtr);
+      block = buf_page_get(
+        page_id_t(TRX_SYS_SPACE, FSP_DICT_HDR_PAGE_NO),
+        0, RW_X_LATCH, &mtr);
+      fil_block_check_type(*block, FIL_PAGE_TYPE_SYS, &mtr);
+      mtr.commit();
+
+      /* Roll back any recovered data dictionary
+      transactions, so that the data dictionary
+      tables will be free of any locks.  The data
+      dictionary latch should guarantee that there
+      is at most one data dictionary transaction
+      active at a time. */
+      if (srv_force_recovery < SRV_FORCE_NO_TRX_UNDO) {
+        /* If the following call is ever
+        removed, the first-time
+        ha_innobase::open() must hold (or
+        acquire and release) a table lock that
+        conflicts with
+        trx_resurrect_table_locks(), to ensure
+        that any recovered incomplete ALTER
+        TABLE will have been rolled
+        back. Otherwise, dict_table_t::instant
+        could be cleared by rollback invoking
+        dict_index_t::clear_instant_alter()
+        while open table handles exist in
+        client connections. */
+        trx_rollback_recovered(false);
+      }
+    }
+
+    /* FIXME: Skip the following if srv_read_only_mode,
+    while avoiding "Allocated tablespace ID" warnings. */
+    if (srv_force_recovery <= SRV_FORCE_NO_IBUF_MERGE) {
+      /* Open or Create SYS_TABLESPACES and SYS_DATAFILES
+      so that tablespace names and other metadata can be
+      found. */
+      err = dict_create_or_check_sys_tablespace();
+      if (err != DB_SUCCESS) {
+        return(srv_init_abort(err));
+      }
+
+      /* The following call is necessary for the insert
+      buffer to work with multiple tablespaces. We must
+      know the mapping between space id's and .ibd file
+      names.
+
+      In a crash recovery, we check that the info in data
+      dictionary is consistent with what we already know
+      about space id's from the calls to fil_ibd_load().
+
+      In a normal startup, we create the space objects for
+      every table in the InnoDB data dictionary that has
+      an .ibd file.
+
+      We also determine the maximum tablespace id used. */
+      dict_check_tablespaces_and_store_max_id();
+    }
+
+    if (srv_force_recovery < SRV_FORCE_NO_TRX_UNDO
+        && !srv_read_only_mode) {
+      /* Drop partially created indexes. */
+      row_merge_drop_temp_indexes();
+      /* Drop garbage tables. */
+      row_mysql_drop_garbage_tables();
+
+      /* Drop any auxiliary tables that were not
+      dropped when the parent table was
+      dropped. This can happen if the parent table
+      was dropped but the server crashed before the
+      auxiliary tables were dropped. */
+      fts_drop_orphaned_tables();
+
+      /* Rollback incomplete non-DDL transactions */
+      trx_rollback_is_active = true;
+      os_thread_create(trx_rollback_all_recovered, 0, 0);
+    }
+  }
+
+  srv_startup_is_before_trx_rollback_phase = false;
+
+  if (!srv_read_only_mode) {
+    /* Create the thread which watches the timeouts
+    for lock waits */
+    thread_handles[2 + SRV_MAX_N_IO_THREADS] = os_thread_create(
+      lock_wait_timeout_thread,
+      NULL, thread_ids + 2 + SRV_MAX_N_IO_THREADS);
+    thread_started[2 + SRV_MAX_N_IO_THREADS] = true;
+    lock_sys.timeout_thread_active = true;
+
+    DBUG_EXECUTE_IF("innodb_skip_monitors", goto skip_monitors;);
+    /* Create the thread which warns of long semaphore waits */
+    srv_error_monitor_active = true;
+    thread_handles[3 + SRV_MAX_N_IO_THREADS] = os_thread_create(
+      srv_error_monitor_thread,
+      NULL, thread_ids + 3 + SRV_MAX_N_IO_THREADS);
+    thread_started[3 + SRV_MAX_N_IO_THREADS] = true;
+
+    /* Create the thread which prints InnoDB monitor info */
+    srv_monitor_active = true;
+    thread_handles[4 + SRV_MAX_N_IO_THREADS] = os_thread_create(
+      srv_monitor_thread,
+      NULL, thread_ids + 4 + SRV_MAX_N_IO_THREADS);
+    thread_started[4 + SRV_MAX_N_IO_THREADS] = true;
+    srv_start_state |= SRV_START_STATE_LOCK_SYS
+      | SRV_START_STATE_MONITOR;
 
 #ifndef DBUG_OFF
 skip_monitors:
 #endif
-		ut_ad(srv_force_recovery >= SRV_FORCE_NO_UNDO_LOG_SCAN
-		      || !purge_sys.enabled());
-
-		if (srv_force_recovery < SRV_FORCE_NO_BACKGROUND) {
-			srv_undo_sources = true;
-			/* Create the dict stats gathering thread */
-			srv_dict_stats_thread_active = true;
-			dict_stats_thread_handle = os_thread_create(
-				dict_stats_thread, NULL, NULL);
-
-			/* Create the thread that will optimize the
-			FULLTEXT search index subsystem. */
-			fts_optimize_init();
-		}
-	}
-
-	/* Create the SYS_FOREIGN and SYS_FOREIGN_COLS system tables */
-	err = dict_create_or_check_foreign_constraint_tables();
-	if (err == DB_SUCCESS) {
-		err = dict_create_or_check_sys_tablespace();
-		if (err == DB_SUCCESS) {
-			err = dict_create_or_check_sys_virtual();
-		}
-	}
-	switch (err) {
-	case DB_SUCCESS:
-		break;
-	case DB_READ_ONLY:
-		if (srv_force_recovery >= SRV_FORCE_NO_TRX_UNDO) {
-			break;
-		}
-		ib::error() << "Cannot create system tables in read-only mode";
-		/* fall through */
-	default:
-		return(srv_init_abort(err));
-	}
-
-	if (!srv_read_only_mode && srv_operation == SRV_OPERATION_NORMAL) {
-		/* Initialize the innodb_temporary tablespace and keep
-		it open until shutdown. */
-		err = srv_open_tmp_tablespace(create_new_db);
-
-		if (err != DB_SUCCESS) {
-			return(srv_init_abort(err));
-		}
-
-		trx_temp_rseg_create();
-
-		if (srv_force_recovery < SRV_FORCE_NO_BACKGROUND) {
-			thread_handles[1 + SRV_MAX_N_IO_THREADS]
-				= os_thread_create(srv_master_thread, NULL,
-						   (1 + SRV_MAX_N_IO_THREADS)
-						   + thread_ids);
-			thread_started[1 + SRV_MAX_N_IO_THREADS] = true;
-			srv_start_state_set(SRV_START_STATE_MASTER);
-		}
-	}
-
-	if (!srv_read_only_mode && srv_operation == SRV_OPERATION_NORMAL
-	    && srv_force_recovery < SRV_FORCE_NO_BACKGROUND) {
-
-		thread_handles[5 + SRV_MAX_N_IO_THREADS] = os_thread_create(
-			srv_purge_coordinator_thread,
-			NULL, thread_ids + 5 + SRV_MAX_N_IO_THREADS);
-
-		thread_started[5 + SRV_MAX_N_IO_THREADS] = true;
-
-		ut_a(UT_ARR_SIZE(thread_ids)
-		     > 5 + srv_n_purge_threads + SRV_MAX_N_IO_THREADS);
-
-		/* We've already created the purge coordinator thread above. */
-		for (i = 1; i < srv_n_purge_threads; ++i) {
-			thread_handles[5 + i + SRV_MAX_N_IO_THREADS] = os_thread_create(
-				srv_worker_thread, NULL,
-				thread_ids + 5 + i + SRV_MAX_N_IO_THREADS);
-			thread_started[5 + i + SRV_MAX_N_IO_THREADS] = true;
-		}
-
-		while (srv_shutdown_state == SRV_SHUTDOWN_NONE
-		       && srv_force_recovery < SRV_FORCE_NO_BACKGROUND
-		       && !purge_sys.enabled()) {
-			ib::info() << "Waiting for purge to start";
-			os_thread_sleep(50000);
-		}
-
-		srv_start_state_set(SRV_START_STATE_PURGE);
-	}
-
-	srv_is_being_started = false;
-
-	if (!srv_read_only_mode) {
-		/* wake main loop of page cleaner up */
-		os_event_set(buf_flush_event);
-	}
-
-	if (srv_print_verbose_log) {
-		ib::info() << INNODB_VERSION_STR
-			   << " started; log sequence number "
-			   << srv_start_lsn
-			   << "; transaction id " << trx_sys.get_max_trx_id();
-	}
-
-	if (srv_force_recovery > 0) {
-		ib::info() << "!!! innodb_force_recovery is set to "
-			<< srv_force_recovery << " !!!";
-	}
-
-	if (srv_force_recovery == 0) {
-		/* In the insert buffer we may have even bigger tablespace
-		id's, because we may have dropped those tablespaces, but
-		insert buffer merge has not had time to clean the records from
-		the ibuf tree. */
-
-		ibuf_update_max_tablespace_id();
-	}
-
-	if (!srv_read_only_mode) {
-		if (create_new_db) {
-			srv_buffer_pool_load_at_startup = FALSE;
-		}
+    ut_ad(srv_force_recovery >= SRV_FORCE_NO_UNDO_LOG_SCAN
+          || !purge_sys.enabled());
+
+    if (srv_force_recovery < SRV_FORCE_NO_BACKGROUND) {
+      srv_undo_sources = true;
+      /* Create the dict stats gathering thread */
+      srv_dict_stats_thread_active = true;
+      dict_stats_thread_handle = os_thread_create(
+        dict_stats_thread, NULL, NULL);
+
+      /* Create the thread that will optimize the
+      FULLTEXT search index subsystem. */
+      fts_optimize_init();
+    }
+  }
+
+  /* Create the SYS_FOREIGN and SYS_FOREIGN_COLS system tables */
+  err = dict_create_or_check_foreign_constraint_tables();
+  if (err == DB_SUCCESS) {
+    err = dict_create_or_check_sys_tablespace();
+    if (err == DB_SUCCESS) {
+      err = dict_create_or_check_sys_virtual();
+    }
+  }
+  switch (err) {
+  case DB_SUCCESS:
+    break;
+  case DB_READ_ONLY:
+    if (srv_force_recovery >= SRV_FORCE_NO_TRX_UNDO) {
+      break;
+    }
+    ib::error() << "Cannot create system tables in read-only mode";
+    /* fall through */
+  default:
+    return(srv_init_abort(err));
+  }
+
+  if (!srv_read_only_mode && srv_operation == SRV_OPERATION_NORMAL) {
+    /* Initialize the innodb_temporary tablespace and keep
+    it open until shutdown. */
+    err = srv_open_tmp_tablespace(create_new_db);
+
+    if (err != DB_SUCCESS) {
+      return(srv_init_abort(err));
+    }
+
+    trx_temp_rseg_create();
+
+    if (srv_force_recovery < SRV_FORCE_NO_BACKGROUND) {
+      thread_handles[1 + SRV_MAX_N_IO_THREADS]
+        = os_thread_create(srv_master_thread, NULL,
+               (1 + SRV_MAX_N_IO_THREADS)
+               + thread_ids);
+      thread_started[1 + SRV_MAX_N_IO_THREADS] = true;
+      srv_start_state_set(SRV_START_STATE_MASTER);
+    }
+  }
+
+  if (!srv_read_only_mode && srv_operation == SRV_OPERATION_NORMAL
+      && srv_force_recovery < SRV_FORCE_NO_BACKGROUND) {
+
+    thread_handles[5 + SRV_MAX_N_IO_THREADS] = os_thread_create(
+      srv_purge_coordinator_thread,
+      NULL, thread_ids + 5 + SRV_MAX_N_IO_THREADS);
+
+    thread_started[5 + SRV_MAX_N_IO_THREADS] = true;
+
+    ut_a(UT_ARR_SIZE(thread_ids)
+         > 5 + srv_n_purge_threads + SRV_MAX_N_IO_THREADS);
+
+    /* We've already created the purge coordinator thread above. */
+    for (i = 1; i < srv_n_purge_threads; ++i) {
+      thread_handles[5 + i + SRV_MAX_N_IO_THREADS] = os_thread_create(
+        srv_worker_thread, NULL,
+        thread_ids + 5 + i + SRV_MAX_N_IO_THREADS);
+      thread_started[5 + i + SRV_MAX_N_IO_THREADS] = true;
+    }
+
+    while (srv_shutdown_state == SRV_SHUTDOWN_NONE
+           && srv_force_recovery < SRV_FORCE_NO_BACKGROUND
+           && !purge_sys.enabled()) {
+      ib::info() << "Waiting for purge to start";
+      os_thread_sleep(50000);
+    }
+
+    srv_start_state_set(SRV_START_STATE_PURGE);
+  }
+
+  srv_is_being_started = false;
+
+  if (!srv_read_only_mode) {
+    /* wake main loop of page cleaner up */
+    os_event_set(buf_flush_event);
+  }
+
+  if (srv_print_verbose_log) {
+    ib::info() << INNODB_VERSION_STR
+         << " started; log sequence number "
+         << srv_start_lsn
+         << "; transaction id " << trx_sys.get_max_trx_id();
+  }
+
+  if (srv_force_recovery > 0) {
+    ib::info() << "!!! innodb_force_recovery is set to "
+      << srv_force_recovery << " !!!";
+  }
+
+  if (srv_force_recovery == 0) {
+    /* In the insert buffer we may have even bigger tablespace
+    id's, because we may have dropped those tablespaces, but
+    insert buffer merge has not had time to clean the records from
+    the ibuf tree. */
+
+    ibuf_update_max_tablespace_id();
+  }
+
+  if (!srv_read_only_mode) {
+    if (create_new_db) {
+      srv_buffer_pool_load_at_startup = FALSE;
+    }
 
 #ifdef WITH_WSREP
-		/*
-		  Create the dump/load thread only when not running with
-		  --wsrep-recover.
-		*/
-		if (!get_wsrep_recovery()) {
+    /*
+      Create the dump/load thread only when not running with
+      --wsrep-recover.
+    */
+    if (!get_wsrep_recovery()) {
 #endif /* WITH_WSREP */
 
-		/* Create the buffer pool dump/load thread */
-		srv_buf_dump_thread_active = true;
-		buf_dump_thread_handle=
-			os_thread_create(buf_dump_thread, NULL, NULL);
+    /* Create the buffer pool dump/load thread */
+    srv_buf_dump_thread_active = true;
+    buf_dump_thread_handle=
+      os_thread_create(buf_dump_thread, NULL, NULL);
 
 #ifdef WITH_WSREP
-		} else {
-			ib::warn() <<
-				"Skipping buffer pool dump/restore during "
-				"wsrep recovery.";
-		}
+    } else {
+      ib::warn() <<
+        "Skipping buffer pool dump/restore during "
+        "wsrep recovery.";
+    }
 #endif /* WITH_WSREP */
 
-		/* Create thread(s) that handles key rotation. This is
-		needed already here as log_preflush_pool_modified_pages
-		will flush dirty pages and that might need e.g.
-		fil_crypt_threads_event. */
-		fil_system_enter();
-		btr_scrub_init();
-		fil_crypt_threads_init();
-		fil_system_exit();
+    /* Create thread(s) that handles key rotation. This is
+    needed already here as log_preflush_pool_modified_pages
+    will flush dirty pages and that might need e.g.
+    fil_crypt_threads_event. */
+    fil_system_enter();
+    btr_scrub_init();
+    fil_crypt_threads_init();
+    fil_system_exit();
 
-		/* Initialize online defragmentation. */
-		btr_defragment_init();
-		btr_defragment_thread_active = true;
-		os_thread_create(btr_defragment_thread, NULL, NULL);
+    /* Initialize online defragmentation. */
+    btr_defragment_init();
+    btr_defragment_thread_active = true;
+    os_thread_create(btr_defragment_thread, NULL, NULL);
 
-		srv_start_state |= SRV_START_STATE_REDO;
-	}
+    srv_start_state |= SRV_START_STATE_REDO;
+  }
 
-	/* Create the buffer pool resize thread */
-	srv_buf_resize_thread_active = true;
-	os_thread_create(buf_resize_thread, NULL, NULL);
+  /* Create the buffer pool resize thread */
+  srv_buf_resize_thread_active = true;
+  os_thread_create(buf_resize_thread, NULL, NULL);
 
-	return(DB_SUCCESS);
+  return(DB_SUCCESS);
 }
 
 /** Shut down background threads that can generate undo log. */
 void srv_shutdown_bg_undo_sources()
 {
-	if (srv_undo_sources) {
-		ut_ad(!srv_read_only_mode);
-		fts_optimize_shutdown();
-		dict_stats_shutdown();
-		while (row_get_background_drop_list_len_low()) {
-			srv_wake_master_thread();
-			os_thread_yield();
-		}
-		srv_undo_sources = false;
-	}
+  if (srv_undo_sources) {
+    ut_ad(!srv_read_only_mode);
+    fts_optimize_shutdown();
+    dict_stats_shutdown();
+    while (row_get_background_drop_list_len_low()) {
+      srv_wake_master_thread();
+      os_thread_yield();
+    }
+    srv_undo_sources = false;
+  }
 }
 
 /** Shut down InnoDB. */
 void innodb_shutdown()
 {
-	ut_ad(!srv_running.load(std::memory_order_relaxed));
-	ut_ad(!srv_undo_sources);
-
-	switch (srv_operation) {
-	case SRV_OPERATION_BACKUP:
-	case SRV_OPERATION_RESTORE:
-	case SRV_OPERATION_RESTORE_DELTA:
-	case SRV_OPERATION_RESTORE_EXPORT:
-		fil_close_all_files();
-		break;
-	case SRV_OPERATION_NORMAL:
-		/* Shut down the persistent files. */
-		logs_empty_and_mark_files_at_shutdown();
-
-		if (ulint n_threads = srv_conc_get_active_threads()) {
-			ib::warn() << "Query counter shows "
-				   << n_threads << " queries still"
-				" inside InnoDB at shutdown";
-		}
-	}
-
-	/* Exit any remaining threads. */
-	srv_shutdown_all_bg_threads();
-
-	if (srv_monitor_file) {
-		my_fclose(srv_monitor_file, MYF(MY_WME));
-		srv_monitor_file = 0;
-		if (srv_monitor_file_name) {
-			unlink(srv_monitor_file_name);
-			ut_free(srv_monitor_file_name);
-		}
-	}
-
-	if (srv_misc_tmpfile) {
-		my_fclose(srv_misc_tmpfile, MYF(MY_WME));
-		srv_misc_tmpfile = 0;
-	}
-
-	ut_ad(dict_stats_event || !srv_was_started || srv_read_only_mode);
-	ut_ad(dict_sys.is_initialised() || !srv_was_started);
-	ut_ad(trx_sys.is_initialised() || !srv_was_started);
-	ut_ad(buf_dblwr || !srv_was_started || srv_read_only_mode
-	      || srv_force_recovery >= SRV_FORCE_NO_TRX_UNDO);
-	ut_ad(lock_sys.is_initialised() || !srv_was_started);
-	ut_ad(log_sys.is_initialised() || !srv_was_started);
+  ut_ad(!srv_running.load(std::memory_order_relaxed));
+  ut_ad(!srv_undo_sources);
+
+  switch (srv_operation) {
+  case SRV_OPERATION_BACKUP:
+  case SRV_OPERATION_RESTORE:
+  case SRV_OPERATION_RESTORE_DELTA:
+  case SRV_OPERATION_RESTORE_EXPORT:
+    fil_close_all_files();
+    break;
+  case SRV_OPERATION_NORMAL:
+    /* Shut down the persistent files. */
+    logs_empty_and_mark_files_at_shutdown();
+
+    if (ulint n_threads = srv_conc_get_active_threads()) {
+      ib::warn() << "Query counter shows "
+           << n_threads << " queries still"
+        " inside InnoDB at shutdown";
+    }
+  }
+
+  /* Exit any remaining threads. */
+  srv_shutdown_all_bg_threads();
+
+  if (srv_monitor_file) {
+    my_fclose(srv_monitor_file, MYF(MY_WME));
+    srv_monitor_file = 0;
+    if (srv_monitor_file_name) {
+      unlink(srv_monitor_file_name);
+      ut_free(srv_monitor_file_name);
+    }
+  }
+
+  if (srv_misc_tmpfile) {
+    my_fclose(srv_misc_tmpfile, MYF(MY_WME));
+    srv_misc_tmpfile = 0;
+  }
+
+  ut_ad(dict_stats_event || !srv_was_started || srv_read_only_mode);
+  ut_ad(dict_sys.is_initialised() || !srv_was_started);
+  ut_ad(trx_sys.is_initialised() || !srv_was_started);
+  ut_ad(buf_dblwr || !srv_was_started || srv_read_only_mode
+        || srv_force_recovery >= SRV_FORCE_NO_TRX_UNDO);
+  ut_ad(lock_sys.is_initialised() || !srv_was_started);
+  ut_ad(log_sys.is_initialised() || !srv_was_started);
 #ifdef BTR_CUR_HASH_ADAPT
-	ut_ad(btr_search_sys || !srv_was_started);
+  ut_ad(btr_search_sys || !srv_was_started);
 #endif /* BTR_CUR_HASH_ADAPT */
-	ut_ad(ibuf.index || !srv_was_started);
+  ut_ad(ibuf.index || !srv_was_started);
 
-	if (dict_stats_event) {
-		dict_stats_thread_deinit();
-	}
+  if (dict_stats_event) {
+    dict_stats_thread_deinit();
+  }
 
-	if (srv_start_state_is_set(SRV_START_STATE_REDO)) {
-		ut_ad(!srv_read_only_mode);
-		/* srv_shutdown_bg_undo_sources() already invoked
-		fts_optimize_shutdown(); dict_stats_shutdown(); */
+  if (srv_start_state_is_set(SRV_START_STATE_REDO)) {
+    ut_ad(!srv_read_only_mode);
+    /* srv_shutdown_bg_undo_sources() already invoked
+    fts_optimize_shutdown(); dict_stats_shutdown(); */
 
-		fil_crypt_threads_cleanup();
-		btr_scrub_cleanup();
-		btr_defragment_shutdown();
-	}
+    fil_crypt_threads_cleanup();
+    btr_scrub_cleanup();
+    btr_defragment_shutdown();
+  }
 
-	/* This must be disabled before closing the buffer pool
-	and closing the data dictionary.  */
+  /* This must be disabled before closing the buffer pool
+  and closing the data dictionary.  */
 
 #ifdef BTR_CUR_HASH_ADAPT
-	if (dict_sys.is_initialised()) {
-		btr_search_disable(true);
-	}
+  if (dict_sys.is_initialised()) {
+    btr_search_disable(true);
+  }
 #endif /* BTR_CUR_HASH_ADAPT */
-	ibuf_close();
-	log_sys.close();
-	purge_sys.close();
-	trx_sys.close();
-	if (buf_dblwr) {
-		buf_dblwr_free();
-	}
-	lock_sys.close();
-	trx_pool_close();
-
-	if (!srv_read_only_mode) {
-		mutex_free(&srv_monitor_file_mutex);
-		mutex_free(&srv_misc_tmpfile_mutex);
-	}
-
-	dict_sys.close();
-	btr_search_sys_free();
-
-	/* 3. Free all InnoDB's own mutexes and the os_fast_mutexes inside
-	them */
-	os_aio_free();
-	row_mysql_close();
-	srv_free();
-	fil_system.close();
-
-	/* 4. Free all allocated memory */
-
-	pars_lexer_close();
-	recv_sys.close();
-
-	ut_ad(buf_pool_ptr || !srv_was_started);
-	if (buf_pool_ptr) {
-		buf_pool_free(srv_buf_pool_instances);
-	}
-
-	sync_check_close();
-
-	if (srv_was_started && srv_print_verbose_log) {
-		ib::info() << "Shutdown completed; log sequence number "
-			   << srv_shutdown_lsn
-			   << "; transaction id " << trx_sys.get_max_trx_id();
-	}
-
-	srv_start_state = SRV_START_STATE_NONE;
-	srv_was_started = false;
-	srv_start_has_been_called = false;
+  ibuf_close();
+  log_sys.close();
+  purge_sys.close();
+  trx_sys.close();
+  if (buf_dblwr) {
+    buf_dblwr_free();
+  }
+  lock_sys.close();
+  trx_pool_close();
+
+  if (!srv_read_only_mode) {
+    mutex_free(&srv_monitor_file_mutex);
+    mutex_free(&srv_misc_tmpfile_mutex);
+  }
+
+  dict_sys.close();
+  btr_search_sys_free();
+
+  /* 3. Free all InnoDB's own mutexes and the os_fast_mutexes inside
+  them */
+  os_aio_free();
+  row_mysql_close();
+  srv_free();
+  fil_system.close();
+
+  /* 4. Free all allocated memory */
+
+  pars_lexer_close();
+  recv_sys.close();
+
+  ut_ad(buf_pool_ptr || !srv_was_started);
+  if (buf_pool_ptr) {
+    buf_pool_free(srv_buf_pool_instances);
+  }
+
+  sync_check_close();
+
+  if (srv_was_started && srv_print_verbose_log) {
+    ib::info() << "Shutdown completed; log sequence number "
+         << srv_shutdown_lsn
+         << "; transaction id " << trx_sys.get_max_trx_id();
+  }
+
+  srv_start_state = SRV_START_STATE_NONE;
+  srv_was_started = false;
+  srv_start_has_been_called = false;
 }
 
 /** Get the meta-data filename from the table name for a
@@ -2578,30 +2579,30 @@ single-table tablespace.
 @param[in]	max_len		filename max length */
 void
 srv_get_meta_data_filename(
-	dict_table_t*	table,
-	char*		filename,
-	ulint		max_len)
+  dict_table_t*	table,
+  char*		filename,
+  ulint		max_len)
 {
-	ulint		len;
-	char*		path;
+  ulint		len;
+  char*		path;
 
-	/* Make sure the data_dir_path is set. */
-	dict_get_and_save_data_dir_path(table, false);
+  /* Make sure the data_dir_path is set. */
+  dict_get_and_save_data_dir_path(table, false);
 
-	if (DICT_TF_HAS_DATA_DIR(table->flags)) {
-		ut_a(table->data_dir_path);
+  if (DICT_TF_HAS_DATA_DIR(table->flags)) {
+    ut_a(table->data_dir_path);
 
-		path = fil_make_filepath(
-			table->data_dir_path, table->name.m_name, CFG, true);
-	} else {
-		path = fil_make_filepath(NULL, table->name.m_name, CFG, false);
-	}
+    path = fil_make_filepath(
+      table->data_dir_path, table->name.m_name, CFG, true);
+  } else {
+    path = fil_make_filepath(NULL, table->name.m_name, CFG, false);
+  }
 
-	ut_a(path);
-	len = strlen(path);
-	ut_a(max_len >= len);
+  ut_a(path);
+  len = strlen(path);
+  ut_a(max_len >= len);
 
-	strcpy(filename, path);
+  strcpy(filename, path);
 
-	ut_free(path);
+  ut_free(path);
 }
